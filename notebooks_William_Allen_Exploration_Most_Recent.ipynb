{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 5,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": "# Downloading The Data",
      "metadata": {},
      "id": "b12db014"
    },
    {
      "cell_type": "code",
      "source": "import os\n\nimport numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nfrom allensdk.brain_observatory.ecephys.ecephys_project_cache import EcephysProjectCache\n\nimport scipy.stats as stats\nimport math\n\nimport sklearn.linear_model",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": [],
      "id": "8cf0b9b6"
    },
    {
      "cell_type": "code",
      "source": "# Example cache directory path, it determines where downloaded data will be stored\nbase_directory = 'C:\\\\Users\\\\claym\\\\OneDrive\\\\Documents\\\\OSU\\\\uPNC\\\\Project\\\\Data'\n\nout_directory = os.path.join(base_directory, 'Plots and output')\n\ndata_directory = os.path.join(base_directory, 'Manifest')\n\nmanifest_path = os.path.join(data_directory, \"manifest.json\")\n\ncache = EcephysProjectCache.from_warehouse(manifest=manifest_path,timeout=12000)",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "f1827234"
    },
    {
      "cell_type": "code",
      "source": "sessionID_1 = 715093703\nsessionID_2 = 739448407\nsessionID_3 = 732592105\nsession_train = cache.get_session_data(sessionID_1)\nsession_test = cache.get_session_data(sessionID_1)",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "729abfc8"
    },
    {
      "cell_type": "code",
      "source": "probe_id = session_test.probes[session_test.probes.description == 'probeC'].index.values[0]\n\nlfp = session_train.get_lfp(probe_id)\n\nlfp_VISp_test = lfp.sel(channel = lfp.channel[54:67])\n",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "a7443e8f"
    },
    {
      "cell_type": "code",
      "source": "probe_id = session.probes[session.probes.description == 'probeE'].index.values[0]\n\nlfp = session.get_lfp(probe_id)\n\n# lfp_VISrl = lfp.sel(channel = lfp.channel[64:85])\n\nlfp_thalamus = lfp.sel(channel = lfp.channel[42:63])\n\n# del globals()[lfp]",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "928e1585"
    },
    {
      "cell_type": "code",
      "source": "probe_id = session.probes[session.probes.description == 'probeD'].index.values[0]\n\nlfp = session.get_lfp(probe_id)\n\n# lfp_LGd = lfp.sel(channel = lfp.channel[:20])\n\nlfp_VISl = lfp.sel(channel = lfp.channel[60:80])",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "dfffbada"
    },
    {
      "cell_type": "code",
      "source": "probe_id = session_train.probes[session_train.probes.description == 'probeC'].index.values[0]\n\nlfp = session_train.get_lfp(probe_id)\n\n# lfp_VISp = lfp.sel(channel = lfp.channel[60:80])\n\nlfp_VISp_train = lfp.sel(channel = lfp.channel[63:76])\n\n# lfp_LP = lfp.sel(channel = lfp.channel[5:25])\n",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "9d2d7916"
    },
    {
      "cell_type": "code",
      "source": "probe_id = session.probes[session.probes.description == 'probeB'].index.values[0]\n\nlfp = session.get_lfp(probe_id)\n\nlfp_VISpm = lfp.sel(channel = lfp.channel[66:81])",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "e8563f73"
    },
    {
      "cell_type": "code",
      "source": "probe_id = session.probes[session.probes.description == 'probeA'].index.values[0]\n\nlfp = session.get_lfp(probe_id)\n\nlfp_VISam = lfp.sel(channel = lfp.channel[60:80])",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "f1a8fbc6"
    },
    {
      "cell_type": "markdown",
      "source": " # Probe C",
      "metadata": {},
      "id": "d88cdaa6"
    },
    {
      "cell_type": "markdown",
      "source": "The motivation in investigating Probe C is to isolate V1 (VISp)",
      "metadata": {},
      "id": "46832ec4"
    },
    {
      "cell_type": "markdown",
      "source": "## NWBWIDGETS",
      "metadata": {},
      "id": "508cc010"
    },
    {
      "cell_type": "code",
      "source": "from pynwb import NWBHDF5IO\nimport allensdk.brain_observatory.ecephys.nwb\n\nfrom nwbwidgets import nwb2widget\nfpath = '/Users/willi/OneDrive/Documents/Computational Neuroscience/Project/ecephys_guides/session_715093703/probe_810755805_lfp-004.nwb'\n#this is probe C which passes through V1, specific interest in 62-82 or VISp. Clay mentions 135 and 315 are orientations of interest\nnwb = NWBHDF5IO(fpath, 'r').read()\n\n\n#from nwbwidgets.allen import AllenRasterWidget\n\n#AllenRasterWidget(nwb.units)",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "addd76a1"
    },
    {
      "cell_type": "code",
      "source": "nwb2widget(nwb)\n",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "de788daa"
    },
    {
      "cell_type": "code",
      "source": "from pynwb import NWBHDF5IO\nimport allensdk.brain_observatory.ecephys.nwb\nimport ndx_icephys_meta\nfrom nwbwidgets import nwb2widget\nfpath = '/Users/willi/downloads/session_715093703/probe_810755801_lfp.nwb'\n#this is probe C which passes through V1, specific interest in 62-82 or VISp. Clay mentions 135 and 315 are orientations of interest\nnwb = NWBHDF5IO(fpath, 'r').read()\nnwb2widget(nwb)",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "9c5cfea1"
    },
    {
      "cell_type": "code",
      "source": "#from nwbwidgets.allen import AllenRasterWidget\n#\n#AllenRasterWidget(nwb.units)",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "463d541b"
    },
    {
      "cell_type": "markdown",
      "source": "# LFP Exploration",
      "metadata": {},
      "id": "1b44a1d8"
    },
    {
      "cell_type": "markdown",
      "source": "Below is loading in the specific probe of interest and selecting the region of interest VISp",
      "metadata": {},
      "id": "a4b988e8"
    },
    {
      "cell_type": "code",
      "source": "probe_id = session.probes[session.probes.description == 'probeC'].index.values[0]\n##from clay print(session.probes[session.probes.description == 'probeC'].index.values)\nlfp = session.get_lfp(probe_id)\nlfp_VISp = lfp.sel(channel = lfp.channel[62:84])",
      "metadata": {
        "scrolled": true
      },
      "execution_count": null,
      "outputs": [],
      "id": "b4b25e84"
    },
    {
      "cell_type": "code",
      "source": "lfp",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "8215fc82"
    },
    {
      "cell_type": "code",
      "source": "import torch\nimport torch.nn.functional as F\nfrom torch.autograd import Variable\n\ndevice = torch.device(\"cuda:0\")\ntorch.cuda.set_device(device)\n\nimport torchvision.models as models\n\n# io utils\nfrom pytorch3d.io import load_obj\n\n# Util function for loading meshes\nfrom pytorch3d.io import load_objs_as_meshes\n\n# Data structures and functions for rendering\nfrom pytorch3d.structures import Meshes\nfrom pytorch3d.renderer import (\n    Textures,\n    look_at_view_transform,\n    OpenGLPerspectiveCameras, \n    PointLights, \n    DirectionalLights, \n    Materials, \n    RasterizationSettings, \n    MeshRenderer, \n    MeshRasterizer,  \n    SoftPhongShader,\n    BlendParams\n)\n\nimport os\nimport numpy as np\nfrom PIL import Image\nprint(\"not the import\")\n\n\n\n# function loading a 3d obj and texture using pytorch3d\ndef load_obj_and_texture_img_as_mesh(f_obj, f_tex, device=None, texture_requires_grad=False):\n  verts, faces, aux = load_obj(f_obj, load_textures=False)\n  verts = verts.to(device)\n  \n  if aux is None or aux.verts_uvs is None:\n    raise ValueError(f\"{f_obj} and {f_tex} loaded incorrectly\")\n  \n  verts_uvs = aux.verts_uvs[None, ...].to(device)  # (1, V, 2)\n  faces_uvs = faces.textures_idx[None, ...].to(device)  # (1, F, 3)\n  image = torch.as_tensor(np.array(Image.open(f_tex).convert(\"RGB\")) / 255.0, dtype=torch.float32).to(device)[None]\n  tex = Textures(verts_uvs=verts_uvs, faces_uvs=faces_uvs, maps=image)\n  \n  mesh = Meshes(verts=[verts], faces=[faces.verts_idx.to(device)], textures=tex)\n  \n  if texture_requires_grad:\n    mesh.textures._maps_padded.requires_grad = True\n  \n  return mesh\n\n\n# Data preprocessing for inception_v3\ndef process_data(device, data, input_size):\n    data = torch.squeeze(data)\n    data = (data - data.min()) / (data.max() - data.min())  # rescale to [0, 1]\n    mean = torch.tensor([0.485, 0.456, 0.406]).to(device)\n    std = torch.tensor([0.229, 0.224, 0.225]).to(device)\n    data = (data - mean[: ,None, None]) / std[: ,None, None]  # normalise with tensors\n    data = torch.unsqueeze(data,0)\n    data = F.interpolate(data, (input_size, input_size))\n    return data\n\n# # multiview setting\nPARAMETER_PATH = \"/data03/home/cwashington/PyTorch3D/data_stop_new/tv_nps_ce_eykholt_goodplacement/test_set_params_short.txt\"\nparam_file = open(PARAMETER_PATH, 'r')\ntesting_params = []\nfor line in param_file:\n  testing_params.append(line.split(','))\n  testing_params[len(testing_params)-1] = list(map(float, testing_params[len(testing_params)-1]))\nparam_file.close()\n\nimage_size = 1024  # for high quality\nfaces_per_pixel = 10\n\n\nnum_renders_per_iteration = len(testing_params)\nprint(num_renders_per_iteration)\n\n##LOCAL ATTACK ATTEMPT (CE ONLY)\nimport random\n\n#phase 1: masking image effectively\n\n#load image\nDATA_DIR = \"/data03/home/cwashington/PyTorch3D/data_stop_new\"\nTEXTURE_DIR_ROOT = os.path.join(DATA_DIR, \"tv_nps_ce_eykholt_goodplacement\")\n\n\n#phase 2: perform attack and eliminate gradient in masked area\n\n# # Set up Renderer\nraster_settings = RasterizationSettings(image_size=image_size,\n                                        blur_radius=0.0,\n                                        faces_per_pixel=faces_per_pixel,\n                                        bin_size=None,\n                                        max_faces_per_bin=None\n)\n\nrenderer = MeshRenderer(\n    rasterizer=MeshRasterizer(\n        cameras=None,\n        raster_settings=raster_settings,\n    ),\n    shader=SoftPhongShader(\n        device=device,\n        cameras=None,\n        lights=None,\n    )\n)\n\ntarget = Variable(torch.LongTensor([919]), requires_grad=False)\ntarget = target.to(device)\n\n\n# # load 3d objects and texture\n\nobj_path = os.path.join(DATA_DIR, \"stopsign.obj\")\nmax_texture_number = 149\nsave_success_ratios = [None]*(max_texture_number)\n\n\n\ndef initialize_model(model_name, use_pretrained=True):\n        # Initialize these variables which will be set in this if statement. Each of these\n        #   variables is model specific.\n        model_ft = None\n        input_size = 0\n\n        if model_name == \"resnet18\":\n            \"\"\" Resnet18\n            \"\"\"\n            model_ft = models.resnet18(pretrained=use_pretrained)\n            input_size = 224\n\n        elif model_name == \"alexnet\":\n            \"\"\" Alexnet\n            \"\"\"\n            model_ft = models.alexnet(pretrained=use_pretrained)\n            input_size = 224\n\n        elif model_name == \"squeezenet1_0\":\n            \"\"\" Squeezenet\n            \"\"\"\n            model_ft = models.squeezenet1_0(pretrained=use_pretrained)\n            input_size = 224\n\n        elif model_name == \"vgg16\":\n            \"\"\" VGG16\n            \"\"\"\n            model_ft = models.vgg16(pretrained=use_pretrained)\n            input_size = 224\n\n        elif model_name == \"densenet161\":\n            \"\"\" Densenet\n            \"\"\"\n            model_ft = models.densenet161(pretrained=use_pretrained)\n            input_size = 224\n\n        elif model_name == \"inception_v3\":\n            \"\"\" Inception v3 \n            Be careful, expects (299,299) sized images and has auxiliary output\n            \"\"\"\n            model_ft = models.inception_v3(pretrained=use_pretrained)\n            input_size = 299\n        else:\n            print(\"Invalid model name, exiting...\")\n            exit()\n\n        return model_ft, input_size\n    \nPRETRAINED_NETMODEL_NAMES = ['resnet18','alexnet','squeezenet1_0','vgg16','densenet161','inception_v3']\nPRETRAINED_NETMODEL_NAMES_1 = ['resnet18','alexnet','squeezenet1_0']\nPRETRAINED_NETMODEL_NAMES_2 = ['vgg16','densenet161','inception_v3']\n\nfor PRETRAINED_NETMODEL_NAME in PRETRAINED_NETMODEL_NAMES_1:\n\n    print(PRETRAINED_NETMODEL_NAME)\n\n    \n\n\n    # Initialize the model for this run\n    model_ft, input_size = initialize_model(PRETRAINED_NETMODEL_NAME)\n\n    model = model_ft.to(device)\n\n    model.eval()\n\n    ##################################################\n    \n    for PERTURBATION_SOURCE in PRETRAINED_NETMODEL_NAMES:\n\n        texture_path = os.path.join(TEXTURE_DIR_ROOT, PERTURBATION_SOURCE, \"perturbed_texture_12.png\")\n        mesh = load_obj_and_texture_img_as_mesh(obj_path, texture_path, device=device)\n\n        count = 0\n        close_count = 0\n        med_count = 0\n        far_count = 0\n\n        for i in range(len(testing_params)):\n\n            params = testing_params[i]\n\n            ambient_color = params[0]\n            dist = params[1]\n            elev = params[2]\n            azim = params[3]    \n\n            materials = Materials(device=device, ambient_color=[[ambient_color*1] * 3], specular_color=[[ambient_color*.3]*3], shininess = 32)\n\n\n            # get look at, openGL perspec camera according to current parameters\n            R, T = look_at_view_transform(dist, elev, azim)\n            cameras = OpenGLPerspectiveCameras(device=device, R=R, T=T)\n            location = cameras.get_camera_center().detach().cpu().numpy()\n            lights = PointLights(device=device, location = location, ambient_color=((ambient_color, ambient_color, ambient_color),), diffuse_color=((ambient_color*.9, ambient_color*.9, ambient_color*.9),))\n\n            # run neural renderer and process output for training targets\n            images = renderer(mesh, cameras=cameras, materials=materials,  lights = lights)\n            images = images[..., :3]\n\n            # ### show the rendered images\n            # imagesDos = images.clone()\n            # imagesDos = imagesDos[0].cpu().detach().numpy()\n            # plt.figure(figsize=(10, 10))\n            # plt.imshow(imagesDos)\n            # plt.grid(\"off\");\n            # plt.axis(\"off\");\n            # plt.show()\n\n            images = images.permute(0, 3, 1, 2)\n\n            processed_temp_images = process_data(device, images, input_size)\n\n            output1 = model(processed_temp_images)\n\n            init_pred = output1.max(1, keepdim=True)[1]  # get the index of the max log-probability\n\n            if init_pred.item() != target.data.item():\n              count = count + 1\n\n        success_ratio = count/num_renders_per_iteration\n        print(\"attacking model: {} victim model: {} success rate: {}\".format(PERTURBATION_SOURCE,PRETRAINED_NETMODEL_NAME,str(success_ratio)))\n\n\n",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "342d84e6"
    },
    {
      "cell_type": "markdown",
      "source": "Next we desire to isolate time slices and visualize them through a plot",
      "metadata": {},
      "id": "5e6a5ace"
    },
    {
      "cell_type": "code",
      "source": "lfp_slice = lfp.sel(time=slice(1800,5410))\n\nlfp_slice_VISp = lfp_slice.sel(channel=lfp_slice.channel[62:84])\n",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "3cf4de1f"
    },
    {
      "cell_type": "code",
      "source": "lfp_slice = lfp.sel(time=slice(1800,5410))\n\nlfp_slice_VISp = lfp_slice.sel(channel=lfp_slice.channel[-25:-10]) ##playing around with the range for the matplotlib...\n#...function further down\n",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "f85ec247"
    },
    {
      "cell_type": "markdown",
      "source": "Obtaining multiple plots at once for lfp_slice_VISp with a for loop",
      "metadata": {},
      "id": "a32e1fc0"
    },
    {
      "cell_type": "code",
      "source": "for i in range(15):\n    plt.figure(figsize=(10,2))\n    _ = plt.plot(lfp_slice_VISp.time, lfp_slice_VISp.sel(channel=lfp_slice_VISp.channel[i]))\n    plt.xlabel('Time (s)')\n    plt.ylabel('LFP (V)')",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "a0687df2"
    },
    {
      "cell_type": "code",
      "source": "lfp_slice_VISp",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "b8a1f453"
    },
    {
      "cell_type": "code",
      "source": "plt.figure(figsize=(10,2))\n_ = plt.plot(lfp_slice_VISp.time, lfp_slice_VISp)\nplt.xlabel('Time (s)')\nplt.ylabel('LFP (V)')",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "18013ef9"
    },
    {
      "cell_type": "markdown",
      "source": "Alternatively, we can visualize lfp_slice_VISp using matplotlib's imshow method:\n!!This is strangely lacking information so look at this again!!",
      "metadata": {},
      "id": "274fefcc"
    },
    {
      "cell_type": "code",
      "source": "plt.figure(figsize=(16,16))\nim = plt.imshow(lfp_slice_VISp.T,aspect='auto',origin='lower',vmin=-1e-3, vmax=1e-3)\n_ = plt.colorbar(im, fraction=0.036, pad=0.04)\n_ = plt.xlabel('Sample number')\n_ = plt.ylabel('Channel index')",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "7e9edc45"
    },
    {
      "cell_type": "markdown",
      "source": "Note that we've transposed the original array to place the time dimension along the x-axis. We've also configured the plot so that the origin of the array is in the lower-left, so that that channels closer to the probe tip are lower in the image.\n\nA few things to note about this plot:\n\nThe units of the LFP are volts, so the color scale ranges from -1 to +1 mV\n\nEven though there are 384 channels on the Neuropixels probe, there are only 95 channels in this plot. That's because only every 4th channel is included in the NWB file (resulting in 40 micron vertical spacing). In addition, the reference channels and channels far outside the brain have been removed.\n\nThe top of the plot is relatively flat. This corresponds to channels that are outside the brain. The LFP channels are originally referenced to a ground wire embedded in the ACSF/agarose mixture about cortex. Before NWB packaging, the LFP data is digitally referenced to the channels outside the brain, to remove noise that's shared across the whole probe.\nThere's a large increase in LFP power toward the middle of the probe, which corresponds to channels in hippocampus.",
      "metadata": {},
      "id": "4960c378"
    },
    {
      "cell_type": "markdown",
      "source": "Let's do some additional data selection to look at just the visual recordings",
      "metadata": {},
      "id": "0aad7f2a"
    },
    {
      "cell_type": "code",
      "source": "channel_ids = session.channels[(session.channels.probe_id == probe_id) & \\\n                 (session.channels.ecephys_structure_acronym.isin(['VISp']))].index.values\n\nlfp_slice2 = lfp_slice.sel(channel=slice(np.min(channel_ids), np.max(channel_ids)))\n\nplt.figure(figsize=(8,4))\nim = plt.imshow(lfp_slice2.T,aspect='auto',origin='lower',vmin=-1e-3, vmax=1e-3)\n_ = plt.colorbar(im, fraction=0.036, pad=0.04)\n_ = plt.xlabel('Sample number') ## Sample number is time: think of it like each time point is a sample\n_ = plt.ylabel('Channel index')",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "32ff5e2f"
    },
    {
      "cell_type": "markdown",
      "source": "What follows next is a sequence of code cells from Allen/ Written by Clay, edited by myself which appear to be attempts to isolate the stimulus presentation for the probe. The code is fairly straightforward and will be used for work on Probe D Analysis",
      "metadata": {},
      "id": "17a10067"
    },
    {
      "cell_type": "markdown",
      "source": "# transferability experiment",
      "metadata": {},
      "id": "00919dd0"
    },
    {
      "cell_type": "code",
      "source": "import random\nimport statistics\nfrom sklearn.model_selection import train_test_split\n\nflashes_presentation_table_train = session_train.stimulus_presentations[session_train.stimulus_presentations.stimulus_name == 'flashes']\nflashes_presentation_times_train = flashes_presentation_table_train.start_time.values\nflashes_presentation_ids_train = flashes_presentation_table_train.index.values\n\nflashes_presentation_table_test = session_test.stimulus_presentations[session_test.stimulus_presentations.stimulus_name == 'flashes']\nflashes_presentation_times_test = flashes_presentation_table_test.start_time.values\nflashes_presentation_ids_test = flashes_presentation_table_test.index.values\n\n\n#TRAIN MODEL\n\n\n#CREATING PLOTS WITH NCV\n\n# LINEAR CLASSIFIER\n\n#specifically works for flashes\ndef lr_transferability_train(flashes_presentation_table, lfp_data, window_size, end_time, time_res):\n    classifier_accuracies = []\n    models = []\n    \n    window_start_times = []\n    start_time = 0\n    while start_time + 1000*window_size < 1000*end_time:\n        window_start_times.append(start_time/1000)\n        start_time += 1000*window_size\n    print(window_start_times)\n\n    next_empty_column = 0\n    \n# PRODUCE ALIGNED LFPs FROM PROBE DATA\n\n    flashes_presentation_table_1 = flashes_presentation_table[flashes_presentation_table.color\n                                                                      == 1.0]\n    flashes_presentation_table_minus1 = flashes_presentation_table[flashes_presentation_table.color\n                                                                          == -1.0]\n    presentation_times_1 = flashes_presentation_table_1.start_time.values\n    presentation_ids_1 = flashes_presentation_table_1.index.values\n\n    presentation_times_minus1 = flashes_presentation_table_minus1.start_time.values\n    presentation_ids_minus1 = flashes_presentation_table_minus1.index.values\n\n    for window_start in window_start_times:\n    \n \n\n\n    #for 1\n\n\n\n        trial_window = np.arange(window_start, window_start + window_size, time_res)\n        if 1/(len(trial_window)*100) <  time_res:\n            trial_window = trial_window[:-1]\n        time_selection = np.concatenate([trial_window + t for t in presentation_times_1])\n\n        inds = pd.MultiIndex.from_product((presentation_ids_1, trial_window),\n                                      names=('presentation_id', 'time_from_presentation_onset'))\n\n        ds = lfp_data.sel(time = time_selection, method='nearest').to_dataset(name = 'aligned_lfp')\n        ds = ds.assign(time=inds).unstack('time')\n\n        aligned_lfp_1 = ds['aligned_lfp']\n\n#for -1\n\n\n\n        trial_window = np.arange(window_start, window_start + window_size, time_res)\n        if 1/(len(trial_window)*100) <  time_res:\n            trial_window = trial_window[:-1]\n        time_selection = np.concatenate([trial_window + t for t in presentation_times_minus1])\n\n        inds = pd.MultiIndex.from_product((presentation_ids_minus1, trial_window),\n                                      names=('presentation_id', 'time_from_presentation_onset'))\n\n        ds = lfp_data.sel(time = time_selection, method='nearest').to_dataset(name = 'aligned_lfp')\n        ds = ds.assign(time=inds).unstack('time')\n\n        aligned_lfp_minus1 = ds['aligned_lfp']\n\n\n# COMPUTE T SCORES AND CORRESPONDING P VALUES IN INDEPENDENT T TEST BETWEEN TRIAL CONDITIONS\n\n        tStat, pValue = stats.ttest_ind(a= aligned_lfp_minus1,\n            b = aligned_lfp_1,\n            axis = 1,\n            equal_var = False,\n            nan_policy = 'raise')\n\n# FORMAT TRIAL DATA FOR CLASSIFICATION\n\n\n        flashes_1_data = aligned_lfp_1.to_masked_array()\n        flashes_minus1_data = aligned_lfp_minus1.to_masked_array()\n        flashes_1_data.mask = np.ma.nomask\n        flashes_minus1_data.mask = np.ma.nomask\n        flashes_data_combined = np.concatenate((flashes_1_data,flashes_minus1_data),axis=1).transpose(1,0,2)\n        flashes_data_combined = flashes_data_combined.reshape(flashes_data_combined.shape[0],flashes_data_combined.shape[1] * flashes_data_combined.shape[2])\n        labels = []\n        for i in range(75):\n            labels.append(1)\n        for i in range(75,150):\n            labels.append(0)\n\n\n        x_train, x_test, y_train, y_test = train_test_split(flashes_data_combined, labels, test_size=0.25, stratify=labels)\n        \n        \n        model = sklearn.linear_model.LogisticRegression(solver='liblinear')\n\n        penalty = ['l1','l2']\n        C = [10,100,1000]\n        hyperparameters = dict(C=C,penalty=penalty)\n\n        clf = sklearn.model_selection.GridSearchCV(model, hyperparameters, cv=3)\n        best_model_LR = clf.fit(x_train,y_train)\n        models.append(best_model_LR)\n        classifier_accuracies.append(best_model_LR.score(x_test,y_test))\n\n        \n    return window_start_times, models, classifier_accuracies\n\ndef lr_transferability_test(flashes_presentation_table, lfp_data, window_size, end_time, time_res, models):\n    classifier_accuracies = []\n    model_idx = 0\n    \n    window_start_times = []\n    start_time = 0\n    while start_time + 1000*window_size < 1000*end_time:\n        window_start_times.append(start_time/1000)\n        start_time += 1000*window_size\n    print(window_start_times)\n\n    next_empty_column = 0\n    \n# PRODUCE ALIGNED LFPs FROM PROBE DATA\n\n    flashes_presentation_table_1 = flashes_presentation_table[flashes_presentation_table.color\n                                                                      == 1.0]\n    flashes_presentation_table_minus1 = flashes_presentation_table[flashes_presentation_table.color\n                                                                          == -1.0]\n    presentation_times_1 = flashes_presentation_table_1.start_time.values\n    presentation_ids_1 = flashes_presentation_table_1.index.values\n\n    presentation_times_minus1 = flashes_presentation_table_minus1.start_time.values\n    presentation_ids_minus1 = flashes_presentation_table_minus1.index.values\n\n    for window_start in window_start_times:\n    \n \n\n\n    #for 1\n\n\n\n        trial_window = np.arange(window_start, window_start + window_size, time_res)\n        if 1/(len(trial_window)*100) <  time_res:\n            trial_window = trial_window[:-1]\n        time_selection = np.concatenate([trial_window + t for t in presentation_times_1])\n\n        inds = pd.MultiIndex.from_product((presentation_ids_1, trial_window),\n                                      names=('presentation_id', 'time_from_presentation_onset'))\n\n        ds = lfp_data.sel(time = time_selection, method='nearest').to_dataset(name = 'aligned_lfp')\n        ds = ds.assign(time=inds).unstack('time')\n\n        aligned_lfp_1 = ds['aligned_lfp']\n\n#for -1\n\n\n\n        trial_window = np.arange(window_start, window_start + window_size, time_res)\n        if 1/(len(trial_window)*100) <  time_res:\n            trial_window = trial_window[:-1]\n        time_selection = np.concatenate([trial_window + t for t in presentation_times_minus1])\n\n        inds = pd.MultiIndex.from_product((presentation_ids_minus1, trial_window),\n                                      names=('presentation_id', 'time_from_presentation_onset'))\n\n        ds = lfp_data.sel(time = time_selection, method='nearest').to_dataset(name = 'aligned_lfp')\n        ds = ds.assign(time=inds).unstack('time')\n\n        aligned_lfp_minus1 = ds['aligned_lfp']\n\n\n# COMPUTE T SCORES AND CORRESPONDING P VALUES IN INDEPENDENT T TEST BETWEEN TRIAL CONDITIONS\n\n        tStat, pValue = stats.ttest_ind(a= aligned_lfp_minus1,\n            b = aligned_lfp_1,\n            axis = 1,\n            equal_var = False,\n            nan_policy = 'raise')\n\n# FORMAT TRIAL DATA FOR CLASSIFICATION\n\n\n        flashes_1_data = aligned_lfp_1.to_masked_array()\n        flashes_minus1_data = aligned_lfp_minus1.to_masked_array()\n        flashes_1_data.mask = np.ma.nomask\n        flashes_minus1_data.mask = np.ma.nomask\n        flashes_data_combined = np.concatenate((flashes_1_data,flashes_minus1_data),axis=1).transpose(1,0,2)\n        flashes_data_combined = flashes_data_combined.reshape(flashes_data_combined.shape[0],flashes_data_combined.shape[1] * flashes_data_combined.shape[2])\n        labels = []\n        for i in range(75):\n            labels.append(1)\n        for i in range(75,150):\n            labels.append(0)\n\n\n#         x_train, x_test, y_train, y_test = train_test_split(flashes_data_combined, labels, test_size=1, stratify=labels)\n        \n        \n        best_model_LR = models[model_idx]\n        classifier_accuracies.append(best_model_LR.score(flashes_data_combined,labels))\n\n        model_idx += 1\n        \n    return classifier_accuracies\n\n#-----------------------------------------------------------------------------------------\n\n# starts, models, train_accuracies = lr_transferability_train(flashes_presentation_table=flashes_presentation_table_train,\n#                                                                          lfp_data=lfp_VISp_train, \n#                                                                          window_size=.01, \n#                                                                          end_time=.5, \n#                                                                          time_res=1/100)\n# print(\"train complete\")\n\n# test_accuracies = lr_transferability_test(flashes_presentation_table=flashes_presentation_table_test,\n#                                                                          lfp_data=lfp_VISp_train, \n#                                                                          window_size=.01, \n#                                                                          end_time=.5, \n#                                                                          time_res=1/100,\n#                                                                          models=models)\n\n# for i in range(len(starts)):\n#     print(\"Window start: {} ms      Mean Classifier Accuracy: {}\".format(math.floor(1000*starts[i]), classifier_accuracies[i]))\n    \nplt.figure(figsize=(8,6))\nim = plt.plot(starts, train_accuracies, label=\"Training mouse\")\n# _ = plt.fill_between(starts, ci_low, ci_hi, alpha=0.2)\nim = plt.plot(starts, test_accuracies, label=\"New mouse\")\n# im = plt.plot(starts, ci_hi, label=\"ci high\")\n_ = plt.xlabel('Start of time window following stimulus onset (s)')\n_ = plt.ylabel('Classifier Accuracy')\n_ = plt.title('Logistic regression classifer accuracy on mouse used for training and new mouse')\n_ = plt.legend()\n\n# plt.figure(figsize=(8,6))\n# im = plt.plot(starts, errhat_ncv, label=\"mean\")\n# _ = plt.xlabel('Start of time window following stimulus onset (s)')\n# _ = plt.ylabel('Classifier Accuracy')\n# _ = plt.title('Bootstrapped mean linear classifer accuracy with 95% CI, trained on 10 ms sliding time windows')\n# _ = plt.legend()\n\n# plt.figure(figsize=(8,6))\n# im = plt.plot(starts, errhat_cv, label=\"mean\")\n# _ = plt.xlabel('Start of time window following stimulus onset (s)')\n# _ = plt.ylabel('Classifier Accuracy')\n# _ = plt.title('Bootstrapped mean linear classifer accuracy with 95% CI, trained on 10 ms sliding time windows')\n# _ = plt.legend()\n\n# fig = plt.figure(figsize=(8,6))\n# im2 = plt.imshow(coefficients, origin='lower', cmap='bone')\n# _ = plt.xlabel(\"Time sample after stimulus onset (by 10ms)\")\n# _ = plt.ylabel(\"Electrode index\")\n# _ = plt.title(\"Linear Classifier Coefficients\")\n# _ = plt.colorbar(im2, cax = fig.add_axes([.92, 0.33, 0.03, 0.38]))\n\n\n\n\n\n\n\n\n",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "81728bf8"
    },
    {
      "cell_type": "markdown",
      "source": "# 2x2x2 table and Kappa",
      "metadata": {},
      "id": "73540ed3"
    },
    {
      "cell_type": "code",
      "source": "flashes_presentation_table_1 = flashes_presentation_table[flashes_presentation_table.color \n                                                                      == 1.0]\nflashes_presentation_table_minus1 = flashes_presentation_table[flashes_presentation_table.color \n                                                                          == -1.0]\n\nwindow_end = 0.5\ntime_res = 1/100\nlfp_data = lfp_VISp\n\n#for 1\n\npresentation_times = flashes_presentation_table_1.start_time.values\npresentation_ids = flashes_presentation_table_1.index.values\n\ntrial_window = np.arange(0, window_end, time_res)\ntime_selection = np.concatenate([trial_window + t for t in presentation_times])\n\ninds = pd.MultiIndex.from_product((presentation_ids, trial_window), \n                                  names=('presentation_id', 'time_from_presentation_onset'))\n\nds = lfp_data.sel(time = time_selection, method='nearest').to_dataset(name = 'aligned_lfp')\nds = ds.assign(time=inds).unstack('time')\n\naligned_lfp_1 = ds['aligned_lfp']\n\n#for -1\n\npresentation_times = flashes_presentation_table_minus1.start_time.values\npresentation_ids = flashes_presentation_table_minus1.index.values\n\ntrial_window = np.arange(0, window_end, time_res)\ntime_selection = np.concatenate([trial_window + t for t in presentation_times])\n\ninds = pd.MultiIndex.from_product((presentation_ids, trial_window), \n                                  names=('presentation_id', 'time_from_presentation_onset'))\n\nds = lfp_data.sel(time = time_selection, method='nearest').to_dataset(name = 'aligned_lfp')\nds = ds.assign(time=inds).unstack('time')\n\naligned_lfp_minus1 = ds['aligned_lfp']\n\n\n# COMPUTE T SCORES AND CORRESPONDING P VALUES IN INDEPENDENT T TEST BETWEEN TRIAL CONDITIONS\n\ntStat, pValue = stats.ttest_ind(a= aligned_lfp_minus1,\n       b = aligned_lfp_1,\n       axis = 1,\n       equal_var = False,\n       nan_policy = 'raise')\n\n# FORMAT TRIAL DATA FOR CLASSIFICATION\n\n\nflashes_1_data = aligned_lfp_1.to_masked_array()\nflashes_minus1_data = aligned_lfp_minus1.to_masked_array()\nflashes_1_data.mask = np.ma.nomask\nflashes_minus1_data.mask = np.ma.nomask\nflashes_data_combined = np.concatenate((flashes_1_data,flashes_minus1_data),axis=1).transpose(1,0,2)\nflashes_data_combined = flashes_data_combined.reshape(flashes_data_combined.shape[0],flashes_data_combined.shape[1] * flashes_data_combined.shape[2])\nlabels = []\nfor i in range(75):\n    labels.append(1)\nfor i in range(75,150):\n    labels.append(0)\n    \nNMC = 100\n\n# GT/SVM/LR\na111=0\na110=0\na101=0\na100=0\na011=0\na010=0\na001=0\na000=0\n\n\nSVM_out_total = []\nLR_out_total = []\n    \n    \nfor a in range(NMC):\n\n    # PERFORM  CLASSIFICATIONS\n\n\n    from sklearn.model_selection import train_test_split\n    x_train, x_test, y_train, y_test = train_test_split(flashes_data_combined, labels, test_size=0.5, stratify=labels)\n\n    # TUNE HYPERPARAMETERS USING CROSS-VALIDATION\n\n    model = sklearn.svm.SVC()\n\n    kernel = ['linear', 'poly', 'rbf', 'sigmoid']\n    C = [10,100,1000]\n    hyperparameters = dict(C=C,kernel=kernel)\n\n    clf = sklearn.model_selection.GridSearchCV(model, hyperparameters, cv=3)\n    best_model_SVM = clf.fit(x_train,y_train)\n\n    model = sklearn.linear_model.LogisticRegression(solver='liblinear')\n\n    penalty = ['l1','l2']\n    C = [10,100,1000]\n    hyperparameters = dict(C=C,penalty=penalty)\n\n    clf = sklearn.model_selection.GridSearchCV(model, hyperparameters, cv=3)\n    best_model_LR = clf.fit(x_train,y_train)\n\n\n\n    ground_truth = y_test\n    SVM_out = best_model_SVM.predict(x_test)\n    LR_out = best_model_LR.predict(x_test)\n    \n    SVM_out_total.append(SVM_out)\n    LR_out_total.append(LR_out)\n\n\n\n\n\n\n    for i in range(len(ground_truth)):\n        if ground_truth[i] == 1:\n            if SVM_out[i] == 1:\n                if LR_out[i] == 1:\n                    a111 += 1\n                else:\n                    a110 += 1\n            else:\n                if LR_out[i] == 1:\n                    a101 += 1\n                else:\n                    a100 += 1\n        else:\n            if SVM_out[i] == 1:\n                if LR_out[i] == 1:\n                    a011 += 1\n                else:\n                    a010 += 1\n            else:\n                if LR_out[i] == 1:\n                    a001 += 1\n                else:\n                    a000 += 1\n                    \ntot = a111 + a110 + a101 + a100 + a011 + a010 + a001 + a000\n\nprint(\"111: {} \\n110: {} \\n101: {} \\n100: {} \\n011: {} \\n010: {} \\n001: {} \\n000: {}\".format(a111/tot,a110/tot,a101/tot,a100/tot,a011/tot,a010/tot,a001/tot,a000/tot))\nkappa = sklearn.metrics.cohen_kappa_score(SVM_out,LR_out)\nprint(\"kappa:\",kappa)",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "fc840a15"
    },
    {
      "cell_type": "markdown",
      "source": "# # PLOTTING SLIDING TIME WINDOW-BASED NCV CIs FOR CLASSIFIER ACCURACY (4WILLIAM)",
      "metadata": {},
      "id": "662d32cd"
    },
    {
      "cell_type": "code",
      "source": "# svm\n\ndef standard_CV(data,labels,K):\n    scores = []\n    rand_inds = [i for i in range(len(data))]\n    random.shuffle(rand_inds)\n    data_folds = []\n    label_folds = []\n    for i in range(K):\n        fold_inds = rand_inds[round(len(rand_inds)*i/K):round(len(rand_inds)*(i+1)/K)]\n        data_fold = []\n        label_fold = []\n        for ind in fold_inds:\n            data_fold.append(data[ind])\n            label_fold.append(labels[ind])\n        data_folds.append(data_fold)\n        label_folds.append(label_fold)\n    for val_ind in range(K):\n        val_data_fold = None\n        val_label_fold = None \n        train_data_folds = []\n        train_label_folds = []\n        for fold_ind in range(K):\n            if fold_ind == val_ind:\n                val_data_fold = data_folds[fold_ind]\n                val_label_fold = label_folds[fold_ind]\n            else:\n                train_data_folds.append(data_folds[fold_ind])\n                train_label_folds.append(label_folds[fold_ind])\n                \n        val_data_fold = np.array(val_data_fold)\n        val_label_fold = np.array(val_label_fold)\n        train_data_folds = np.array(train_data_folds)\n        train_label_folds = np.array(train_label_folds)\n\n\n        train_data = train_data_folds.reshape(train_data_folds.shape[0]*train_data_folds.shape[1],train_data_folds.shape[2])\n        train_labels = train_label_folds.flatten()       \n        \n        \n        model = sklearn.svm.SVC()\n\n        kernel = ['linear', 'sigmoid']\n        C = [10,100,1000]\n        hyperparameters = dict(C=C,kernel=kernel)\n\n        clf = sklearn.model_selection.GridSearchCV(model, hyperparameters, cv=3)\n\n        \n        \n        \n        theta_hat = clf.fit(train_data,train_labels)\n        mean_e_out = 1 - theta_hat.score(val_data_fold,val_label_fold)\n        \n\n        scores.append(mean_e_out)\n    return scores\n\ndef inner_CV(data_folds,label_folds,K):\n    e_in = []\n\n    for val_ind in range(K-1):\n        val_data_fold = None\n        val_label_fold = None \n        train_data_folds = []\n        train_label_folds = []\n        for fold_ind in range(K-1):\n            if fold_ind == val_ind:\n                val_data_fold = data_folds[fold_ind]\n                val_label_fold = label_folds[fold_ind]\n            else:\n                train_data_folds.append(data_folds[fold_ind])\n                train_label_folds.append(label_folds[fold_ind])\n                \n        val_data_fold = np.array(val_data_fold)\n        val_label_fold = np.array(val_label_fold)\n        train_data_folds = np.array(train_data_folds)\n        train_label_folds = np.array(train_label_folds)\n\n                \n        train_data = train_data_folds.reshape(train_data_folds.shape[0]*train_data_folds.shape[1],train_data_folds.shape[2])\n        train_labels = train_label_folds.flatten()\n\n        model = sklearn.svm.SVC()\n\n        kernel = ['linear', 'sigmoid']\n        C = [10,100,1000]\n        hyperparameters = dict(C=C,kernel=kernel)\n\n        clf = sklearn.model_selection.GridSearchCV(model, hyperparameters, cv=3)\n        theta_hat = clf.fit(train_data,train_labels)\n        mean_e_out = 1 - theta_hat.score(val_data_fold,val_label_fold)\n        num_1 = np.round_(mean_e_out*len(val_data_fold),2)\n        num_0 = len(val_data_fold)-num_1\n        fake_sample = []\n        for i in range(int(num_1)):\n            fake_sample.append(1)\n        for i in range(int(num_0)):\n            fake_sample.append(0)\n        \n        e_in.append(fake_sample)\n    return e_in\n\n\ndef nested_CV(X,Y,R,K):\n    es = []\n    a_list = []\n    b_list = []\n    for r in range(R):\n        #assign folds    CAN THROW IN STRATIFY USING FRACTIONS IN TRAIN TEST SPLIT WITH DECREASING DENOM\n        rand_inds = [i for i in range(len(X))]\n        random.shuffle(rand_inds)\n        data_folds_for_rep = []\n        label_folds_for_rep = []\n        for i in range(K):\n            fold_inds = rand_inds[round(len(rand_inds)*i/K):round(len(rand_inds)*(i+1)/K)]\n            data_fold = []\n            label_fold = []\n            for ind in fold_inds:\n                data_fold.append(X[ind])\n                label_fold.append(Y[ind])\n            data_folds_for_rep.append(data_fold)\n            label_folds_for_rep.append(label_fold)\n\n        #outer cv loop\n        for val_ind in range(K):\n            val_data_fold = None\n            val_label_fold = None \n            train_data_folds = []\n            train_label_folds = []\n            for fold_ind in range(K):\n                if fold_ind == val_ind:\n                    val_data_fold = data_folds_for_rep[fold_ind]\n                    val_label_fold = label_folds_for_rep[fold_ind]\n                else:\n                    train_data_folds.append(data_folds_for_rep[fold_ind])\n                    train_label_folds.append(label_folds_for_rep[fold_ind])\n                    \n            val_data_fold = np.array(val_data_fold)\n            val_label_fold = np.array(val_label_fold)\n            train_data_folds = np.array(train_data_folds)\n            train_label_folds = np.array(train_label_folds)\n            \n            e_in = inner_CV(train_data_folds,train_label_folds,K)\n\n            \n            train_data = train_data_folds.reshape(train_data_folds.shape[0]*train_data_folds.shape[1],train_data_folds.shape[2])\n            train_labels = train_label_folds.flatten()\n            \n            model = sklearn.svm.SVC()\n\n            kernel = ['linear', 'sigmoid']\n            C = [10,100,1000]\n            hyperparameters = dict(C=C,kernel=kernel)\n\n            clf = sklearn.model_selection.GridSearchCV(model, hyperparameters, cv=3)\n            theta_hat = clf.fit(train_data,train_labels)\n            \n            mean_e_out = 1 - theta_hat.score(val_data_fold,val_label_fold)\n\n            num_1 = np.round_(mean_e_out*len(val_data_fold),2)\n            num_0 = len(val_data_fold)-num_1\n            fake_sample = []\n            for i in range(int(num_1)):\n                fake_sample.append(1)\n            for i in range(int(num_0)):\n                fake_sample.append(0)\n            var_e_out = statistics.variance(fake_sample)\n            a_list.append((np.mean(e_in) - mean_e_out)**2)\n            b_list.append(statistics.variance(fake_sample)/len(val_data_fold))\n            es.append(e_in)\n    \n\n    MSEhat = np.mean(a_list) - np.mean(b_list)\n    errhat_NCV = np.mean(es)\n    return errhat_NCV, MSEhat",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "5f0081a2"
    },
    {
      "cell_type": "code",
      "source": "import scipy.stats as st\nimport random\n\n#CREATING PLOTS WITH NCV\n\n# LINEAR CLASSIFIER\n\n#specifically works for flashes\ndef classifier_accuracy_by_trial_window_ncv_lin(flashes_presentation_table, lfp_data, window_size, end_time, time_res, reps, k, alpha):\n    classifier_accuracies_qalphadiv2 = []\n    classifier_accuracies_means = []\n    classifier_accuracies_q1minusalphadiv2 = []\n    errhat_ncv_store = []\n    errhat_cv_store = []\n        \n    \n    window_start_times = []\n    start_time = 0\n    while start_time + 1000*window_size < 1000*end_time:\n        window_start_times.append(start_time/1000)\n        start_time += 1000*window_size\n    print(window_start_times)\n    \n    model_coefficients = np.zeros((len(lfp_data.channel),int(end_time/time_res)))\n    print(\"model coefficients shape:\",model_coefficients.shape)\n\n    next_empty_column = 0\n    \n# PRODUCE ALIGNED LFPs FROM PROBE DATA\n\n    flashes_presentation_table_1 = flashes_presentation_table[flashes_presentation_table.color\n                                                                      == 1.0]\n    flashes_presentation_table_minus1 = flashes_presentation_table[flashes_presentation_table.color\n                                                                          == -1.0]\n    presentation_times_1 = flashes_presentation_table_1.start_time.values\n    presentation_ids_1 = flashes_presentation_table_1.index.values\n\n    presentation_times_minus1 = flashes_presentation_table_minus1.start_time.values\n    presentation_ids_minus1 = flashes_presentation_table_minus1.index.values\n\n    for window_start in window_start_times:\n    \n \n\n\n    #for 1\n\n\n\n        trial_window = np.arange(window_start, window_start + window_size, time_res)\n        if 1/(len(trial_window)*100) <  time_res:\n            trial_window = trial_window[:-1]\n        time_selection = np.concatenate([trial_window + t for t in presentation_times_1])\n\n        inds = pd.MultiIndex.from_product((presentation_ids_1, trial_window),\n                                      names=('presentation_id', 'time_from_presentation_onset'))\n\n        ds = lfp_data.sel(time = time_selection, method='nearest').to_dataset(name = 'aligned_lfp')\n        ds = ds.assign(time=inds).unstack('time')\n\n        aligned_lfp_1 = ds['aligned_lfp']\n\n#for -1\n\n\n\n        trial_window = np.arange(window_start, window_start + window_size, time_res)\n        if 1/(len(trial_window)*100) <  time_res:\n            trial_window = trial_window[:-1]\n        time_selection = np.concatenate([trial_window + t for t in presentation_times_minus1])\n\n        inds = pd.MultiIndex.from_product((presentation_ids_minus1, trial_window),\n                                      names=('presentation_id', 'time_from_presentation_onset'))\n\n        ds = lfp_data.sel(time = time_selection, method='nearest').to_dataset(name = 'aligned_lfp')\n        ds = ds.assign(time=inds).unstack('time')\n\n        aligned_lfp_minus1 = ds['aligned_lfp']\n\n\n# COMPUTE T SCORES AND CORRESPONDING P VALUES IN INDEPENDENT T TEST BETWEEN TRIAL CONDITIONS\n\n        tStat, pValue = stats.ttest_ind(a= aligned_lfp_minus1,\n            b = aligned_lfp_1,\n            axis = 1,\n            equal_var = False,\n            nan_policy = 'raise')\n\n# FORMAT TRIAL DATA FOR CLASSIFICATION\n\n\n        flashes_1_data = aligned_lfp_1.to_masked_array()\n        flashes_minus1_data = aligned_lfp_minus1.to_masked_array()\n        flashes_1_data.mask = np.ma.nomask\n        flashes_minus1_data.mask = np.ma.nomask\n        flashes_data_combined = np.concatenate((flashes_1_data,flashes_minus1_data),axis=1).transpose(1,0,2)\n        flashes_data_combined = flashes_data_combined.reshape(flashes_data_combined.shape[0],flashes_data_combined.shape[1] * flashes_data_combined.shape[2])\n        labels = []\n        for i in range(75):\n            labels.append(1)\n        for i in range(75,150):\n            labels.append(0)\n\n\n\n        errhat_ncv, MSEhat = nested_CV(X=flashes_data_combined, Y=labels, R=reps, K=k)\n        \n        from sklearn.model_selection import train_test_split\n        x_train, x_test, y_train, y_test = train_test_split(flashes_data_combined, labels, test_size=0.25, stratify=labels)\n        \n\n\n        errhat_cv = np.mean(standard_CV(flashes_data_combined,labels,k))\n        \n        \n        errhat_ncv_store.append(errhat_ncv)\n        errhat_cv_store.append(errhat_cv)\n        \n        biashat = (1+((k-2)/k))*(errhat_ncv-errhat_cv)\n        point_estimate = errhat_ncv - biashat\n        \n        \n        #CONSTRUCTION\n        print(\"window:\",window_start)\n        print(\"k:\",k,\"MSEhat\",MSEhat)\n        print(\"NCV error estimate:\",errhat_ncv,\"point estimate:\",point_estimate)\n        \n        #/CONSTRUCTION\n        \n        \n        interval_radius = st.norm.ppf(1-alpha/2)*math.sqrt((k-1)/k)*math.sqrt(abs(MSEhat))     \n        \n    \n#         coefficient_store = np.matrix(coefficient_store)\n#         print(coefficient_store.shape)\n#         coefficient_store = np.transpose(coefficient_store)\n#         print(coefficient_store.shape)\n#         coefficient_store = coefficient_store.mean(axis=1)\n#         print(coefficient_store.shape)\n\n\n        \n    \n\n        classifier_accuracies_qalphadiv2.append(min(1,1-(point_estimate - interval_radius)))\n        classifier_accuracies_means.append(1-point_estimate)\n        classifier_accuracies_q1minusalphadiv2.append(min(1,1-(point_estimate + interval_radius)))\n        \n    return window_start_times, classifier_accuracies_qalphadiv2, classifier_accuracies_means, classifier_accuracies_q1minusalphadiv2, errhat_ncv_store, errhat_cv_store\n\n#-----------------------------------------------------------------------------------------\n\nstarts, ci_low, classifier_accuracies, ci_hi, errhat_ncv, errhat_cv = classifier_accuracy_by_trial_window_ncv_lin(flashes_presentation_table=flashes_presentation_table,\n                                                                         lfp_data=lfp_VISp, \n                                                                         window_size=.01, \n                                                                         end_time=.5, \n                                                                         time_res=1/100, \n                                                                         reps=10, k=5,\n                                                                         alpha=.05)\nfor i in range(len(starts)):\n    print(\"Window start: {} ms      Mean Classifier Accuracy: {}\".format(math.floor(1000*starts[i]), classifier_accuracies[i]))\n    \nplt.figure(figsize=(8,6))\nim = plt.plot(starts, classifier_accuracies, label=\"mean\")\n_ = plt.fill_between(starts, ci_low, ci_hi, alpha=0.2)\n# im = plt.plot(starts, ci_low, label=\"ci low\")\n# im = plt.plot(starts, ci_hi, label=\"ci high\")\n_ = plt.xlabel('Start of time window following stimulus onset (s)')\n_ = plt.ylabel('Classifier Accuracy')\n_ = plt.title('Logistic regression classifer accuracy with 95% CI from NCV')\n_ = plt.legend()\n\n# plt.figure(figsize=(8,6))\n# im = plt.plot(starts, errhat_ncv, label=\"mean\")\n# _ = plt.xlabel('Start of time window following stimulus onset (s)')\n# _ = plt.ylabel('Classifier Accuracy')\n# _ = plt.title('Bootstrapped mean linear classifer accuracy with 95% CI, trained on 10 ms sliding time windows')\n# _ = plt.legend()\n\n# plt.figure(figsize=(8,6))\n# im = plt.plot(starts, errhat_cv, label=\"mean\")\n# _ = plt.xlabel('Start of time window following stimulus onset (s)')\n# _ = plt.ylabel('Classifier Accuracy')\n# _ = plt.title('Bootstrapped mean linear classifer accuracy with 95% CI, trained on 10 ms sliding time windows')\n# _ = plt.legend()\n\n# fig = plt.figure(figsize=(8,6))\n# im2 = plt.imshow(coefficients, origin='lower', cmap='bone')\n# _ = plt.xlabel(\"Time sample after stimulus onset (by 10ms)\")\n# _ = plt.ylabel(\"Electrode index\")\n# _ = plt.title(\"Linear Classifier Coefficients\")\n# _ = plt.colorbar(im2, cax = fig.add_axes([.92, 0.33, 0.03, 0.38]))",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "b27c18b8"
    },
    {
      "cell_type": "code",
      "source": "import random\nimport statistics\n\nflashes_presentation_table = session.stimulus_presentations[session.stimulus_presentations.stimulus_name == 'flashes']\nflashes_presentation_times = flashes_presentation_table.start_time.values\nflashes_presentation_ids = flashes_presentation_table.index.values\n\nlen(flashes_presentation_table)\n",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "63d76703"
    },
    {
      "cell_type": "code",
      "source": "def standard_CV(data,labels,K):\n    scores = []\n    rand_inds = [i for i in range(len(data))]\n    random.shuffle(rand_inds)\n    data_folds = []\n    label_folds = []\n    for i in range(K):\n        fold_inds = rand_inds[round(len(rand_inds)*i/K):round(len(rand_inds)*(i+1)/K)]\n        data_fold = []\n        label_fold = []\n        for ind in fold_inds:\n            data_fold.append(data[ind])\n            label_fold.append(labels[ind])\n        data_folds.append(data_fold)\n        label_folds.append(label_fold)\n    for val_ind in range(K):\n        val_data_fold = None\n        val_label_fold = None \n        train_data_folds = []\n        train_label_folds = []\n        for fold_ind in range(K):\n            if fold_ind == val_ind:\n                val_data_fold = data_folds[fold_ind]\n                val_label_fold = label_folds[fold_ind]\n            else:\n                train_data_folds.append(data_folds[fold_ind])\n                train_label_folds.append(label_folds[fold_ind])\n                \n        val_data_fold = np.array(val_data_fold)\n        val_label_fold = np.array(val_label_fold)\n        train_data_folds = np.array(train_data_folds)\n        train_label_folds = np.array(train_label_folds)\n\n\n        train_data = train_data_folds.reshape(train_data_folds.shape[0]*train_data_folds.shape[1],train_data_folds.shape[2])\n        train_labels = train_label_folds.flatten()\n\n        model = sklearn.linear_model.LogisticRegression(solver='liblinear')\n\n        penalty = ['l1','l2']\n        C = [10,100,1000]\n        hyperparameters = dict(C=C,penalty=penalty)\n\n        clf = sklearn.model_selection.GridSearchCV(model, hyperparameters, cv=3)\n        theta_hat = clf.fit(train_data,train_labels)\n        mean_e_out = 1 - theta_hat.score(val_data_fold,val_label_fold)\n        \n\n        scores.append(mean_e_out)\n    return scores\n\ndef inner_CV(data_folds,label_folds,K):\n    e_in = []\n\n    for val_ind in range(K-1):\n        val_data_fold = None\n        val_label_fold = None \n        train_data_folds = []\n        train_label_folds = []\n        for fold_ind in range(K-1):\n            if fold_ind == val_ind:\n                val_data_fold = data_folds[fold_ind]\n                val_label_fold = label_folds[fold_ind]\n            else:\n                train_data_folds.append(data_folds[fold_ind])\n                train_label_folds.append(label_folds[fold_ind])\n                \n        val_data_fold = np.array(val_data_fold)\n        val_label_fold = np.array(val_label_fold)\n        train_data_folds = np.array(train_data_folds)\n        train_label_folds = np.array(train_label_folds)\n\n                \n        train_data = train_data_folds.reshape(train_data_folds.shape[0]*train_data_folds.shape[1],train_data_folds.shape[2])\n        train_labels = train_label_folds.flatten()\n\n        model = sklearn.linear_model.LogisticRegression(solver='liblinear')\n\n        penalty = ['l1','l2']\n        C = [10,100,1000]\n        hyperparameters = dict(C=C,penalty=penalty)\n\n        clf = sklearn.model_selection.GridSearchCV(model, hyperparameters, cv=3)\n        theta_hat = clf.fit(train_data,train_labels)\n        mean_e_out = 1 - theta_hat.score(val_data_fold,val_label_fold)\n        num_1 = np.round_(mean_e_out*len(val_data_fold),2)\n        num_0 = len(val_data_fold)-num_1\n        fake_sample = []\n        for i in range(int(num_1)):\n            fake_sample.append(1)\n        for i in range(int(num_0)):\n            fake_sample.append(0)\n        \n        e_in.append(fake_sample)\n    return e_in\n\n\ndef nested_CV(X,Y,R,K):\n    es = []\n    a_list = []\n    b_list = []\n    for r in range(R):\n        #assign folds    CAN THROW IN STRATIFY USING FRACTIONS IN TRAIN TEST SPLIT WITH DECREASING DENOM\n        rand_inds = [i for i in range(len(X))]\n        random.shuffle(rand_inds)\n        data_folds_for_rep = []\n        label_folds_for_rep = []\n        for i in range(K):\n            fold_inds = rand_inds[round(len(rand_inds)*i/K):round(len(rand_inds)*(i+1)/K)]\n            data_fold = []\n            label_fold = []\n            for ind in fold_inds:\n                data_fold.append(X[ind])\n                label_fold.append(Y[ind])\n            data_folds_for_rep.append(data_fold)\n            label_folds_for_rep.append(label_fold)\n\n        #outer cv loop\n        for val_ind in range(K):\n            val_data_fold = None\n            val_label_fold = None \n            train_data_folds = []\n            train_label_folds = []\n            for fold_ind in range(K):\n                if fold_ind == val_ind:\n                    val_data_fold = data_folds_for_rep[fold_ind]\n                    val_label_fold = label_folds_for_rep[fold_ind]\n                else:\n                    train_data_folds.append(data_folds_for_rep[fold_ind])\n                    train_label_folds.append(label_folds_for_rep[fold_ind])\n                    \n            val_data_fold = np.array(val_data_fold)\n            val_label_fold = np.array(val_label_fold)\n            train_data_folds = np.array(train_data_folds)\n            train_label_folds = np.array(train_label_folds)\n            \n            e_in = inner_CV(train_data_folds,train_label_folds,K)\n\n            \n            train_data = train_data_folds.reshape(train_data_folds.shape[0]*train_data_folds.shape[1],train_data_folds.shape[2])\n            train_labels = train_label_folds.flatten()\n            \n            model = sklearn.linear_model.LogisticRegression(solver='liblinear')\n\n            penalty = ['l1','l2']\n            C = [10,100,1000]\n            hyperparameters = dict(C=C,penalty=penalty)\n            \n            clf = sklearn.model_selection.GridSearchCV(model, hyperparameters, cv=3)\n            theta_hat = clf.fit(train_data,train_labels)\n            \n            mean_e_out = 1 - theta_hat.score(val_data_fold,val_label_fold)\n\n            num_1 = np.round_(mean_e_out*len(val_data_fold),2)\n            num_0 = len(val_data_fold)-num_1\n            fake_sample = []\n            for i in range(int(num_1)):\n                fake_sample.append(1)\n            for i in range(int(num_0)):\n                fake_sample.append(0)\n            var_e_out = statistics.variance(fake_sample)\n            a_list.append((np.mean(e_in) - mean_e_out)**2)\n            b_list.append(statistics.variance(fake_sample)/len(val_data_fold))\n            es.append(e_in)\n    \n\n    MSEhat = np.mean(a_list) - np.mean(b_list)\n    errhat_NCV = np.mean(es)\n    return errhat_NCV, MSEhat",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "2f7cd114"
    },
    {
      "cell_type": "code",
      "source": "import scipy.stats as st\nimport random\n\n#CREATING PLOTS WITH NCV\n\n# LINEAR CLASSIFIER\n\n#specifically works for flashes\ndef classifier_accuracy_by_trial_window_ncv_lin(flashes_presentation_table, lfp_data, window_size, end_time, time_res, reps, k, alpha):\n    classifier_accuracies_qalphadiv2 = []\n    classifier_accuracies_means = []\n    classifier_accuracies_q1minusalphadiv2 = []\n    errhat_ncv_store = []\n    errhat_cv_store = []\n        \n    \n    window_start_times = []\n    start_time = 0\n    while start_time + 1000*window_size < 1000*end_time:\n        window_start_times.append(start_time/1000)\n        start_time += 1000*window_size\n    print(window_start_times)\n    \n    model_coefficients = np.zeros((len(lfp_data.channel),int(end_time/time_res)))\n    print(\"model coefficients shape:\",model_coefficients.shape)\n\n    next_empty_column = 0\n    \n# PRODUCE ALIGNED LFPs FROM PROBE DATA\n\n    flashes_presentation_table_1 = flashes_presentation_table[flashes_presentation_table.color\n                                                                      == 1.0]\n    flashes_presentation_table_minus1 = flashes_presentation_table[flashes_presentation_table.color\n                                                                          == -1.0]\n    presentation_times_1 = flashes_presentation_table_1.start_time.values\n    presentation_ids_1 = flashes_presentation_table_1.index.values\n\n    presentation_times_minus1 = flashes_presentation_table_minus1.start_time.values\n    presentation_ids_minus1 = flashes_presentation_table_minus1.index.values\n\n    for window_start in window_start_times:\n    \n \n\n\n    #for 1\n\n\n\n        trial_window = np.arange(window_start, window_start + window_size, time_res)\n        if 1/(len(trial_window)*100) <  time_res:\n            trial_window = trial_window[:-1]\n        time_selection = np.concatenate([trial_window + t for t in presentation_times_1])\n\n        inds = pd.MultiIndex.from_product((presentation_ids_1, trial_window),\n                                      names=('presentation_id', 'time_from_presentation_onset'))\n\n        ds = lfp_data.sel(time = time_selection, method='nearest').to_dataset(name = 'aligned_lfp')\n        ds = ds.assign(time=inds).unstack('time')\n\n        aligned_lfp_1 = ds['aligned_lfp']\n\n#for -1\n\n\n\n        trial_window = np.arange(window_start, window_start + window_size, time_res)\n        if 1/(len(trial_window)*100) <  time_res:\n            trial_window = trial_window[:-1]\n        time_selection = np.concatenate([trial_window + t for t in presentation_times_minus1])\n\n        inds = pd.MultiIndex.from_product((presentation_ids_minus1, trial_window),\n                                      names=('presentation_id', 'time_from_presentation_onset'))\n\n        ds = lfp_data.sel(time = time_selection, method='nearest').to_dataset(name = 'aligned_lfp')\n        ds = ds.assign(time=inds).unstack('time')\n\n        aligned_lfp_minus1 = ds['aligned_lfp']\n\n\n# COMPUTE T SCORES AND CORRESPONDING P VALUES IN INDEPENDENT T TEST BETWEEN TRIAL CONDITIONS\n\n        tStat, pValue = stats.ttest_ind(a= aligned_lfp_minus1,\n            b = aligned_lfp_1,\n            axis = 1,\n            equal_var = False,\n            nan_policy = 'raise')\n\n# FORMAT TRIAL DATA FOR CLASSIFICATION\n\n\n        flashes_1_data = aligned_lfp_1.to_masked_array()\n        flashes_minus1_data = aligned_lfp_minus1.to_masked_array()\n        flashes_1_data.mask = np.ma.nomask\n        flashes_minus1_data.mask = np.ma.nomask\n        flashes_data_combined = np.concatenate((flashes_1_data,flashes_minus1_data),axis=1).transpose(1,0,2)\n        flashes_data_combined = flashes_data_combined.reshape(flashes_data_combined.shape[0],flashes_data_combined.shape[1] * flashes_data_combined.shape[2])\n        labels = []\n        for i in range(75):\n            labels.append(1)\n        for i in range(75,150):\n            labels.append(0)\n\n\n\n        errhat_ncv, MSEhat = nested_CV(X=flashes_data_combined, Y=labels, R=reps, K=k)\n        \n        from sklearn.model_selection import train_test_split\n        x_train, x_test, y_train, y_test = train_test_split(flashes_data_combined, labels, test_size=0.25, stratify=labels)\n        \n\n\n        errhat_cv = np.mean(standard_CV(flashes_data_combined,labels,k))\n        \n        \n        errhat_ncv_store.append(errhat_ncv)\n        errhat_cv_store.append(errhat_cv)\n        \n        biashat = (1+((k-2)/k))*(errhat_ncv-errhat_cv)\n        point_estimate = errhat_ncv - biashat\n        \n        \n        #CONSTRUCTION\n        print(\"window:\",window_start)\n        print(\"k:\",k,\"MSEhat\",MSEhat)\n        print(\"NCV error estimate:\",errhat_ncv,\"point estimate:\",point_estimate)\n        \n        #/CONSTRUCTION\n        \n        \n        interval_radius = st.norm.ppf(1-alpha/2)*math.sqrt((k-1)/k)*math.sqrt(abs(MSEhat))     \n        \n    \n#         coefficient_store = np.matrix(coefficient_store)\n#         print(coefficient_store.shape)\n#         coefficient_store = np.transpose(coefficient_store)\n#         print(coefficient_store.shape)\n#         coefficient_store = coefficient_store.mean(axis=1)\n#         print(coefficient_store.shape)\n\n\n        \n    \n\n        classifier_accuracies_qalphadiv2.append(min(1,1-(point_estimate - interval_radius)))\n        classifier_accuracies_means.append(1-point_estimate)\n        classifier_accuracies_q1minusalphadiv2.append(min(1,1-(point_estimate + interval_radius)))\n        \n    return window_start_times, classifier_accuracies_qalphadiv2, classifier_accuracies_means, classifier_accuracies_q1minusalphadiv2, errhat_ncv_store, errhat_cv_store\n\n#-----------------------------------------------------------------------------------------\n\nstarts, ci_low, classifier_accuracies, ci_hi, errhat_ncv, errhat_cv = classifier_accuracy_by_trial_window_ncv_lin(flashes_presentation_table=flashes_presentation_table,\n                                                                         lfp_data=lfp_VISp, \n                                                                         window_size=.01, \n                                                                         end_time=.5, \n                                                                         time_res=1/100, \n                                                                         reps=10, k=5,\n                                                                         alpha=.05)\nfor i in range(len(starts)):\n    print(\"Window start: {} ms      Mean Classifier Accuracy: {}\".format(math.floor(1000*starts[i]), classifier_accuracies[i]))\n    \nplt.figure(figsize=(8,6))\nim = plt.plot(starts, classifier_accuracies, label=\"mean\")\n_ = plt.fill_between(starts, ci_low, ci_hi, alpha=0.2)\n# im = plt.plot(starts, ci_low, label=\"ci low\")\n# im = plt.plot(starts, ci_hi, label=\"ci high\")\n_ = plt.xlabel('Start of time window following stimulus onset (s)')\n_ = plt.ylabel('Classifier Accuracy')\n_ = plt.title('Logistic regression classifer accuracy with 95% CI from NCV')\n_ = plt.legend()\n\n# plt.figure(figsize=(8,6))\n# im = plt.plot(starts, errhat_ncv, label=\"mean\")\n# _ = plt.xlabel('Start of time window following stimulus onset (s)')\n# _ = plt.ylabel('Classifier Accuracy')\n# _ = plt.title('Bootstrapped mean linear classifer accuracy with 95% CI, trained on 10 ms sliding time windows')\n# _ = plt.legend()\n\n# plt.figure(figsize=(8,6))\n# im = plt.plot(starts, errhat_cv, label=\"mean\")\n# _ = plt.xlabel('Start of time window following stimulus onset (s)')\n# _ = plt.ylabel('Classifier Accuracy')\n# _ = plt.title('Bootstrapped mean linear classifer accuracy with 95% CI, trained on 10 ms sliding time windows')\n# _ = plt.legend()\n\n# fig = plt.figure(figsize=(8,6))\n# im2 = plt.imshow(coefficients, origin='lower', cmap='bone')\n# _ = plt.xlabel(\"Time sample after stimulus onset (by 10ms)\")\n# _ = plt.ylabel(\"Electrode index\")\n# _ = plt.title(\"Linear Classifier Coefficients\")\n# _ = plt.colorbar(im2, cax = fig.add_axes([.92, 0.33, 0.03, 0.38]))",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "57f1801a"
    },
    {
      "cell_type": "code",
      "source": "st.norm.ppf(.975)\nstatistics.variance([1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0])\n",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "f297c401"
    },
    {
      "cell_type": "code",
      "source": "# COMBINED THALAMUS AND V1\n# LINEAR CLASSIFIER\n\n#specifically works for flashes\ndef classifier_accuracy_by_trial_window_boot_lin_v1_th(flashes_presentation_table, lfp_data_v1, lfp_data_th, window_size, end_time, time_res, num_bootstrap_iterations, alpha):\n    classifier_accuracies_qalphadiv2 = []\n    classifier_accuracies_means = []\n    classifier_accuracies_q1minusalphadiv2 = []\n    \n    window_start_times = []\n    start_time = 0\n    while start_time + 1000*window_size < 1000*end_time:\n        window_start_times.append(start_time/1000)\n        start_time += 1000*window_size\n    print(window_start_times)\n    \n    model_coefficients = np.zeros((len(lfp_data_v1.channel),int(end_time/time_res)))\n    print(\"model coefficients shape:\",model_coefficients.shape)\n\n    next_empty_column = 0\n    \n# PRODUCE ALIGNED LFPs FROM PROBE DATA\n\n    flashes_presentation_table_1 = flashes_presentation_table[flashes_presentation_table.color\n                                                                      == 1.0]\n    flashes_presentation_table_minus1 = flashes_presentation_table[flashes_presentation_table.color\n                                                                          == -1.0]\n    presentation_times_1 = flashes_presentation_table_1.start_time.values\n    presentation_ids_1 = flashes_presentation_table_1.index.values\n\n    presentation_times_minus1 = flashes_presentation_table_minus1.start_time.values\n    presentation_ids_minus1 = flashes_presentation_table_minus1.index.values\n\n    for window_start in window_start_times:\n    \n \n    #V1\n\n    #for 1\n\n\n\n        trial_window = np.arange(window_start, window_start + window_size, time_res)\n        if 1/(len(trial_window)*100) <  time_res:\n            trial_window = trial_window[:-1]\n        time_selection = np.concatenate([trial_window + t for t in presentation_times_1])\n\n        inds = pd.MultiIndex.from_product((presentation_ids_1, trial_window),\n                                      names=('presentation_id', 'time_from_presentation_onset'))\n\n        ds = lfp_data_v1.sel(time = time_selection, method='nearest').to_dataset(name = 'aligned_lfp')\n        ds = ds.assign(time=inds).unstack('time')\n\n        aligned_lfp_1_v1 = ds['aligned_lfp']\n\n#for -1\n\n\n\n        trial_window = np.arange(window_start, window_start + window_size, time_res)\n        if 1/(len(trial_window)*100) <  time_res:\n            trial_window = trial_window[:-1]\n        time_selection = np.concatenate([trial_window + t for t in presentation_times_minus1])\n\n        inds = pd.MultiIndex.from_product((presentation_ids_minus1, trial_window),\n                                      names=('presentation_id', 'time_from_presentation_onset'))\n\n        ds = lfp_data_v1.sel(time = time_selection, method='nearest').to_dataset(name = 'aligned_lfp')\n        ds = ds.assign(time=inds).unstack('time')\n\n        aligned_lfp_minus1_v1 = ds['aligned_lfp']\n        \n        \n        #thalamus\n        \n            #for 1\n\n\n\n        trial_window = np.arange(window_start, window_start + window_size, time_res)\n        if 1/(len(trial_window)*100) <  time_res:\n            trial_window = trial_window[:-1]\n        time_selection = np.concatenate([trial_window + t for t in presentation_times_1])\n\n        inds = pd.MultiIndex.from_product((presentation_ids_1, trial_window),\n                                      names=('presentation_id', 'time_from_presentation_onset'))\n\n        ds = lfp_data_th.sel(time = time_selection, method='nearest').to_dataset(name = 'aligned_lfp')\n        ds = ds.assign(time=inds).unstack('time')\n\n        aligned_lfp_1_th = ds['aligned_lfp']\n\n#for -1\n\n\n\n        trial_window = np.arange(window_start, window_start + window_size, time_res)\n        if 1/(len(trial_window)*100) <  time_res:\n            trial_window = trial_window[:-1]\n        time_selection = np.concatenate([trial_window + t for t in presentation_times_minus1])\n\n        inds = pd.MultiIndex.from_product((presentation_ids_minus1, trial_window),\n                                      names=('presentation_id', 'time_from_presentation_onset'))\n\n        ds = lfp_data_th.sel(time = time_selection, method='nearest').to_dataset(name = 'aligned_lfp')\n        ds = ds.assign(time=inds).unstack('time')\n\n        aligned_lfp_minus1_th = ds['aligned_lfp']\n        \n        \n\n\n# COMPUTE T SCORES AND CORRESPONDING P VALUES IN INDEPENDENT T TEST BETWEEN TRIAL CONDITIONS\n\n#         tStat, pValue = stats.ttest_ind(a= aligned_lfp_minus1,\n#             b = aligned_lfp_1,\n#             axis = 1,\n#             equal_var = False,\n#             nan_policy = 'raise')\n\n# FORMAT TRIAL DATA FOR CLASSIFICATION\n\n\n        flashes_1_data_v1 = aligned_lfp_1_v1.to_masked_array()\n        flashes_minus1_data_v1 = aligned_lfp_minus1_v1.to_masked_array()\n        flashes_1_data_v1.mask = np.ma.nomask\n        flashes_minus1_data_v1.mask = np.ma.nomask\n        flashes_data_combined_v1 = np.concatenate((flashes_1_data_v1,flashes_minus1_data_v1),axis=1).transpose(1,0,2)\n        flashes_data_combined_v1 = flashes_data_combined_v1.reshape(flashes_data_combined_v1.shape[0],flashes_data_combined_v1.shape[1] * flashes_data_combined_v1.shape[2])\n        \n        flashes_1_data_th = aligned_lfp_1_th.to_masked_array()\n        flashes_minus1_data_th = aligned_lfp_minus1_th.to_masked_array()\n        flashes_1_data_th.mask = np.ma.nomask\n        flashes_minus1_data_th.mask = np.ma.nomask\n        flashes_data_combined_th = np.concatenate((flashes_1_data_th,flashes_minus1_data_th),axis=1).transpose(1,0,2)\n        flashes_data_combined_th = flashes_data_combined_th.reshape(flashes_data_combined_th.shape[0],flashes_data_combined_th.shape[1] * flashes_data_combined_th.shape[2])\n\n        flashes_data_combined = np.concatenate((flashes_data_combined_v1,flashes_data_combined_th),axis=1)\n        \n        labels = []\n        for i in range(75):\n            labels.append(1)\n        for i in range(75,150):\n            labels.append(0)\n\n\n    # PERFORM MANY CLASSIFICATIONS ON BOOTSTRAPPED SAMPLES\n\n        window_classifier_accuracies = []\n        coefficient_store = []\n        \n        for i in range(num_bootstrap_iterations):\n                       \n            bootstrapped_sample = []\n            bootstrapped_labels = []\n            \n            while len(bootstrapped_sample) < len(flashes_data_combined):\n                rand_ind = np.random.choice(range(len(flashes_data_combined)))\n                bootstrapped_sample.append(flashes_data_combined[rand_ind])\n                bootstrapped_labels.append(labels[rand_ind])\n\n\n            from sklearn.model_selection import train_test_split\n            x_train, x_test, y_train, y_test = train_test_split(flashes_data_combined, labels, test_size=0.25, stratify=labels)\n\n        # TUNE HYPERPARAMETERS USING CROSS-VALIDATION\n\n            model = sklearn.linear_model.LogisticRegression(solver='liblinear')\n\n            penalty = ['l1','l2']\n            C = [10,100,1000]\n            hyperparameters = dict(C=C,penalty=penalty)\n            \n            clf = sklearn.model_selection.GridSearchCV(model, hyperparameters, cv=3)\n            best_model = clf.fit(x_train,y_train)\n            \n            \n        # EXTRACT MODEL COEFFICIENTS FOR VISUALIZATION  \n            \n#             coefficient_store.append(best_model.best_estimator_.coef_[0])\n\n\n\n# TESTING\n\n            window_classifier_accuracies.append(best_model.score(x_test,y_test))\n    \n#         coefficient_store = np.matrix(coefficient_store)\n#         print(coefficient_store.shape)\n#         coefficient_store = np.transpose(coefficient_store)\n#         print(coefficient_store.shape)\n#         coefficient_store = coefficient_store.mean(axis=1)\n#         print(coefficient_store.shape)\n\n        for i in range(len(coefficient_store)):\n            print(i)\n#             model_coefficients[i,next_empty_column] = coefficient_store[i]\n        next_empty_column += 1\n        \n    \n        window_classifier_accuracies = sorted(window_classifier_accuracies)\n        classifier_accuracies_qalphadiv2.append(window_classifier_accuracies[math.floor(len(window_classifier_accuracies)*alpha/2)])\n        classifier_accuracies_means.append(np.mean(window_classifier_accuracies))\n        classifier_accuracies_q1minusalphadiv2.append(window_classifier_accuracies[math.ceil((1-alpha/2)*len(window_classifier_accuracies))])\n        \n    return window_start_times, classifier_accuracies_qalphadiv2, classifier_accuracies_means, classifier_accuracies_q1minusalphadiv2, model_coefficients\n\n#-----------------------------------------------------------------------------------------\n\nstarts, ci_low, classifier_accuracies, ci_hi, coefficients = classifier_accuracy_by_trial_window_boot_lin_v1_th(flashes_presentation_table=flashes_presentation_table,\n                                                                         lfp_data_v1=lfp_VISp, lfp_data_th=lfp_thalamus,\n                                                                         window_size=.01, \n                                                                         end_time=.5, \n                                                                         time_res=1/100, \n                                                                         num_bootstrap_iterations=100, \n                                                                         alpha=.05)\nfor i in range(len(starts)):\n    print(\"Window start: {} ms      Mean Classifier Accuracy: {}\".format(math.floor(1000*starts[i]), classifier_accuracies[i]))\n    \nplt.figure(figsize=(8,6))\nim = plt.plot(starts, classifier_accuracies, label=\"mean\")\n_ = plt.fill_between(starts, ci_low, ci_hi, alpha=0.2)\n# im = plt.plot(starts, ci_low, label=\"ci low\")\n# im = plt.plot(starts, ci_hi, label=\"ci high\")\n_ = plt.xlabel('Start of time window following stimulus onset (s)')\n_ = plt.ylabel('Classifier Accuracy')\n_ = plt.title('Bootstrapped mean linear classifer accuracy with 95% CI, trained on 10 ms sliding time windows')\n_ = plt.legend()\n\nfig = plt.figure(figsize=(8,6))\nim2 = plt.imshow(coefficients, origin='lower', cmap='bone')\n_ = plt.xlabel(\"Time sample after stimulus onset (by 10ms)\")\n_ = plt.ylabel(\"Electrode index\")\n_ = plt.title(\"Linear Classifier Coefficients\")\n_ = plt.colorbar(im2, cax = fig.add_axes([.92, 0.33, 0.03, 0.38]))",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "e7d7d172"
    },
    {
      "cell_type": "code",
      "source": "# RF\nimport sklearn.ensemble\n#specifically works for flashes\ndef classifier_accuracy_by_trial_window_boot_rf(flashes_presentation_table, lfp_data, window_size, end_time, time_res, num_bootstrap_iterations, alpha):\n    classifier_accuracies_qalphadiv2 = []\n    classifier_accuracies_means = []\n    classifier_accuracies_q1minusalphadiv2 = []\n    \n    window_start_times = []\n    start_time = 0\n    while start_time + 1000*window_size < 1000*end_time:\n        window_start_times.append(start_time/1000)\n        start_time += 1000*window_size\n    \n    \n# PRODUCE ALIGNED LFPs FROM PROBE DATA\n\n    flashes_presentation_table_1 = flashes_presentation_table[flashes_presentation_table.color\n                                                                      == 1.0]\n    flashes_presentation_table_minus1 = flashes_presentation_table[flashes_presentation_table.color\n                                                                          == -1.0]\n    presentation_times_1 = flashes_presentation_table_1.start_time.values\n    presentation_ids_1 = flashes_presentation_table_1.index.values\n\n    presentation_times_minus1 = flashes_presentation_table_minus1.start_time.values\n    presentation_ids_minus1 = flashes_presentation_table_minus1.index.values\n\n    for window_start in window_start_times:\n        print(window_start)\n    \n \n\n\n    #for 1\n\n\n\n        trial_window = np.arange(window_start, window_start + window_size, time_res)\n        time_selection = np.concatenate([trial_window + t for t in presentation_times_1])\n\n        inds = pd.MultiIndex.from_product((presentation_ids_1, trial_window),\n                                      names=('presentation_id', 'time_from_presentation_onset'))\n\n        ds = lfp_data.sel(time = time_selection, method='nearest').to_dataset(name = 'aligned_lfp')\n        ds = ds.assign(time=inds).unstack('time')\n\n        aligned_lfp_1 = ds['aligned_lfp']\n\n#for -1\n\n\n\n        trial_window = np.arange(window_start, window_start + window_size, time_res)\n        time_selection = np.concatenate([trial_window + t for t in presentation_times_minus1])\n\n        inds = pd.MultiIndex.from_product((presentation_ids_minus1, trial_window),\n                                      names=('presentation_id', 'time_from_presentation_onset'))\n\n        ds = lfp_data.sel(time = time_selection, method='nearest').to_dataset(name = 'aligned_lfp')\n        ds = ds.assign(time=inds).unstack('time')\n\n        aligned_lfp_minus1 = ds['aligned_lfp']\n\n\n# COMPUTE T SCORES AND CORRESPONDING P VALUES IN INDEPENDENT T TEST BETWEEN TRIAL CONDITIONS\n\n        tStat, pValue = stats.ttest_ind(a= aligned_lfp_minus1,\n            b = aligned_lfp_1,\n            axis = 1,\n            equal_var = False,\n            nan_policy = 'raise')\n\n# FORMAT TRIAL DATA FOR CLASSIFICATION\n\n\n        flashes_1_data = aligned_lfp_1.to_masked_array()\n        flashes_minus1_data = aligned_lfp_minus1.to_masked_array()\n        flashes_1_data.mask = np.ma.nomask\n        flashes_minus1_data.mask = np.ma.nomask\n        flashes_data_combined = np.concatenate((flashes_1_data,flashes_minus1_data),axis=1).transpose(1,0,2)\n        flashes_data_combined = flashes_data_combined.reshape(flashes_data_combined.shape[0],flashes_data_combined.shape[1] * flashes_data_combined.shape[2])\n        labels = []\n        for i in range(75):\n            labels.append(1)\n        for i in range(75,150):\n            labels.append(0)\n\n\n    # PERFORM MANY CLASSIFICATIONS ON BOOTSTRAPPED SAMPLES\n\n        window_classifier_accuracies = []\n        \n        for i in range(num_bootstrap_iterations):\n                       \n            bootstrapped_sample = []\n            bootstrapped_labels = []\n            \n            while len(bootstrapped_sample) < len(flashes_data_combined):\n                rand_ind = np.random.choice(range(len(flashes_data_combined)))\n                bootstrapped_sample.append(flashes_data_combined[rand_ind])\n                bootstrapped_labels.append(labels[rand_ind])\n\n\n            from sklearn.model_selection import train_test_split\n            x_train, x_test, y_train, y_test = train_test_split(flashes_data_combined, labels, test_size=0.25, stratify=labels)\n\n        # TUNE HYPERPARAMETERS USING CROSS-VALIDATION\n\n            model = sklearn.ensemble.RandomForestClassifier(bootstrap = False)\n\n            criterion = ['gini','entropy']\n           \n            hyperparameters = dict(criterion = criterion)\n\n            clf = sklearn.model_selection.GridSearchCV(model, hyperparameters, cv=3)\n            best_model = clf.fit(x_train,y_train)\n\n\n\n# TESTING\n\n            window_classifier_accuracies.append(best_model.score(x_test,y_test))\n        window_classifier_accuracies = sorted(window_classifier_accuracies)\n        classifier_accuracies_qalphadiv2.append(window_classifier_accuracies[math.floor(len(window_classifier_accuracies)*alpha/2)])\n        classifier_accuracies_means.append(np.mean(window_classifier_accuracies))\n        classifier_accuracies_q1minusalphadiv2.append(window_classifier_accuracies[math.ceil((1-alpha/2)*len(window_classifier_accuracies))])\n        \n    return window_start_times, classifier_accuracies_qalphadiv2, classifier_accuracies_means, classifier_accuracies_q1minusalphadiv2\n\n#-----------------------------------------------------------------------------------------\n\nstarts, ci_low, classifier_accuracies, ci_hi = classifier_accuracy_by_trial_window_boot_rf(flashes_presentation_table=flashes_presentation_table,\n                                                                         lfp_data=lfp_VISp, \n                                                                         window_size=.01, \n                                                                         end_time=.5, \n                                                                         time_res=1/100, \n                                                                         num_bootstrap_iterations=100, \n                                                                         alpha=.05)\nfor i in range(len(starts)):\n    print(\"Window start: {} ms      Mean Classifier Accuracy: {}\".format(math.floor(1000*starts[i]), classifier_accuracies[i]))\n    \nplt.figure(figsize=(8,6))\nim = plt.plot(starts, classifier_accuracies, label=\"mean\")\n_ = plt.fill_between(starts, ci_low, ci_hi, alpha=0.2)\n# im = plt.plot(starts, ci_low, label=\"ci low\")\n# im = plt.plot(starts, ci_hi, label=\"ci high\")\n_ = plt.xlabel('Window End (s)')\n_ = plt.ylabel('Classifier Accuracy')\n_ = plt.legend()",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "741dfac9"
    },
    {
      "cell_type": "code",
      "source": "# SVC\n\n#specifically works for flashes\ndef classifier_accuracy_by_trial_window_boot_svc(flashes_presentation_table, lfp_data, window_size, end_time, time_res, num_bootstrap_iterations, alpha):\n    classifier_accuracies_qalphadiv2 = []\n    classifier_accuracies_means = []\n    classifier_accuracies_q1minusalphadiv2 = []\n    \n    window_start_times = []\n    start_time = 0\n\n    while start_time + 1000*window_size < 1000*end_time:\n        window_start_times.append(start_time/1000)\n        start_time += 1000*window_size\n    \n    \n# PRODUCE ALIGNED LFPs FROM PROBE DATA\n\n    flashes_presentation_table_1 = flashes_presentation_table[flashes_presentation_table.color\n                                                                      == 1.0]\n    flashes_presentation_table_minus1 = flashes_presentation_table[flashes_presentation_table.color\n                                                                          == -1.0]\n    presentation_times_1 = flashes_presentation_table_1.start_time.values\n    presentation_ids_1 = flashes_presentation_table_1.index.values\n\n    presentation_times_minus1 = flashes_presentation_table_minus1.start_time.values\n    presentation_ids_minus1 = flashes_presentation_table_minus1.index.values\n\n    for window_start in window_start_times:\n    \n \n\n\n#for 1\n\n\n\n        trial_window = np.arange(window_start, window_start + window_size, time_res)\n        if 1/(len(trial_window)*100) <  time_res:\n            trial_window = trial_window[:-1]\n        time_selection = np.concatenate([trial_window + t for t in presentation_times_1])\n\n        inds = pd.MultiIndex.from_product((presentation_ids_1, trial_window),\n                                      names=('presentation_id', 'time_from_presentation_onset'))\n\n        ds = lfp_data.sel(time = time_selection, method='nearest').to_dataset(name = 'aligned_lfp')\n        ds = ds.assign(time=inds).unstack('time')\n\n        aligned_lfp_1 = ds['aligned_lfp']\n\n#for -1\n\n\n\n        trial_window = np.arange(window_start, window_start + window_size, time_res)\n        if 1/(len(trial_window)*100) <  time_res:\n            trial_window = trial_window[:-1]\n        time_selection = np.concatenate([trial_window + t for t in presentation_times_minus1])\n\n        inds = pd.MultiIndex.from_product((presentation_ids_minus1, trial_window),\n                                      names=('presentation_id', 'time_from_presentation_onset'))\n\n        ds = lfp_data.sel(time = time_selection, method='nearest').to_dataset(name = 'aligned_lfp')\n        ds = ds.assign(time=inds).unstack('time')\n\n        aligned_lfp_minus1 = ds['aligned_lfp']\n\n\n# COMPUTE T SCORES AND CORRESPONDING P VALUES IN INDEPENDENT T TEST BETWEEN TRIAL CONDITIONS\n\n        tStat, pValue = stats.ttest_ind(a= aligned_lfp_minus1,\n            b = aligned_lfp_1,\n            axis = 1,\n            equal_var = False,\n            nan_policy = 'raise')\n\n# FORMAT TRIAL DATA FOR CLASSIFICATION\n\n\n        flashes_1_data = aligned_lfp_1.to_masked_array()\n        flashes_minus1_data = aligned_lfp_minus1.to_masked_array()\n        flashes_1_data.mask = np.ma.nomask\n        flashes_minus1_data.mask = np.ma.nomask\n        flashes_data_combined = np.concatenate((flashes_1_data,flashes_minus1_data),axis=1).transpose(1,0,2)\n        flashes_data_combined = flashes_data_combined.reshape(flashes_data_combined.shape[0],flashes_data_combined.shape[1] * flashes_data_combined.shape[2])\n        labels = []\n        for i in range(75):\n            labels.append(1)\n        for i in range(75,150):\n            labels.append(0)\n\n\n    # PERFORM MANY CLASSIFICATIONS ON BOOTSTRAPPED SAMPLES\n\n        window_classifier_accuracies = []\n        \n        for i in range(num_bootstrap_iterations):\n                       \n            bootstrapped_sample = []\n            bootstrapped_labels = []\n            \n            while len(bootstrapped_sample) < len(flashes_data_combined):\n                rand_ind = np.random.choice(range(len(flashes_data_combined)))\n                bootstrapped_sample.append(flashes_data_combined[rand_ind])\n                bootstrapped_labels.append(labels[rand_ind])\n\n\n            from sklearn.model_selection import train_test_split\n            x_train, x_test, y_train, y_test = train_test_split(flashes_data_combined, labels, test_size=0.25, stratify=labels)\n\n        # TUNE HYPERPARAMETERS USING CROSS-VALIDATION\n\n            model = sklearn.svm.SVC()\n\n            kernel = ['linear', 'poly', 'rbf', 'sigmoid']\n            C = [10,100,1000]\n            hyperparameters = dict(C=C,kernel=kernel)\n\n            clf = sklearn.model_selection.GridSearchCV(model, hyperparameters, cv=3)\n            print(clf.best_params_)\n            best_model = clf.fit(x_train,y_train)\n\n\n\n# TESTING\n\n            window_classifier_accuracies.append(best_model.score(x_test,y_test))\n        window_classifier_accuracies = sorted(window_classifier_accuracies)\n        classifier_accuracies_qalphadiv2.append(window_classifier_accuracies[math.floor(len(window_classifier_accuracies)*alpha/2)])\n        classifier_accuracies_means.append(np.mean(window_classifier_accuracies))\n        classifier_accuracies_q1minusalphadiv2.append(window_classifier_accuracies[math.ceil((1-alpha/2)*len(window_classifier_accuracies))])\n        \n    return window_start_times, classifier_accuracies_qalphadiv2, classifier_accuracies_means, classifier_accuracies_q1minusalphadiv2\n\n#-----------------------------------------------------------------------------------------\n\nstarts, ci_low, classifier_accuracies, ci_hi = classifier_accuracy_by_trial_window_boot_svc(flashes_presentation_table=flashes_presentation_table,\n                                                                         lfp_data=lfp_VISp, \n                                                                         window_size=.01, \n                                                                         end_time=.5, \n                                                                         time_res=1/100, \n                                                                         num_bootstrap_iterations=100, \n                                                                         alpha=.05)\nfor i in range(len(starts)):\n    print(\"Window start: {} ms      Mean Classifier Accuracy: {}\".format(math.floor(1000*starts[i]), classifier_accuracies[i]))\n    \nplt.figure(figsize=(8,6))\nim = plt.plot(starts, classifier_accuracies, label=\"mean\")\n_ = plt.fill_between(starts, ci_low, ci_hi, alpha=0.2)\n# im = plt.plot(starts, ci_low, label=\"ci low\")\n# im = plt.plot(starts, ci_hi, label=\"ci high\")\n_ = plt.xlabel('Window End (s)')\n_ = plt.ylabel('Classifier Accuracy')\n_ = plt.legend()",
      "metadata": {
        "scrolled": true
      },
      "execution_count": null,
      "outputs": [],
      "id": "41236012"
    },
    {
      "cell_type": "code",
      "source": "print(classifier_accuracies)",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "b6478276"
    },
    {
      "cell_type": "code",
      "source": "print(coefficients)",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "aa1388ae"
    },
    {
      "cell_type": "code",
      "source": "# LINEAR CLASSIFIER\n\n#specifically works for flashes\ndef classifier_accuracy_by_trial_window_boot_lin(flashes_presentation_table, lfp_data, window_size, end_time, time_res, num_bootstrap_iterations, alpha):\n    classifier_accuracies_qalphadiv2 = []\n    classifier_accuracies_means = []\n    classifier_accuracies_q1minusalphadiv2 = []\n    \n    window_start_times = []\n    start_time = 0\n    while start_time + 1000*window_size < 1000*end_time:\n        window_start_times.append(start_time/1000)\n        start_time += 1000*window_size\n    print(window_start_times)\n    \n    model_coefficients = np.zeros((len(lfp_data.channel),int(end_time/time_res)))\n    print(\"model coefficients shape:\",model_coefficients.shape)\n\n    next_empty_column = 0\n    \n# PRODUCE ALIGNED LFPs FROM PROBE DATA\n\n    flashes_presentation_table_1 = flashes_presentation_table[flashes_presentation_table.color\n                                                                      == 1.0]\n    flashes_presentation_table_minus1 = flashes_presentation_table[flashes_presentation_table.color\n                                                                          == -1.0]\n    presentation_times_1 = flashes_presentation_table_1.start_time.values\n    presentation_ids_1 = flashes_presentation_table_1.index.values\n\n    presentation_times_minus1 = flashes_presentation_table_minus1.start_time.values\n    presentation_ids_minus1 = flashes_presentation_table_minus1.index.values\n\n    for window_start in window_start_times:\n    \n \n\n\n    #for 1\n\n\n\n        trial_window = np.arange(window_start, window_start + window_size, time_res)\n        if 1/(len(trial_window)*100) <  time_res:\n            trial_window = trial_window[:-1]\n        time_selection = np.concatenate([trial_window + t for t in presentation_times_1])\n\n        inds = pd.MultiIndex.from_product((presentation_ids_1, trial_window),\n                                      names=('presentation_id', 'time_from_presentation_onset'))\n\n        ds = lfp_data.sel(time = time_selection, method='nearest').to_dataset(name = 'aligned_lfp')\n        ds = ds.assign(time=inds).unstack('time')\n\n        aligned_lfp_1 = ds['aligned_lfp']\n\n#for -1\n\n\n\n        trial_window = np.arange(window_start, window_start + window_size, time_res)\n        if 1/(len(trial_window)*100) <  time_res:\n            trial_window = trial_window[:-1]\n        time_selection = np.concatenate([trial_window + t for t in presentation_times_minus1])\n\n        inds = pd.MultiIndex.from_product((presentation_ids_minus1, trial_window),\n                                      names=('presentation_id', 'time_from_presentation_onset'))\n\n        ds = lfp_data.sel(time = time_selection, method='nearest').to_dataset(name = 'aligned_lfp')\n        ds = ds.assign(time=inds).unstack('time')\n\n        aligned_lfp_minus1 = ds['aligned_lfp']\n\n\n# COMPUTE T SCORES AND CORRESPONDING P VALUES IN INDEPENDENT T TEST BETWEEN TRIAL CONDITIONS\n\n        tStat, pValue = stats.ttest_ind(a= aligned_lfp_minus1,\n            b = aligned_lfp_1,\n            axis = 1,\n            equal_var = False,\n            nan_policy = 'raise')\n\n# FORMAT TRIAL DATA FOR CLASSIFICATION\n\n\n        flashes_1_data = aligned_lfp_1.to_masked_array()\n        flashes_minus1_data = aligned_lfp_minus1.to_masked_array()\n        flashes_1_data.mask = np.ma.nomask\n        flashes_minus1_data.mask = np.ma.nomask\n        flashes_data_combined = np.concatenate((flashes_1_data,flashes_minus1_data),axis=1).transpose(1,0,2)\n        flashes_data_combined = flashes_data_combined.reshape(flashes_data_combined.shape[0],flashes_data_combined.shape[1] * flashes_data_combined.shape[2])\n        labels = []\n        for i in range(75):\n            labels.append(1)\n        for i in range(75,150):\n            labels.append(0)\n\n\n    # PERFORM MANY CLASSIFICATIONS ON BOOTSTRAPPED SAMPLES\n\n        window_classifier_accuracies = []\n        coefficient_store = []\n        \n        for i in range(num_bootstrap_iterations):\n                       \n            bootstrapped_sample = []\n            bootstrapped_labels = []\n            \n            while len(bootstrapped_sample) < len(flashes_data_combined):\n                rand_ind = np.random.choice(range(len(flashes_data_combined)))\n                bootstrapped_sample.append(flashes_data_combined[rand_ind])\n                bootstrapped_labels.append(labels[rand_ind])\n\n\n            from sklearn.model_selection import train_test_split\n            x_train, x_test, y_train, y_test = train_test_split(flashes_data_combined, labels, test_size=0.25, stratify=labels)\n\n        # TUNE HYPERPARAMETERS USING CROSS-VALIDATION\n\n            model = sklearn.linear_model.LogisticRegression(solver='liblinear', penalty='l2')\n\n#             penalty = ['l1','l2']\n            C = [10,100,1000]\n            hyperparameters = dict(C=C)\n            \n            clf = sklearn.model_selection.GridSearchCV(model, hyperparameters, cv=3)\n            best_model = clf.fit(x_train,y_train)\n            \n            \n        # EXTRACT MODEL COEFFICIENTS FOR VISUALIZATION  \n            \n            coefficient_store.append(best_model.best_estimator_.coef_[0])\n\n\n\n# TESTING\n\n            window_classifier_accuracies.append(best_model.score(x_test,y_test))\n    \n        coefficient_store = np.matrix(coefficient_store)\n        print(coefficient_store.shape)\n        coefficient_store = np.transpose(coefficient_store)\n        print(coefficient_store.shape)\n        coefficient_store = coefficient_store.mean(axis=1)\n        print(coefficient_store.shape)\n\n        for i in range(len(coefficient_store)):\n            print(i)\n            model_coefficients[i,next_empty_column] = coefficient_store[i]\n        next_empty_column += 1\n        \n    \n        window_classifier_accuracies = sorted(window_classifier_accuracies)\n        classifier_accuracies_qalphadiv2.append(window_classifier_accuracies[math.floor(len(window_classifier_accuracies)*alpha/2)])\n        classifier_accuracies_means.append(np.mean(window_classifier_accuracies))\n        classifier_accuracies_q1minusalphadiv2.append(window_classifier_accuracies[math.ceil((1-alpha/2)*len(window_classifier_accuracies))])\n        \n    return window_start_times, classifier_accuracies_qalphadiv2, classifier_accuracies_means, classifier_accuracies_q1minusalphadiv2, model_coefficients\n\n#-----------------------------------------------------------------------------------------\n\nstarts, ci_low, classifier_accuracies, ci_hi, coefficients = classifier_accuracy_by_trial_window_boot_lin(flashes_presentation_table=flashes_presentation_table,\n                                                                         lfp_data=lfp_VISp, \n                                                                         window_size=.01, \n                                                                         end_time=.5, \n                                                                         time_res=1/100, \n                                                                         num_bootstrap_iterations=100, \n                                                                         alpha=.05)\nfor i in range(len(starts)):\n    print(\"Window start: {} ms      Mean Classifier Accuracy: {}\".format(math.floor(1000*starts[i]), classifier_accuracies[i]))\n    \nplt.figure(figsize=(8,6))\nim = plt.plot(starts, classifier_accuracies, label=\"mean\")\n_ = plt.fill_between(starts, ci_low, ci_hi, alpha=0.2)\n# im = plt.plot(starts, ci_low, label=\"ci low\")\n# im = plt.plot(starts, ci_hi, label=\"ci high\")\n_ = plt.xlabel('Start of time window following stimulus onset (s)')\n_ = plt.ylabel('Classifier Accuracy')\n_ = plt.title('Bootstrapped mean linear classifer accuracy with 95% CI, trained on 10 ms sliding time windows')\n_ = plt.legend()\n\nfig = plt.figure(figsize=(8,6))\nim2 = plt.imshow(coefficients, origin='lower', cmap='bone')\n_ = plt.xlabel(\"Time sample after stimulus onset (by 10ms)\")\n_ = plt.ylabel(\"Electrode index\")\n_ = plt.title(\"Linear Classifier Coefficients\")\n_ = plt.colorbar(im2, cax = fig.add_axes([.92, 0.33, 0.03, 0.38]))",
      "metadata": {
        "scrolled": true
      },
      "execution_count": null,
      "outputs": [],
      "id": "70612eaf"
    },
    {
      "cell_type": "code",
      "source": "#specifically works for flashes\ndef classifier_accuracy_by_trial_window_boot_mod(flashes_presentation_table, lfp_data, window_size, end_time, time_res, num_bootstrap_iterations, alpha):\n    classifier_accuracies_qalphadiv2 = []\n    classifier_accuracies_means = []\n    classifier_accuracies_q1minusalphadiv2 = []\n    \n    window_start_times = []\n    start_time = 0\n    while start_time + window_size < end_time:\n        window_start_times.append(start_time)\n        start_time += window_size\n    \n    \n# PRODUCE ALIGNED LFPs FROM PROBE DATA\n    flashes_presentation_table_1 = flashes_presentation_table[flashes_presentation_table.color \n                                                                          == 1.0]\n    flashes_presentation_table_minus1 = flashes_presentation_table[flashes_presentation_table.color \n                                                                              == -1.0]\n    presentation_times_1 = flashes_presentation_table_1.start_time.values\n    presentation_ids_1 = flashes_presentation_table_1.index.values\n    \n    presentation_times_minus1 = flashes_presentation_table_minus1.start_time.values\n    presentation_ids_minus1 = flashes_presentation_table_minus1.index.values\n    \n    for window_start in window_start_times:\n    \n     \n\n\n        #for 1\n\n\n\n        trial_window = np.arange(window_start, window_start + window_size, time_res)\n        time_selection = np.concatenate([trial_window + t for t in presentation_times_1])\n\n        inds = pd.MultiIndex.from_product((presentation_ids_1, trial_window), \n                                          names=('presentation_id', 'time_from_presentation_onset'))\n\n        ds = lfp_data.sel(time = time_selection, method='nearest').to_dataset(name = 'aligned_lfp')\n        ds = ds.assign(time=inds).unstack('time')\n\n        aligned_lfp_1 = ds['aligned_lfp']\n\n        #for -1\n\n       \n\n        trial_window = np.arange(window_start, window_start + window_size, time_res)\n        time_selection = np.concatenate([trial_window + t for t in presentation_times_minus1])\n\n        inds = pd.MultiIndex.from_product((presentation_ids_minus1, trial_window), \n                                          names=('presentation_id', 'time_from_presentation_onset'))\n\n        ds = lfp_data.sel(time = time_selection, method='nearest').to_dataset(name = 'aligned_lfp')\n        ds = ds.assign(time=inds).unstack('time')\n\n        aligned_lfp_minus1 = ds['aligned_lfp']\n        \n        \n        # COMPUTE T SCORES AND CORRESPONDING P VALUES IN INDEPENDENT T TEST BETWEEN TRIAL CONDITIONS\n        \n        tStat, pValue = stats.ttest_ind(a= aligned_lfp_minus1,\n               b = aligned_lfp_1,\n               axis = 1,\n               equal_var = False,\n               nan_policy = 'raise')\n        \n        # FORMAT TRIAL DATA FOR CLASSIFICATION\n        \n        \n        flashes_1_data = aligned_lfp_1.to_masked_array()\n        flashes_minus1_data = aligned_lfp_minus1.to_masked_array()\n        flashes_1_data.mask = np.ma.nomask\n        flashes_minus1_data.mask = np.ma.nomask\n        flashes_data_combined = np.concatenate((flashes_1_data,flashes_minus1_data),axis=1).transpose(1,0,2)\n        flashes_data_combined = flashes_data_combined.reshape(flashes_data_combined.shape[0],flashes_data_combined.shape[1] * flashes_data_combined.shape[2])\n        labels = []\n        for i in range(75):\n            labels.append(1)\n        for i in range(75,150):\n            labels.append(0)\n            \n\n        # PERFORM MANY CLASSIFICATIONS ON BOOTSTRAPPED SAMPLES\n        \n        window_classifier_accuracies = []\n               \n            \n        from sklearn.model_selection import train_test_split\n        x_train, x_test, y_train, y_test = train_test_split(flashes_data_combined, labels, test_size=0.25, stratify=labels)\n\n        # TUNE HYPERPARAMETERS USING CROSS-VALIDATION\n        \n        model = sklearn.linear_model.LogisticRegression(solver='saga')\n\n        penalty = ['l1','l2']\n        C = np.logspace(10,1000)\n        hyperparameters = dict(C=C,penalty=penalty)\n        \n        clf = sklearn.model_selection.GridSearchCV(model, hyperparameters, cv=5)\n        best_model = clf.fit(x_train,y_train)\n        \n        print(clf)\n\n        # TESTING\n\n        window_classifier_accuracies.append(best_model.score(x_test,y_test))\n        window_classifier_accuracies = sorted(window_classifier_accuracies)\n#         classifier_accuracies_qalphadiv2.append(window_classifier_accuracies[math.floor(len(window_classifier_accuracies)*alpha/2)])\n        classifier_accuracies_means.append(np.mean(window_classifier_accuracies))\n#         classifier_accuracies_q1minusalphadiv2.append(window_classifier_accuracies[math.ceil((1-alpha/2)*len(window_classifier_accuracies))])\n        \n    return window_start_times, classifier_accuracies_means\n\n#         classifier_accuracies_means.append(window_classifier_accuracies)\n    \n#     return classifier_accuracies_means\n\n\n# v----------------------------------------------------------------------------------------------------\n\nstarts, classifier_accuracies = classifier_accuracy_by_trial_window_boot_mod(flashes_presentation_table=flashes_presentation_table,\n                                                                         lfp_data=lfp_VISp, \n                                                                         window_size=.01, \n                                                                         end_time=.5, \n                                                                         time_res=1/100, \n                                                                         num_bootstrap_iterations=100, \n                                                                         alpha=.05)\nfor i in range(len(starts)):\n    print(\"Window start: {} ms      Mean Classifier Accuracy: {}\".format(math.floor(1000*widths[i]), classifier_accuracies[i]))\n    \nplt.figure(figsize=(8,6))\nim = plt.plot(starts, classifier_accuracies, label=\"mean\")\n\n_ = plt.xlabel('Window End (s)')\n_ = plt.ylabel('Classifier Accuracy')\n_ = plt.legend()",
      "metadata": {
        "scrolled": true
      },
      "execution_count": null,
      "outputs": [],
      "id": "f989ccc2"
    },
    {
      "cell_type": "code",
      "source": "# MEGACELL FOR INCREASING WINDOWS FOR VISUAL AREAS ALL 3 CLASSIFIERS\n\n#RF\ndef classifier_accuracy_by_time_after_presentation_rf(flashes_presentation_table, lfp_data, step_size, end_time, time_res, num_classification_iterations):\n    mean_classifier_accuracies = []\n    \n    window_end_times = []\n    end_time_temp = step_size\n    while end_time_temp <= end_time:\n        window_end_times.append(end_time_temp)\n        end_time_temp += step_size\n    \n    \n# PRODUCE ALIGNED LFPs FROM PROBE DATA\n    flashes_presentation_table_1 = flashes_presentation_table[flashes_presentation_table.color \n                                                                          == 1.0]\n    flashes_presentation_table_minus1 = flashes_presentation_table[flashes_presentation_table.color \n                                                                              == -1.0]\n    \n    \n    for window_end in window_end_times:\n    \n     \n\n\n        #for 1\n\n        presentation_times = flashes_presentation_table_1.start_time.values\n        presentation_ids = flashes_presentation_table_1.index.values\n\n        trial_window = np.arange(0, window_end, time_res)\n        time_selection = np.concatenate([trial_window + t for t in presentation_times])\n\n        inds = pd.MultiIndex.from_product((presentation_ids, trial_window), \n                                          names=('presentation_id', 'time_from_presentation_onset'))\n\n        ds = lfp_data.sel(time = time_selection, method='nearest').to_dataset(name = 'aligned_lfp')\n        ds = ds.assign(time=inds).unstack('time')\n\n        aligned_lfp_1 = ds['aligned_lfp']\n\n        #for -1\n\n        presentation_times = flashes_presentation_table_minus1.start_time.values\n        presentation_ids = flashes_presentation_table_minus1.index.values\n\n        trial_window = np.arange(0, window_end, time_res)\n        time_selection = np.concatenate([trial_window + t for t in presentation_times])\n\n        inds = pd.MultiIndex.from_product((presentation_ids, trial_window), \n                                          names=('presentation_id', 'time_from_presentation_onset'))\n\n        ds = lfp_data.sel(time = time_selection, method='nearest').to_dataset(name = 'aligned_lfp')\n        ds = ds.assign(time=inds).unstack('time')\n\n        aligned_lfp_minus1 = ds['aligned_lfp']\n        \n        \n        # COMPUTE T SCORES AND CORRESPONDING P VALUES IN INDEPENDENT T TEST BETWEEN TRIAL CONDITIONS\n        \n        tStat, pValue = stats.ttest_ind(a= aligned_lfp_minus1,\n               b = aligned_lfp_1,\n               axis = 1,\n               equal_var = False,\n               nan_policy = 'raise')\n        \n        # FORMAT TRIAL DATA FOR CLASSIFICATION\n        \n        \n        flashes_1_data = aligned_lfp_1.to_masked_array()\n        flashes_minus1_data = aligned_lfp_minus1.to_masked_array()\n        flashes_1_data.mask = np.ma.nomask\n        flashes_minus1_data.mask = np.ma.nomask\n        flashes_data_combined = np.concatenate((flashes_1_data,flashes_minus1_data),axis=1).transpose(1,0,2)\n        flashes_data_combined = flashes_data_combined.reshape(flashes_data_combined.shape[0],flashes_data_combined.shape[1] * flashes_data_combined.shape[2])\n        labels = []\n        for i in range(75):\n            labels.append(1)\n        for i in range(75,150):\n            labels.append(0)\n\n        # PERFORM MANY CLASSIFICATIONS\n        \n        window_classifier_accuracies = []\n        for i in range(num_classification_iterations):\n            \n            from sklearn.model_selection import train_test_split\n            x_train, x_test, y_train, y_test = train_test_split(flashes_data_combined, labels, test_size=0.25, stratify=labels)\n        \n            model = sklearn.ensemble.RandomForestClassifier(bootstrap = False, criterion='entropy')\n\n            model.fit(x_train,y_train)\n\n\n\n# TESTING\n\n            window_classifier_accuracies.append(model.score(x_test,y_test))\n        mean_classifier_accuracies.append(np.mean(window_classifier_accuracies))\n        \n    return window_end_times, mean_classifier_accuracies\n\n\n#SVC\ndef classifier_accuracy_by_time_after_presentation_svc(flashes_presentation_table, lfp_data, step_size, end_time, time_res, num_classification_iterations):\n    mean_classifier_accuracies = []\n    \n    window_end_times = []\n    end_time_temp = step_size\n    while end_time_temp <= end_time:\n        window_end_times.append(end_time_temp)\n        end_time_temp += step_size\n    \n    \n# PRODUCE ALIGNED LFPs FROM PROBE DATA\n   ncv\n#LIN\n\ndef classifier_accuracy_by_time_after_presentation_lin(flashes_presentation_table, lfp_data, step_size, end_time, time_res, num_classification_iterations):\n    mean_classifier_accuracies = []\n    \n    window_end_times = []\n    end_time_temp = step_size\n    while end_time_temp <= end_time:\n        window_end_times.append(end_time_temp)\n        end_time_temp += step_size\n    \n    \n# PRODUCE ALIGNED LFPs FROM PROBE DATA\n    flashes_presentation_table_1 = flashes_presentation_table[flashes_presentation_table.color \n                                                                          == 1.0]\n    flashes_presentation_table_minus1 = flashes_presentation_table[flashes_presentation_table.color \n                                                                              == -1.0]\n    \n    \n    for window_end in window_end_times:\n    \n     \n\n\n        #for 1\n\n        presentation_times = flashes_presentation_table_1.start_time.values\n        presentation_ids = flashes_presentation_table_1.index.values\n\n        trial_window = np.arange(0, window_end, time_res)\n        time_selection = np.concatenate([trial_window + t for t in presentation_times])\n\n        inds = pd.MultiIndex.from_product((presentation_ids, trial_window), \n                                          names=('presentation_id', 'time_from_presentation_onset'))\n\n        ds = lfp_data.sel(time = time_selection, method='nearest').to_dataset(name = 'aligned_lfp')\n        ds = ds.assign(time=inds).unstack('time')\n\n        aligned_lfp_1 = ds['aligned_lfp']\n\n        #for -1\n\n        presentation_times = flashes_presentation_table_minus1.start_time.values\n        presentation_ids = flashes_presentation_table_minus1.index.values\n\n        trial_window = np.arange(0, window_end, time_res)\n        time_selection = np.concatenate([trial_window + t for t in presentation_times])\n\n        inds = pd.MultiIndex.from_product((presentation_ids, trial_window), \n                                          names=('presentation_id', 'time_from_presentation_onset'))\n\n        ds = lfp_data.sel(time = time_selection, method='nearest').to_dataset(name = 'aligned_lfp')\n        ds = ds.assign(time=inds).unstack('time')\n\n        aligned_lfp_minus1 = ds['aligned_lfp']\n        \n        \n        # COMPUTE T SCORES AND CORRESPONDING P VALUES IN INDEPENDENT T TEST BETWEEN TRIAL CONDITIONS\n        \n        tStat, pValue = stats.ttest_ind(a= aligned_lfp_minus1,\n               b = aligned_lfp_1,\n               axis = 1,\n               equal_var = False,\n               nan_policy = 'raise')\n        \n        # FORMAT TRIAL DATA FOR CLASSIFICATION\n        \n        \n        flashes_1_data = aligned_lfp_1.to_masked_array()\n        flashes_minus1_data = aligned_lfp_minus1.to_masked_array()\n        flashes_1_data.mask = np.ma.nomask\n        flashes_minus1_data.mask = np.ma.nomask\n        flashes_data_combined = np.concatenate((flashes_1_data,flashes_minus1_data),axis=1).transpose(1,0,2)\n        flashes_data_combined = flashes_data_combined.reshape(flashes_data_combined.shape[0],flashes_data_combined.shape[1] * flashes_data_combined.shape[2])\n        labels = []\n        for i in range(75):\n            labels.append(1)\n        for i in range(75,150):\n            labels.append(0)\n\n        # PERFORM MANY CLASSIFICATIONS\n        \n        window_classifier_accuracies = []\n        for i in range(num_classification_iterations):\n            \n            from sklearn.model_selection import train_test_split\n            x_train, x_test, y_train, y_test = train_test_split(flashes_data_combined, labels, test_size=0.25, stratify=labels)\n        \n            # TUNE HYPERPARAMETERS USING CROSS-VALIDATION\n\n            model = sklearn.linear_model.LogisticRegression(solver='liblinear')\n\n            penalty = ['l1','l2']\n            C = [10,100,1000]\n            hyperparameters = dict(C=C,penalty=penalty)\n            \n            clf = sklearn.model_selection.GridSearchCV(model, hyperparameters, cv=3)\n            best_model = clf.fit(x_train,y_train)\n\n\n\n# TESTING\n\n            window_classifier_accuracies.append(best_model.score(x_test,y_test))\n        mean_classifier_accuracies.append(np.mean(window_classifier_accuracies))\n        \n    return window_end_times, mean_classifier_accuracies\n\n\n#-------------------------------P L O T T I N G-----------------------------------------------\n\n  #     RF\nends_pm, means_pm = classifier_accuracy_by_time_after_presentation_rf(flashes_presentation_table=flashes_presentation_table, \n                                                  lfp_data=lfp_VISpm, \n                                                  step_size=0.01, \n                                                  end_time=0.5, \n                                                  time_res=1/100, \n                                                  num_classification_iterations=50)\nends_l, means_l = classifier_accuracy_by_time_after_presentation_rf(flashes_presentation_table=flashes_presentation_table, \n                                                  lfp_data=lfp_VISl, \n                                                  step_size=0.01, \n                                                  end_time=0.5, \n                                                  time_res=1/100, \n                                                  num_classification_iterations=50)\nends_p, means_p = classifier_accuracy_by_time_after_presentation_rf(flashes_presentation_table=flashes_presentation_table, \n                                                  lfp_data=lfp_VISp, \n                                                  step_size=0.01, \n                                                  end_time=0.5, \n                                                  time_res=1/100, \n                                                  num_classification_iterations=50)\nends_rl, means_rl = classifier_accuracy_by_time_after_presentation_rf(flashes_presentation_table=flashes_presentation_table, \n                                                  lfp_data=lfp_VISrl, \n                                                  step_size=0.01, \n                                                  end_time=0.5, \n                                                  time_res=1/100, \n                                                  num_classification_iterations=50)\n\nplt.figure(figsize=(8,6))\nim = plt.plot(ends_pm, means_pm, label=\"PM\")\nim = plt.plot(ends_l, means_l, label=\"LM\")\nim = plt.plot(ends_p, means_p, label=\"V1\")\nim = plt.plot(ends_rl, means_rl, label=\"RL\")\n_ = plt.xlabel('Window Width (by 10ms)')\n_ = plt.ylabel('Classifier Accuracy')\n_ = plt.legend()\n_ = plt.title('Random Forest Classifier Accuracy for Visual Areas by Time Following Stimulus')\n\n#        SVC\n\n# ends_pm, means_pm = classifier_accuracy_by_time_after_presentation_svc(flashes_presentation_table=flashes_presentation_table, \n#                                                   lfp_data=lfp_VISpm, \n#                                                   step_size=0.01, \n#                                                   end_time=0.5, \n#                                                   time_res=1/100, \n#                                                   num_classification_iterations=50)\n# ends_l, means_l = classifier_accuracy_by_time_after_presentation_svc(flashes_presentation_table=flashes_presentation_table, \n#                                                   lfp_data=lfp_VISl, \n#                                                   step_size=0.01, \n#                                                   end_time=0.5, \n#                                                   time_res=1/100, \n#                                                   num_classification_iterations=50)\n# ends_p, means_p = classifier_accuracy_by_time_after_presentation_svc(flashes_presentation_table=flashes_presentation_table, \n#                                                   lfp_data=lfp_VISp, \n#                                                   step_size=0.01, \n#                                                   end_time=0.5, \n#                                                   time_res=1/100, \n#                                                   num_classification_iterations=50)\n# ends_rl, means_rl = classifier_accuracy_by_time_after_presentation_svc(flashes_presentation_table=flashes_presentation_table, \n#                                                   lfp_data=lfp_VISrl, \n#                                                   step_size=0.01, \n#                                                   end_time=0.5, \n#                                                   time_res=1/100, \n#                                                   num_classification_iterations=50)\n\n# plt.figure(figsize=(8,6))\n# im = plt.plot(ends_pm, means_pm, label=\"PM\")\n# im = plt.plot(ends_l, means_l, label=\"LM\")\n# im = plt.plot(ends_p, means_p, label=\"V1\")\n# im = plt.plot(ends_rl, means_rl, label=\"RL\")\n# _ = plt.xlabel('Window Width (by 10ms)')\n# _ = plt.ylabel('Classifier Accuracy')\n# _ = plt.legend()\n# _ = plt.title('Support Vector Classifier Accuracy for Visual Areas by Time Following Stimulus')\n\n\n#        LIN\n\n# ends_pm, means_pm = classifier_accuracy_by_time_after_presentation_lin(flashes_presentation_table=flashes_presentation_table, \n#                                                   lfp_data=lfp_VISpm, \n#                                                   step_size=0.01, \n#                                                   end_time=0.5, \n#                                                   time_res=1/100, \n#                                                   num_classification_iterations=50)\n# ends_l, means_l = classifier_accuracy_by_time_after_presentation_lin(flashes_presentation_table=flashes_presentation_table, \n#                                                   lfp_data=lfp_VISl, \n#                                                   step_size=0.01, \n#                                                   end_time=0.5, \n#                                                   time_res=1/100, \n#                                                   num_classification_iterations=50)\n# ends_p, means_p = classifier_accuracy_by_time_after_presentation_lin(flashes_presentation_table=flashes_presentation_table, \n#                                                   lfp_data=lfp_VISp, \n#                                                   step_size=0.01, \n#                                                   end_time=0.5, \n#                                                   time_res=1/100, \n#                                                   num_classification_iterations=50)\n# ends_rl, means_rl = classifier_accuracy_by_time_after_presentation_lin(flashes_presentation_table=flashes_presentation_table, \n#                                                   lfp_data=lfp_VISrl, \n#                                                   step_size=0.01, \n#                                                   end_time=0.5, \n#                                                   time_res=1/100, \n#                                                   num_classification_iterations=50)\n\n# plt.figure(figsize=(8,6))\n# im = plt.plot(ends_pm, means_pm, label=\"PM\")\n# im = plt.plot(ends_l, means_l, label=\"LM\")\n# im = plt.plot(ends_p, means_p, label=\"V1\")\n# im = plt.plot(ends_rl, means_rl, label=\"RL\")\n# _ = plt.xlabel('Window Width (by 10ms)')\n# _ = plt.ylabel('Classifier Accuracy')\n# _ = plt.legend()\n# _ = plt.title('Linear Classifier Accuracy for Visual Areas by Time Following Stimulus')",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "081b27a1"
    },
    {
      "cell_type": "code",
      "source": "print(len(means_l))",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "6ce8e0f6"
    },
    {
      "cell_type": "code",
      "source": "out = classifier_accuracy_by_trial_window_boot(flashes_presentation_table=flashes_presentation_table,\n                                                                         lfp_data=lfp_VISp, \n                                                                         window_size=.01, \n                                                                         end_time=.5, \n                                                                         time_res=1/100, \n                                                                         num_bootstrap_iterations=100, \n                                                                         alpha=.05)\n\n    \n# plt.hist(out[0])\nplt.hist(out[42],20)\n",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "a1828f9b"
    },
    {
      "cell_type": "code",
      "source": "starts, ci_low, classifier_accuracies, ci_hi = classifier_accuracy_by_trial_window_boot(flashes_presentation_table=flashes_presentation_table,\n                                                                         lfp_data=lfp_VISp, \n                                                                         window_size=.05, \n                                                                         end_time=.5, \n                                                                         time_res=1/100, \n                                                                         num_bootstrap_iterations=100, \n                                                                         alpha=.05)\nfor i in range(len(starts)):\n    print(\"Window start: {} ms      Mean Classifier Accuracy: {}\".format(math.floor(1000*starts[i]), classifier_accuracies[i]))\n    \nplt.figure(figsize=(8,6))\nim = plt.plot(starts, classifier_accuracies, label=\"mean\")\nim = plt.plot(starts, ci_low, label=\"ci low\")\nim = plt.plot(starts, ci_hi, label=\"ci high\")\n_ = plt.xlabel('Window End (s)')\n_ = plt.ylabel('Classifier Accuracy')\n_ = plt.legend()",
      "metadata": {
        "scrolled": true
      },
      "execution_count": null,
      "outputs": [],
      "id": "240303ef"
    },
    {
      "cell_type": "code",
      "source": "starts, ci_low, classifier_accuracies, ci_hi = classifier_accuracy_by_trial_window_boot(flashes_presentation_table=flashes_presentation_table,\n                                                                         lfp_data=lfp_VISl, \n                                                                         window_size=.01, \n                                                                         end_time=.5, \n                                                                         time_res=1/100, \n                                                                         num_bootstrap_iterations=500, \n                                                                         alpha=.05)\nfor i in range(len(starts)):\n    print(\"Window start: {} ms      Mean Classifier Accuracy: {}\".format(math.floor(1000*widths[i]), classifier_accuracies[i]))\n    \nplt.figure(figsize=(8,6))\nim = plt.plot(starts, classifier_accuracies, label=\"mean\")\nim = plt.plot(starts, ci_low, label=\"ci low\")\nim = plt.plot(starts, ci_hi, label=\"ci high\")\n_ = plt.xlabel('Window End (s)')\n_ = plt.ylabel('Classifier Accuracy')\n_ = plt.legend()",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "10e4f796"
    },
    {
      "cell_type": "code",
      "source": "starts, ci_low, classifier_accuracies, ci_hi = classifier_accuracy_by_trial_window_boot(flashes_presentation_table=flashes_presentation_table,\n                                                                         lfp_data=lfp_VISpm, \n                                                                         window_size=.01, \n                                                                         end_time=.5, \n                                                                         time_res=1/100, \n                                                                         num_bootstrap_iterations=250, \n                                                                         alpha=.05)\nfor i in range(len(starts)):\n    print(\"Window start: {} ms      Mean Classifier Accuracy: {}\".format(math.floor(1000*widths[i]), classifier_accuracies[i]))\n    \nplt.figure(figsize=(8,6))\nim = plt.plot(starts, classifier_accuracies, label=\"mean\")\nim = plt.plot(starts, ci_low, label=\"ci low\")\nim = plt.plot(starts, ci_hi, label=\"ci high\")\n_ = plt.xlabel('Window End (s)')\n_ = plt.ylabel('Classifier Accuracy')\n_ = plt.legend()",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "e0feabbc"
    },
    {
      "cell_type": "markdown",
      "source": "# Evaluating classifier accuracy based on window of increasing size",
      "metadata": {},
      "id": "96c187f0"
    },
    {
      "cell_type": "code",
      "source": "#specifically works for flashes\ndef classifier_accuracy_by_time_after_presentation(flashes_presentation_table, lfp_data, step_size, end_time, time_res, num_classification_iterations):\n    mean_classifier_accuracies = []\n    \n    window_end_times = []\n    end_time_temp = step_size\n    while end_time_temp <= end_time:\n        window_end_times.append(end_time_temp)\n        end_time_temp += step_size\n    \n    \n# PRODUCE ALIGNED LFPs FROM PROBE DATA\n    flashes_presentation_table_1 = flashes_presentation_table[flashes_presentation_table.color \n                                                                          == 1.0]\n    flashes_presentation_table_minus1 = flashes_presentation_table[flashes_presentation_table.color \n                                                                              == -1.0]\n    \n    \n    for window_end in window_end_times:\n    \n     \n\n\n        #for 1\n\n        presentation_times = flashes_presentation_table_1.start_time.values\n        presentation_ids = flashes_presentation_table_1.index.values\n\n        trial_window = np.arange(0, window_end, time_res)\n        time_selection = np.concatenate([trial_window + t for t in presentation_times])\n\n        inds = pd.MultiIndex.from_product((presentation_ids, trial_window), \n                                          names=('presentation_id', 'time_from_presentation_onset'))\n\n        ds = lfp_data.sel(time = time_selection, method='nearest').to_dataset(name = 'aligned_lfp')\n        ds = ds.assign(time=inds).unstack('time')\n\n        aligned_lfp_1 = ds['aligned_lfp']\n\n        #for -1\n\n        presentation_times = flashes_presentation_table_minus1.start_time.values\n        presentation_ids = flashes_presentation_table_minus1.index.values\n\n        trial_window = np.arange(0, window_end, time_res)\n        time_selection = np.concatenate([trial_window + t for t in presentation_times])\n\n        inds = pd.MultiIndex.from_product((presentation_ids, trial_window), \n                                          names=('presentation_id', 'time_from_presentation_onset'))\n\n        ds = lfp_data.sel(time = time_selection, method='nearest').to_dataset(name = 'aligned_lfp')\n        ds = ds.assign(time=inds).unstack('time')\n\n        aligned_lfp_minus1 = ds['aligned_lfp']\n        \n        \n        # COMPUTE T SCORES AND CORRESPONDING P VALUES IN INDEPENDENT T TEST BETWEEN TRIAL CONDITIONS\n        \n        tStat, pValue = stats.ttest_ind(a= aligned_lfp_minus1,\n               b = aligned_lfp_1,\n               axis = 1,\n               equal_var = False,\n               nan_policy = 'raise')\n        \n        # FORMAT TRIAL DATA FOR CLASSIFICATION\n        \n        \n        flashes_1_data = aligned_lfp_1.to_masked_array()\n        flashes_minus1_data = aligned_lfp_minus1.to_masked_array()\n        flashes_1_data.mask = np.ma.nomask\n        flashes_minus1_data.mask = np.ma.nomask\n        flashes_data_combined = np.concatenate((flashes_1_data,flashes_minus1_data),axis=1).transpose(1,0,2)\n        flashes_data_combined = flashes_data_combined.reshape(flashes_data_combined.shape[0],flashes_data_combined.shape[1] * flashes_data_combined.shape[2])\n        labels = []\n        for i in range(75):\n            labels.append(1)\n        for i in range(75,150):\n            labels.append(0)\n\n        # PERFORM MANY CLASSIFICATIONS\n        \n        window_classifier_accuracies = []\n        for i in range(num_classification_iterations):\n            \n            from sklearn.model_selection import train_test_split\n            x_train, x_test, y_train, y_test = train_test_split(flashes_data_combined, labels, test_size=0.25, stratify=labels)\n        \n            model = sklearn.linear_model.LogisticRegression()\n            model.fit(x_train,y_train)\n            window_classifier_accuracies.append(model.score(x_test,y_test))\n        mean_classifier_accuracies.append(np.mean(window_classifier_accuracies))\n        \n    return window_end_times, mean_classifier_accuracies",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "0b22ea41"
    },
    {
      "cell_type": "code",
      "source": "widths, classifier_accuracies = classifier_accuracy_by_time_after_presentation(flashes_presentation_table=flashes_presentation_table, \n                                                                         lfp_data=lfp_VISp, \n                                                                         step_size=.01, \n                                                                         end_time=.5, \n                                                                         time_res=1/1000, \n                                                                         num_classification_iterations=100)\nfor i in range(len(widths)):\n    print(\"Window width: {}       Mean Classifier Accuracy: {}\".format(widths[i], classifier_accuracies[i]))\n    \nplt.figure(figsize=(8,6))\nim = plt.plot(widths, classifier_accuracies)\n_ = plt.xlabel('Window length (ms)')\n_ = plt.ylabel('Classifier Accuracy')",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "55aea80e"
    },
    {
      "cell_type": "markdown",
      "source": "# EVALUATING CLASSIFIER ACCURACY BASED ON SLIDING TIME WINDOW",
      "metadata": {},
      "id": "142be2a3"
    },
    {
      "cell_type": "code",
      "source": "#specifically works for flashes\ndef classifier_accuracy_by_trial_window(flashes_presentation_table, lfp_data, window_size, end_time, time_res, num_classification_iterations):\n    mean_classifier_accuracies = []\n    quant_low = []\n    quant_high = []\n    \n    window_start_times = []\n    start_time = 0\n    while start_time + window_size < end_time:\n        window_start_times.append(start_time)\n        start_time += window_size\n    \n    \n# PRODUCE ALIGNED LFPs FROM PROBE DATA\n    flashes_presentation_table_1 = flashes_presentation_table[flashes_presentation_table.color \n                                                                          == 1.0]\n    flashes_presentation_table_minus1 = flashes_presentation_table[flashes_presentation_table.color \n                                                                              == -1.0]\n    \n    \n    for window_start in window_start_times:\n    \n     \n\n\n        #for 1\n\n        presentation_times = flashes_presentation_table_1.start_time.values\n        presentation_ids = flashes_presentation_table_1.index.values\n\n        trial_window = np.arange(window_start, window_start + window_size, time_res)\n        time_selection = np.concatenate([trial_window + t for t in presentation_times])\n\n        inds = pd.MultiIndex.from_product((presentation_ids, trial_window), \n                                          names=('presentation_id', 'time_from_presentation_onset'))\n\n        ds = lfp_data.sel(time = time_selection, method='nearest').to_dataset(name = 'aligned_lfp')\n        ds = ds.assign(time=inds).unstack('time')\n\n        aligned_lfp_1 = ds['aligned_lfp']\n\n        #for -1\n\n        presentation_times = flashes_presentation_table_minus1.start_time.values\n        presentation_ids = flashes_presentation_table_minus1.index.values\n\n        trial_window = np.arange(window_start, window_start + window_size, time_res)\n        time_selection = np.concatenate([trial_window + t for t in presentation_times])\n\n        inds = pd.MultiIndex.from_product((presentation_ids, trial_window), \n                                          names=('presentation_id', 'time_from_presentation_onset'))\n\n        ds = lfp_data.sel(time = time_selection, method='nearest').to_dataset(name = 'aligned_lfp')\n        ds = ds.assign(time=inds).unstack('time')\n\n        aligned_lfp_minus1 = ds['aligned_lfp']\n        \n        \n        # COMPUTE T SCORES AND CORRESPONDING P VALUES IN INDEPENDENT T TEST BETWEEN TRIAL CONDITIONS\n        \n        tStat, pValue = stats.ttest_ind(a= aligned_lfp_minus1,\n               b = aligned_lfp_1,\n               axis = 1,\n               equal_var = False,\n               nan_policy = 'raise')\n        \n        # FORMAT TRIAL DATA FOR CLASSIFICATION\n        \n        \n        flashes_1_data = aligned_lfp_1.to_masked_array()\n        flashes_minus1_data = aligned_lfp_minus1.to_masked_array()\n        flashes_1_data.mask = np.ma.nomask\n        flashes_minus1_data.mask = np.ma.nomask\n        flashes_data_combined = np.concatenate((flashes_1_data,flashes_minus1_data),axis=1).transpose(1,0,2)\n        flashes_data_combined = flashes_data_combined.reshape(flashes_data_combined.shape[0],flashes_data_combined.shape[1] * flashes_data_combined.shape[2])\n        labels = []\n        for i in range(75):\n            labels.append(1)\n        for i in range(75,150):\n            labels.append(0)\n\n#         print(len(flashes_data_combined))\n#         print(len(flashes_data_combined[0]))\n#         print(len(labels))\n        # PERFORM MANY CLASSIFICATIONS\n        \n        window_classifier_accuracies = []\n        for i in range(num_classification_iterations):\n            \n            from sklearn.model_selection import train_test_split\n            x_train, x_test, y_train, y_test = train_test_split(flashes_data_combined, labels, test_size=0.25, stratify=labels)\n        \n            model = sklearn.linear_model.LogisticRegression()\n            model.fit(x_train,y_train)\n            window_classifier_accuracies.append(model.score(x_test,y_test))\n#         mean_classifier_accuracies.append(np.mean(window_classifier_accuracies))\n#         sort = sorted(window_classifier_accuracies)\n#         quant_low.append(sort[math.floor(.025 * len(sort))])\n#         quant_high.append(sort[math.ceil(.975 * len(sort))])\n        \n#     return window_start_times, quant_low, mean_classifier_accuracies, quant_high\n\n        mean_classifier_accuracies.append(window_classifier_accuracies)\n    \n    return mean_classifier_accuracies",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "4658217d"
    },
    {
      "cell_type": "code",
      "source": "out = classifier_accuracy_by_trial_window(flashes_presentation_table=flashes_presentation_table, \n                                                                         lfp_data=lfp_VISp, \n                                                                         window_size=.01, \n                                                                         end_time=.5, \n                                                                         time_res=1/100, \n                                                                         num_classification_iterations=100)\nplt.hist(out[41])\n",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "3e597833"
    },
    {
      "cell_type": "code",
      "source": "start_times, classifier_accuracies = classifier_accuracy_by_trial_window(flashes_presentation_table=flashes_presentation_table, \n                                                                         lfp_data=lfp_VISpm, \n                                                                         window_size=.02, \n                                                                         end_time=.5, \n                                                                         time_res=1/1000, \n                                                                         num_classification_iterations=100)\nfor i in range(len(start_times)):\n    print(\"Window start: {}       Mean Classifier Accuracy: {}\".format(start_times[i], classifier_accuracies[i]))\n    \nplt.figure(figsize=(8,6))\nim = plt.plot(start_times, classifier_accuracies)\n_ = plt.xlabel('Start Time')\n_ = plt.ylabel('Classifier Accuracy')",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "8b915866"
    },
    {
      "cell_type": "code",
      "source": "start_times, classifier_accuracies = classifier_accuracy_by_trial_window(flashes_presentation_table=flashes_presentation_table, \n                                                                         lfp_data=lfp_VISam, \n                                                                         window_size=.02, \n                                                                         end_time=.5, \n                                                                         time_res=1/1000, \n                                                                         num_classification_iterations=100)\nfor i in range(len(start_times)):\n    print(\"Window start: {}       Mean Classifier Accuracy: {}\".format(start_times[i], classifier_accuracies[i]))\n    \nplt.figure(figsize=(8,6))\nim = plt.plot(start_times, classifier_accuracies)\n_ = plt.xlabel('Start Time')\n_ = plt.ylabel('Classifier Accuracy')",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "e036a764"
    },
    {
      "cell_type": "code",
      "source": "start_times, classifier_accuracies = classifier_accuracy_by_trial_window(flashes_presentation_table=flashes_presentation_table, \n                                                                         lfp_data=lfp_VISl, \n                                                                         window_size=.02, \n                                                                         end_time=.5, \n                                                                         time_res=1/1000, \n                                                                         num_classification_iterations=100)\nfor i in range(len(start_times)):\n    print(\"Window start: {}       Mean Classifier Accuracy: {}\".format(start_times[i], classifier_accuracies[i]))\n    \nplt.figure(figsize=(8,6))\nim = plt.plot(start_times, classifier_accuracies)\n_ = plt.xlabel('Start Time')\n_ = plt.ylabel('Classifier Accuracy')",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "9da51697"
    },
    {
      "cell_type": "code",
      "source": "start_times, classifier_accuracies = classifier_accuracy_by_trial_window(flashes_presentation_table=flashes_presentation_table, \n                                                                         lfp_data=lfp_VISrl, \n                                                                         window_size=.005, \n                                                                         end_time=.5, \n                                                                         time_res=1/1000, \n                                                                         num_classification_iterations=100)\nfor i in range(len(start_times)):\n    print(\"Window start: {}       Mean Classifier Accuracy: {}\".format(start_times[i], classifier_accuracies[i]))\n    \nplt.figure(figsize=(8,6))\nim = plt.plot(start_times, classifier_accuracies)\n_ = plt.xlabel('Start Time')\n_ = plt.ylabel('Classifier Accuracy')",
      "metadata": {
        "scrolled": true
      },
      "execution_count": null,
      "outputs": [],
      "id": "29eb17a0"
    },
    {
      "cell_type": "code",
      "source": "starts, ci_low, classifier_accuracies, ci_hi, coefficients = classifier_accuracy_by_trial_window_boot_lin(flashes_presentation_table=flashes_presentation_table,\n                                                                         lfp_data=lfp_VISp, \n                                                                         window_size=.01, \n                                                                         end_time=.5, \n                                                                         time_res=1/100, \n                                                                         num_bootstrap_iterations=250, \n                                                                         alpha=.05)\nfor i in range(len(starts)):\n    print(\"Window start: {} ms      Mean Classifier Accuracy: {}\".format(math.floor(1000*starts[i]), classifier_accuracies[i]))\n    \nplt.figure(figsize=(8,6))\nim = plt.plot(starts, classifier_accuracies, label=\"mean\")\n_ = plt.fill_between(starts, ci_low, ci_hi, alpha=0.2)\n# im = plt.plot(starts, ci_low, label=\"ci low\")\n# im = plt.plot(starts, ci_hi, label=\"ci high\")\n_ = plt.xlabel('Start of time window following stimulus onset (s)')\n_ = plt.ylabel('Classifier Accuracy')\n_ = plt.title('Bootstrapped mean linear classifer accuracy with 95% CI for V1')\n_ = plt.legend()\n\nfig = plt.figure(figsize=(8,6))\nim2 = plt.imshow(coefficients, origin='lower', cmap='bone')\n_ = plt.xlabel(\"Time sample after stimulus onset (by 10ms)\")\n_ = plt.ylabel(\"Electrode index\")\n_ = plt.title(\"Linear Classifier Coefficients\")\n_ = plt.colorbar(im2, cax = fig.add_axes([.92, 0.33, 0.03, 0.38]))",
      "metadata": {
        "scrolled": true
      },
      "execution_count": null,
      "outputs": [],
      "id": "0297fc7a"
    },
    {
      "cell_type": "code",
      "source": "starts, ci_low, classifier_accuracies, ci_hi, coefficients = classifier_accuracy_by_trial_window_boot_lin(flashes_presentation_table=flashes_presentation_table,\n                                                                         lfp_data=lfp_LP, \n                                                                         window_size=.01, \n                                                                         end_time=.5, \n                                                                         time_res=1/100, \n                                                                         num_bootstrap_iterations=250, \n                                                                         alpha=.05)\nfor i in range(len(starts)):\n    print(\"Window start: {} ms      Mean Classifier Accuracy: {}\".format(math.floor(1000*starts[i]), classifier_accuracies[i]))\n    \nplt.figure(figsize=(8,6))\nim = plt.plot(starts, classifier_accuracies, label=\"mean\")\n_ = plt.fill_between(starts, ci_low, ci_hi, alpha=0.2)\n# im = plt.plot(starts, ci_low, label=\"ci low\")\n# im = plt.plot(starts, ci_hi, label=\"ci high\")\n_ = plt.xlabel('Start of time window following stimulus onset (s)')\n_ = plt.ylabel('Classifier Accuracy')\n_ = plt.title('Bootstrapped mean linear classifer accuracy with 95% CI for LP')\n_ = plt.legend()\n\nfig = plt.figure(figsize=(8,6))\nim2 = plt.imshow(coefficients, origin='lower', cmap='bone')\n_ = plt.xlabel(\"Time sample after stimulus onset (by 10ms)\")\n_ = plt.ylabel(\"Electrode index\")\n_ = plt.title(\"Linear Classifier Coefficients\")\n_ = plt.colorbar(im2, cax = fig.add_axes([.92, 0.33, 0.03, 0.38]))",
      "metadata": {
        "scrolled": true
      },
      "execution_count": null,
      "outputs": [],
      "id": "dca6ed43"
    },
    {
      "cell_type": "code",
      "source": "starts, ci_low, classifier_accuracies, ci_hi, coefficients = classifier_accuracy_by_trial_window_boot_lin(flashes_presentation_table=flashes_presentation_table,\n                                                                         lfp_data=lfp_LGd, \n                                                                         window_size=.01, \n                                                                         end_time=.5, \n                                                                         time_res=1/100, \n                                                                         num_bootstrap_iterations=250, \n                                                                         alpha=.05)\nfor i in range(len(starts)):\n    print(\"Window start: {} ms      Mean Classifier Accuracy: {}\".format(math.floor(1000*starts[i]), classifier_accuracies[i]))\n    \nplt.figure(figsize=(8,6))\nim = plt.plot(starts, classifier_accuracies, label=\"mean\")\n_ = plt.fill_between(starts, ci_low, ci_hi, alpha=0.2)\n# im = plt.plot(starts, ci_low, label=\"ci low\")\n# im = plt.plot(starts, ci_hi, label=\"ci high\")\n_ = plt.xlabel('Start of time window following stimulus onset (s)')\n_ = plt.ylabel('Classifier Accuracy')\n_ = plt.title('Bootstrapped mean linear classifer accuracy with 95% CI for LGd')\n_ = plt.legend()\n\nfig = plt.figure(figsize=(8,6))\nim2 = plt.imshow(coefficients, origin='lower', cmap='bone')\n_ = plt.xlabel(\"Time sample after stimulus onset (by 10ms)\")\n_ = plt.ylabel(\"Electrode index\")\n_ = plt.title(\"Linear Classifier Coefficients\")\n_ = plt.colorbar(im2, cax = fig.add_axes([.92, 0.33, 0.03, 0.38]))",
      "metadata": {
        "scrolled": true
      },
      "execution_count": null,
      "outputs": [],
      "id": "31505ed5"
    },
    {
      "cell_type": "code",
      "source": "starts, ci_low, classifier_accuracies, ci_hi, coefficients = classifier_accuracy_by_trial_window_boot_lin(flashes_presentation_table=flashes_presentation_table,\n                                                                         lfp_data=lfp_thalamus, \n                                                                         window_size=.01, \n                                                                         end_time=.5, \n                                                                         time_res=1/100, \n                                                                         num_bootstrap_iterations=250, \n                                                                         alpha=.05)\nfor i in range(len(starts)):\n    print(\"Window start: {} ms      Mean Classifier Accuracy: {}\".format(math.floor(1000*starts[i]), classifier_accuracies[i]))\n    \nplt.figure(figsize=(8,6))\nim = plt.plot(starts, classifier_accuracies, label=\"mean\")\n_ = plt.fill_between(starts, ci_low, ci_hi, alpha=0.2)\n# im = plt.plot(starts, ci_low, label=\"ci low\")\n# im = plt.plot(starts, ci_hi, label=\"ci high\")\n_ = plt.xlabel('Start of time window following stimulus onset (s)')\n_ = plt.ylabel('Classifier Accuracy')\n_ = plt.title('Bootstrapped mean linear classifer accuracy with 95% CI for thalamus')\n_ = plt.legend()\n\nfig = plt.figure(figsize=(8,6))\nim2 = plt.imshow(coefficients, origin='lower', cmap='bone')\n_ = plt.xlabel(\"Time sample after stimulus onset (by 10ms)\")\n_ = plt.ylabel(\"Electrode index\")\n_ = plt.title(\"Linear Classifier Coefficients\")\n_ = plt.colorbar(im2, cax = fig.add_axes([.92, 0.33, 0.03, 0.38]))",
      "metadata": {
        "scrolled": true
      },
      "execution_count": null,
      "outputs": [],
      "id": "0d75f470"
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "d6fbbfeb"
    },
    {
      "cell_type": "markdown",
      "source": "# CLASSIFIER FOR FLASH COLOR",
      "metadata": {},
      "id": "26f97947"
    },
    {
      "cell_type": "code",
      "source": "\nflashes_presentation_table = session.stimulus_presentations[session.stimulus_presentations.stimulus_name == 'flashes']\n\nflashes_presentation_times = flashes_presentation_table.start_time.values\nflashes_presentation_ids = flashes_presentation_table.index.values\n",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "69714ea1"
    },
    {
      "cell_type": "code",
      "source": "lfp_VISp = lfp.sel(channel = lfp.channel[62:84])\n\nflashes_presentation_table_1 = flashes_presentation_table[flashes_presentation_table.color \n                                                                      == 1.0]\nflashes_presentation_table_minus1 = flashes_presentation_table[flashes_presentation_table.color \n                                                                      == -1.0]\n#for overall\npresentation_times = flashes_presentation_table.start_time.values\npresentation_ids = flashes_presentation_table.index.values\n\ntrial_window = np.arange(0,.5, 1/100)\ntime_selection = np.concatenate([trial_window + t for t in presentation_times])\n\ninds = pd.MultiIndex.from_product((presentation_ids, trial_window), \n                                  names=('presentation_id', 'time_from_presentation_onset'))\n\nds = lfp_VISp.sel(time = time_selection, method='nearest').to_dataset(name = 'aligned_lfp')\nds = ds.assign(time=inds).unstack('time')\n\naligned_lfp = ds['aligned_lfp']\n\n#for 1\n\npresentation_times = flashes_presentation_table_1.start_time.values\npresentation_ids = flashes_presentation_table_1.index.values\n\ntrial_window = np.arange(0,.5, 1/100)\ntime_selection = np.concatenate([trial_window + t for t in presentation_times])\n\ninds = pd.MultiIndex.from_product((presentation_ids, trial_window), \n                                  names=('presentation_id', 'time_from_presentation_onset'))\n\nds = lfp_VISp.sel(time = time_selection, method='nearest').to_dataset(name = 'aligned_lfp')\nds = ds.assign(time=inds).unstack('time')\n\naligned_lfp_1 = ds['aligned_lfp']\n\n#for -1\n\npresentation_times = flashes_presentation_table_minus1.start_time.values\npresentation_ids = flashes_presentation_table_minus1.index.values\n\ntrial_window = np.arange(0,.5, 1/100)\ntime_selection = np.concatenate([trial_window + t for t in presentation_times])\n\ninds = pd.MultiIndex.from_product((presentation_ids, trial_window), \n                                  names=('presentation_id', 'time_from_presentation_onset'))\n\nds = lfp_VISp.sel(time = time_selection, method='nearest').to_dataset(name = 'aligned_lfp')\nds = ds.assign(time=inds).unstack('time')\n\naligned_lfp_minus1 = ds['aligned_lfp']",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "b6b4884c"
    },
    {
      "cell_type": "code",
      "source": "aligned_lfp_minus1",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "5c6eba9b"
    },
    {
      "cell_type": "code",
      "source": "import scipy.stats as stats\nimport math\n\ntStat, pValue = stats.ttest_ind(a= aligned_lfp_minus1,\n               b = aligned_lfp_1,\n               axis = 1,\n               equal_var = False,\n               nan_policy = 'raise')\n\n# MANUAL BENJAMINI-HOCHBERG\n\ndef benjamini_hochberg(p_values, alpha):\n    indices_of_significant_values = []\n    p_values_flat = p_values.flatten()\n    dictionary = dict(zip(p_values_flat,range(len(p_values_flat))))\n    \n    sorted_keys = sorted(dictionary)\n    \n    greatest_i_so_far = 0\n\n    for i in range(len(sorted_keys)):\n        key = sorted_keys[i]\n        critical_value = i*alpha/len(dictionary)\n        if key<critical_value:\n            greatest_i_so_far = i\n    for i in range(greatest_i_so_far):\n        indices_of_significant_values.append(dictionary.get(sorted_keys[i]))\n\n    indices_of_significant_values = sorted(indices_of_significant_values)\n    print(\"number of significant p-values:\",len(indices_of_significant_values))\n    \n    return indices_of_significant_values\n\nsignificant_indices = benjamini_hochberg(p_values = pValue, alpha = .000000000000005)\n\nasdf = []\nfor i in range(pValue.shape[0]*pValue.shape[1]):\n    if i in significant_indices:\n        asdf.append(1)\n    else:\n        asdf.append(0)\nprint(len(asdf))\nmask = []\nfor i in range(pValue.shape[0]):\n    row = []\n    for j in range(pValue.shape[1]):\n        row.append(asdf[i*pValue.shape[1]+j])\n    mask.append(row)\n\nfig = plt.figure(figsize=(8,6))\nim = plt.imshow(mask, origin='lower')\n_ = plt.xlabel('Time sample after stimulus onset (by 10ms)')\n_ = plt.ylabel('Electrode index')\n_ = plt.title('Benjamini-Hochberg-Corrected P-values for Independent T Test on LFP Data for Flash Colors')\n\nimport matplotlib\nhandles = [matplotlib.patches.Patch(facecolor='yellow', edgecolor='y',label='Significant feature')]\n_ = plt.legend(handles=handles,loc='lower left')\n# _ = plt.colorbar(im, cax = fig.add_axes([.92, 0.33, 0.03, 0.2]))\n        ",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "e43c5f96"
    },
    {
      "cell_type": "code",
      "source": "# pValue.shape\nprint(aligned_lfp_1.presentation_id)\nprint(aligned_lfp_minus1.presentation_id)\nprint(aligned_lfp.presentation_id)\nprint(flashes_presentation_table.index.values)",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "62c8961c"
    },
    {
      "cell_type": "code",
      "source": "flashes_1_data = aligned_lfp_1.to_masked_array()\nflashes_minus1_data = aligned_lfp_minus1.to_masked_array()\nflashes_1_data.mask = np.ma.nomask\nflashes_minus1_data.mask = np.ma.nomask\nflashes_data_combined = np.concatenate((flashes_1_data,flashes_minus1_data),axis=1).transpose(1,0,2)\nflashes_data_combined = flashes_data_combined.reshape(flashes_data_combined.shape[0],flashes_data_combined.shape[1] * flashes_data_combined.shape[2])\nlabels = []\nfor i in range(75):\n    labels.append(1)\nfor i in range(75,150):\n    labels.append(0)\nprint(flashes_data_combined.shape)\n# print(labels)\nfrom sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(flashes_data_combined, labels, test_size=0.25, stratify=labels)\n# print(x_train.shape)\n# print(x_test.shape)\n# print(len(y_train))\n# print(len(y_test))\nprint(train_test_split)",
      "metadata": {
        "scrolled": true
      },
      "execution_count": null,
      "outputs": [],
      "id": "2c7c3329"
    },
    {
      "cell_type": "code",
      "source": "import sklearn.linear_model\nmodel = sklearn.linear_model.LogisticRegression()\nmodel.fit(x_train,y_train)\nmodel.score(x_test,y_test)",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "c8e48047"
    },
    {
      "cell_type": "markdown",
      "source": "# FIND TRIALS THAT ARE CONSISTENTLY MISCLASSIFIED\n## NOTE: RUN CELL 2 ABOVE THIS ONE FIRST",
      "metadata": {},
      "id": "5cd99cc4"
    },
    {
      "cell_type": "code",
      "source": "import sklearn.linear_model\n# for entry in id_to_incorrect_count_dict:\n#     print(\"Presentation ID: {}            Number incorrect: {}\".format(str(entry),str(id_to_incorrect_count_dict[entry])))",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "347f920c"
    },
    {
      "cell_type": "code",
      "source": "#MAKE DICTIONARY TO MAP LFP DATA TO PRESENTATION ID\ndata_to_id_dict = {}\nflashes_data = aligned_lfp.to_masked_array()\nflashes_data.mask = np.ma.nomask\nflashes_data = flashes_data.transpose(1,0,2)\nflashes_data = flashes_data.reshape(flashes_data.shape[0],flashes_data.shape[1]*flashes_data.shape[2])\n#shape is now (presentation id, total features)\n\nfor id_ind in range(len(flashes_presentation_table.index.values)):\n    id = flashes_presentation_table.index.values[id_ind]\n    trial_lfp_data = flashes_data[id_ind,:]\n    data_to_id_dict[trial_lfp_data.tobytes()] = id\n\n#MAKE DICTIONARY TO MAP PRESENTATION ID TO NUMBER OF INCORRECTS\nid_to_incorrect_count_dict = {}\nfor presentation_id in flashes_presentation_table.index.values:\n    id_to_incorrect_count_dict[str(presentation_id)] = 0\n\nnum_iterations = 10000\nprint(\"Number of iterations: {}\".format(str(num_iterations)))\n    \nfor i in range(num_iterations):\n    #DO RANDOM TRAIN-TEST SPLIT\n    from sklearn.model_selection import train_test_split\n    x_train, x_test, y_train, y_test = train_test_split(flashes_data_combined, labels, test_size=0.25, stratify=labels)\n\n    #INITIALIZE AND TRAIN MODEL\n    model = sklearn.linear_model.LogisticRegression()\n    model.fit(x_train,y_train)\n    \n    #TEST EACH STIMULUS IN TEST SET OF MODEL\n    predictions = model.predict(x_test)\n    for prediction_ind in range(len(predictions)):\n        prediction = predictions[prediction_ind]\n        correct_output = y_test[prediction_ind]\n        if prediction != correct_output:\n            #increase trial ID's incorrect count by 1\n            presentation_id = data_to_id_dict[x_test[prediction_ind].tobytes()]\n            id_to_incorrect_count_dict[str(presentation_id)] += 1\n            \nfor entry in id_to_incorrect_count_dict:\n    print(\"Presentation ID: {}            Number incorrect: {}\".format(str(entry),str(id_to_incorrect_count_dict[entry])))\n    ",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "34ee388b"
    },
    {
      "cell_type": "markdown",
      "source": "# CLASSIFIER FOR DRIFTING GRATING ORIENTATION (JUST BETWEEN 315 AND 135)",
      "metadata": {},
      "id": "83debc2f"
    },
    {
      "cell_type": "code",
      "source": "\ndg_presentation_table = session.stimulus_presentations[session.stimulus_presentations.stimulus_name == 'drifting_gratings']\n\ndg_presentation_times = dg_presentation_table.start_time.values\ndg_presentation_ids = dg_presentation_table.index.values\n",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "d8461216"
    },
    {
      "cell_type": "code",
      "source": "import xarray as xr\nlfp_VISp = lfp.sel(channel = lfp.channel[62:84])\n\ndg_presentation_table_135 = dg_presentation_table[dg_presentation_table.orientation \n                                                                      == 135.0]\ndg_presentation_table_315 = dg_presentation_table[dg_presentation_table.orientation \n                                                                      == 315.0]\n\npresentation_times = dg_presentation_table_135.start_time.values\npresentation_ids = dg_presentation_table_135.index.values\n\nprint(len(presentation_times))\n\ntrial_window = np.arange(0, 0.50, 1/100)\ntime_selection = np.concatenate([trial_window + t for t in presentation_times])\n\ninds = pd.MultiIndex.from_product((presentation_ids, trial_window), \n                                  names=('presentation_id', 'time_from_presentation_onset'))\n\nds = lfp_VISp.sel(time = time_selection, method='nearest').to_dataset(name = 'aligned_lfp')\nds = ds.assign(time=inds).unstack('time')\n\naligned_lfp_135 = ds['aligned_lfp']\n\npresentation_times = dg_presentation_table_315.start_time.values\npresentation_ids = dg_presentation_table_315.index.values\n\nprint(len(presentation_times[:-1]))\n\ntrial_window = np.arange(0, 0.50, 1/100)\ntime_selection = np.concatenate([trial_window + t for t in presentation_times])\n\ninds = pd.MultiIndex.from_product((presentation_ids, trial_window), \n                                  names=('presentation_id', 'time_from_presentation_onset'))\n\nds = lfp_VISp.sel(time = time_selection, method='nearest').to_dataset(name = 'aligned_lfp')\nds = ds.assign(time=inds).unstack('time')\n\naligned_lfp_315 = ds['aligned_lfp']\n\n# aligned_lfp_135 = aligned_lfp_135[:,:8,:].append(aligned_lfp_135[:,12:14,:].append(aligned_lfp_135[:,19:,:]))\n# aligned_lfp_315 = aligned_lfp_315[:,:8,:].append(aligned_lfp_315[:,12:14,:].append(aligned_lfp_315[:,19:,:]))\n\n# aligned_lfp_135 = xr.concat(xr.concat(aligned_lfp_135[:,:8,:], \n#                                       aligned_lfp_135[:,12:14,:], dim='presentation_id'),\n#                             aligned_lfp_135[:,19:,:], dim='presentation_id')\n# aligned_lfp_315 = xr.concat(xr.concat(aligned_lfp_315[:,:8,:], \n#                                       aligned_lfp_315[:,12:14,:], dim='presentation_id'),\n#                             aligned_lfp_315[:,19:,:], dim='presentation_id')\n\n# xr.concat(aligned_lfp_135[:,:8,:], aligned_lfp_135[:,12:14,:], dim='presentation_id')\n\naligned_lfp_135 = aligned_lfp_135[:,:8,:].concat(aligned_lfp_135[:,12:14,:].concat(aligned_lfp_135[:,19:,:],dim=\"presentation_id\"),dim=\"presentation_id\")",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "045a4755"
    },
    {
      "cell_type": "code",
      "source": "aligned_lfp_135\nNaNs = 0\nsus_channels = []\nsus_presentations = []\n\nfor channel in range(len(aligned_lfp_315)):\n    for presentation_id in range(channel):\n        for time in range(presentation_id):\n            if np.isnan(aligned_lfp_315[channel][presentation_id][time]):\n                print(\"NaN at time {} in presentation {} in channel {}\".format(time,presentation_id,channel))\n                NaNs += 1\n                if not (channel in sus_channels):\n                    sus_channels.append(channel)\n                if not (presentation_id in sus_presentations):\n                    sus_presentations.append(presentation_id)\nprint(NaNs)\nprint(\"Sus channels:\",sus_channels)\nprint(\"sus presentations:\",sus_presentations)\n\n[:8 + 12:14 + 19:]",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "c99f6209"
    },
    {
      "cell_type": "code",
      "source": "import scipy.stats as stats\nimport math\n\ntStat, pValue = stats.ttest_ind(a= aligned_lfp_135,\n               b = aligned_lfp_315,\n               axis = 1,\n               equal_var = False,\n               nan_policy = 'raise')\nprint(tStat)\nprint(pValue.shape)\n\n# MANUAL BENJAMINI-HOCHBERG\n\ndef benjamini_hochberg(p_values, alpha):\n    indices_of_significant_values = []\n    p_values_flat = p_values.flatten()\n    dictionary = dict(zip(p_values_flat,range(len(p_values_flat))))\n    \n    sorted_keys = sorted(dictionary)\n    print(sorted_keys[:100])\n    \n    greatest_i_so_far = 0\n\n    for i in range(len(sorted_keys)):\n        key = sorted_keys[i]\n        critical_value = i*alpha/len(dictionary)\n        if key<critical_value:\n            greatest_i_so_far = i\n    for i in range(greatest_i_so_far):\n        indices_of_significant_values.append(dictionary.get(sorted_keys[i]))\n\n    indices_of_significant_values = sorted(indices_of_significant_values)\n    print(\"number of significant p-values:\",len(indices_of_significant_values))\n    \n    return indices_of_significant_values\n\nsignificant_indices = benjamini_hochberg(p_values = pValue, alpha = .05)\n\nasdf = []\nfor i in range(pValue.shape[0]*pValue.shape[1]):\n    if i in significant_indices:\n        asdf.append(1)\n    else:\n        asdf.append(0)\nprint(len(asdf))\nmask = []\nfor i in range(pValue.shape[0]):\n    row = []\n    for j in range(pValue.shape[1]):\n        row.append(asdf[i*pValue.shape[1]+j])\n    mask.append(row)\n\nplt.figure(figsize=(8,6))\nim = plt.imshow(mask, aspect='auto', origin='lower')\n_ = plt.colorbar(im, fraction=0.036, pad=0.04)\n_ = plt.xlabel('Sample number')\n_ = plt.ylabel('Channel index')\n        ",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "28904fc7"
    },
    {
      "cell_type": "code",
      "source": "pValue.shape",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "80680232"
    },
    {
      "cell_type": "code",
      "source": "flashes_1_data = aligned_lfp_1.to_masked_array()\nflashes_minus1_data = aligned_lfp_minus1.to_masked_array()\nflashes_1_data.mask = np.ma.nomask\nflashes_minus1_data.mask = np.ma.nomask\nflashes_data_combined = np.concatenate((flashes_1_data,flashes_minus1_data),axis=1).transpose(1,0,2)\nflashes_data_combined = flashes_data_combined.reshape(flashes_data_combined.shape[0],flashes_data_combined.shape[1] * flashes_data_combined.shape[2])\nlabels = []\nfor i in range(75):\n    labels.append(1)\nfor i in range(75,150):\n    labels.append(0)\nprint(flashes_data_combined.shape)\n# print(labels)\nfrom sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(flashes_data_combined, labels, test_size=0.25, stratify=labels)\n# print(x_train.shape)\n# print(x_test.shape)\n# print(len(y_train))\n# print(len(y_test))\nprint(train_test_split)",
      "metadata": {
        "scrolled": true
      },
      "execution_count": null,
      "outputs": [],
      "id": "e7f80ce8"
    },
    {
      "cell_type": "code",
      "source": "import sklearn.linear_model\nmodel = sklearn.linear_model.LogisticRegression()\nmodel.fit(x_train,y_train)\nmodel.score(x_test,y_test)",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "d3f1931e"
    },
    {
      "cell_type": "code",
      "source": "flashes_presentation_times",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "56a78fc1"
    },
    {
      "cell_type": "code",
      "source": "flashes_presentation_table",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "8131b336"
    },
    {
      "cell_type": "code",
      "source": "presentation_table_drifting_gratings = session.stimulus_presentations[session.stimulus_presentations.stimulus_name == 'drifting_gratings] ']",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "205f0458"
    },
    {
      "cell_type": "code",
      "source": "presentation_table_drifting_gratings",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "44469164"
    },
    {
      "cell_type": "code",
      "source": "drifting_gratings_orientations = presentation_table_drifting_gratings.orientation.unique()\n#for orientation in drifting_gratings_orientations:",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "4c8fc82a"
    },
    {
      "cell_type": "code",
      "source": "presentation_table_drifting_gratings\n\npresentation_table_drifting_gratings_315 = presentation_table_drifting_gratings[presentation_table_drifting_gratings.orientation == 315.0]\npresentation_table_drifting_gratings_135 = presentation_table_drifting_gratings[presentation_table_drifting_gratings.orientation == 135.0]",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "68dc4e0b"
    },
    {
      "cell_type": "code",
      "source": "flashes_presentation_table\n\nflaes_presentation_table_1 = flahses_presentation_table[flahses_presentation_table.color \n                                                                      == 1.0]\nflahses_presentation_table_minus1 = flahses_presentation_table[flahses_presentation_table.color \n                                                                      == -1.0]",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "4143968a"
    },
    {
      "cell_type": "code",
      "source": "flahses_presentation_table_1",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "17880fad"
    },
    {
      "cell_type": "code",
      "source": "flahses_presentation_table_minus1",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "a5e7e0f1"
    },
    {
      "cell_type": "code",
      "source": "print(session.stimulus_presentations.stimulus_name.unique())",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "69d4a258"
    },
    {
      "cell_type": "code",
      "source": "#CONSOLIDATION OF ALLEN CODE FOR PLOTTING LFP DATA ALIGNED TO START OF STIMULUS\ndef plot_aligned_LFP(lfp_data, presentation_table_master, stimulus_str, name_str):\n    \n    #get data and plot\n    presentation_times = presentation_table_master.start_time.values\n    presentation_ids = presentation_table_master.index.values\n\n    trial_window = np.arange(-0.5, 0.5, 1/1000)\n    time_selection = np.concatenate([trial_window + t for t in presentation_times])\n\n    inds = pd.MultiIndex.from_product((presentation_ids, trial_window), \n                                      names=('presentation_id', 'time_from_presentation_onset'))\n\n    ds = lfp_data.sel(time = time_selection, method='nearest').to_dataset(name = 'aligned_lfp')\n    ds = ds.assign(time=inds).unstack('time')\n\n    aligned_lfp = ds['aligned_lfp']\n\n    plt.figure(figsize=(8,6))\n    plt.vlines(x = 500, ymin = 0, ymax = len(lfp_data.channel)-1, \n       colors = 'white', \n       label = 'vline_multiple - full height') \n    im = plt.imshow(aligned_lfp.mean(dim='presentation_id'), aspect='auto', origin='lower', vmin=-1e-4, vmax=1e-4)\n    _ = plt.colorbar(im, fraction=0.036, pad=0.04)\n    _ = plt.xlabel('Sample number')\n    _ = plt.ylabel('Channel index')\n    _ = plt.title('Aligned LFP for stimulus {}'.format(stimulus_str))\n#     filename = '{}___stimulus___{}.png'.format(name_str,stimulus_str)\n#     plt.imsave(os.path.join(out_directory, filename), im)",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "d8de1273"
    },
    {
      "cell_type": "code",
      "source": " presentation_times = presentation_table_master.start_time.values",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "fcebdc67"
    },
    {
      "cell_type": "code",
      "source": "#CUSTOM ATTEMPT TO PLOT ALIGNED LFPs UNDER DIFFERENT CONDITIONS\ndef plot_aligned_LFP_different_orientations(lfp_data, presentation_table_master, orientations, stimulus_str, name_str):\n    for orientation in orientations:\n        #make new DataArray slice\n        presentation_table = presentation_table_master[presentation_table_master.orientation == orientation]\n        \n        #get data and plot\n        presentation_times = presentation_table.start_time.values\n        presentation_ids = presentation_table.index.values\n\n        trial_window = np.arange(-0.5, 0.5, 1/1000)\n        time_selection = np.concatenate([trial_window + t for t in presentation_times])\n\n        inds = pd.MultiIndex.from_product((presentation_ids, trial_window), \n                                          names=('presentation_id', 'time_from_presentation_onset'))\n\n        ds = lfp_data.sel(time = time_selection, method='nearest').to_dataset(name = 'aligned_lfp')\n        ds = ds.assign(time=inds).unstack('time')\n\n        aligned_lfp = ds['aligned_lfp']\n\n        plt.figure(figsize=(8,6))\n        plt.vlines(x = 500, ymin = 0, ymax = len(lfp_data.channel)-1, \n           colors = 'white', \n           label = 'vline_multiple - full height') \n        im = plt.imshow(aligned_lfp.mean(dim='presentation_id'), aspect='auto', origin='lower', vmin=-1e-4, vmax=1e-4)\n        _ = plt.colorbar(im, fraction=0.036, pad=0.04)\n        _ = plt.xlabel('Sample number')\n        _ = plt.ylabel('Channel index')\n        _ = plt.title('Aligned LFP for orientation {} for stimulus {}'.format(str(orientation), stimulus_str))\n#         filename = '{}___orientation_{}___stimulus___{}.png'.format(name_str,str(orientation),stimulus_str)\n#         plt.imsave(os.path.join(out_directory, filename), im)\n\ndef plot_aligned_LFP_different_colors(lfp_data, presentation_table_master, colors, stimulus_str, name_str):\n    for color in colors:\n        #make new DataArray slice\n        presentation_table = presentation_table_master[presentation_table_master.color == color]\n        \n        #get data and plot\n        presentation_times = presentation_table.start_time.values\n        presentation_ids = presentation_table.index.values\n\n        trial_window = np.arange(-0.5, 0.5, 1/1000)\n        time_selection = np.concatenate([trial_window + t for t in presentation_times])\n\n        inds = pd.MultiIndex.from_product((presentation_ids, trial_window), \n                                          names=('presentation_id', 'time_from_presentation_onset'))\n\n        ds = lfp_data.sel(time = time_selection, method='nearest').to_dataset(name = 'aligned_lfp')\n        ds = ds.assign(time=inds).unstack('time')\n\n        aligned_lfp = ds['aligned_lfp']\n\n        plt.figure(figsize=(8,6))\n        plt.vlines(x = 500, ymin = 0, ymax = len(lfp_data.channel)-1, \n           colors = 'white', \n           label = 'vline_multiple - full height')\n        im = plt.imshow(aligned_lfp.mean(dim='presentation_id'), aspect='auto', origin='lower', vmin=-1e-4, vmax=1e-4)\n        _ = plt.colorbar(im, fraction=0.036, pad=0.04)\n        _ = plt.xlabel('Sample number')\n        _ = plt.ylabel('Channel index')\n        _ = plt.title('Aligned LFP for color {} for stimulus {}'.format(str(color), stimulus_str))\n#         filename = '{}___color_{}___stimulus___{}.png'.format(name_str,str(color),stimulus_str)\n#         plt.imsave(os.path.join(out_directory, filename), im)\n        \n        \n",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "01a209bf"
    },
    {
      "cell_type": "code",
      "source": "print(len(lfp_VISp.channel))\nprint(presentation_table_drifting_gratings.orientation.unique())\n",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "45f0111c"
    },
    {
      "cell_type": "markdown",
      "source": "CREATE PLOTS OF LFP DATA AVERAGED ACROSS TRIALS FOR DRIFTING GRATINGS, STATIC GRATINGS, AND FLASHES FOR DIFFERENT ORIENTATION/COLOR CONDITIONS WHERE RELEVANT AS WELL AS ACROSS ALL CONDITIONS\n\nINDIVIDUAL CHANNELS DISPLAYED",
      "metadata": {},
      "id": "69bd9c66"
    },
    {
      "cell_type": "code",
      "source": "# presentation_table_drifting_gratings = session.stimulus_presentations[session.stimulus_presentations.stimulus_name \n#                                                                        == 'drifting_gratings']\n# plot_aligned_LFP_different_orientations(lfp, presentation_table_drifting_gratings, \n#                                          presentation_table_drifting_gratings.orientation.unique(), \n#                                         'Drifting gratings', 'probeC_all')\n\n\n# presentation_table_static_gratings = session.stimulus_presentations[session.stimulus_presentations.stimulus_name \n#                                                                     == 'static_gratings']\n# plot_aligned_LFP_different_orientations(lfp, presentation_table_static_gratings, \n#                                        presentation_table_static_gratings.orientation.unique(), \n#                                       'Static gratings', 'probeC_all')\n\n# plot_aligned_LFP_different_orientations(lfp_VISp, dg_presentation_table, dg_presentation_table.orientation.unique(),'Drifting gratings', 'probeC_VISp')\n# presentation_table_drifting_gratings\n\n\n\n\n\n# plot_aligned_LFP_different_orientations(lfp_VISp, presentation_table_static_gratings, \n#                                         presentation_table_static_gratings.orientation.unique(), \n#                                          'Static gratings', 'probeC_VISp')\n\npresentation_table_flashes = session.stimulus_presentations[session.stimulus_presentations.stimulus_name \n                                                                     == 'flashes']\n# plot_aligned_LFP_different_colors(lfp, presentation_table_flashes, \n#                                          presentation_table_flashes.color.unique(), \n#                                          'Flashes', 'probeC_all')\n\n# plot_aligned_LFP_different_colors(lfp_VISp, presentation_table_flashes, \n#                                          presentation_table_flashes.color.unique(), \n#                                          'Flashes', 'probeC_VISp')\n\n# plot_aligned_LFP(lfp, presentation_table_drifting_gratings, 'Drifting gratings', \"probeC_all\")\n\n# plot_aligned_LFP(lfp, presentation_table_flashes, 'Flashes', \"probeC_all\")\n\n# plot_aligned_LFP(lfp_VISp, presentation_table_drifting_gratings, 'Drifting gratings', \"probeC_VISp\")\n\n# plot_aligned_LFP(lfp_VISp, presentation_table_flashes, 'Flashes', \"probeC_VISp\")\n",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "c668b320"
    },
    {
      "cell_type": "markdown",
      "source": "​\nCREATE PLOTS OF LFP DATA AVERAGED ACROSS TRIALS FOR DRIFTING GRATINGS, STATIC GRATINGS, AND FLASHES FOR DIFFERENT ORIENTATION/COLOR CONDITIONS WHERE RELEVANT AS WELL AS ACROSS ALL CONDITIONS\n\nCHANNELS ALSO AVERAGED",
      "metadata": {},
      "id": "9408fb3a"
    },
    {
      "cell_type": "code",
      "source": "presentation_table_drifting_gratings",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "b26e29cd"
    },
    {
      "cell_type": "markdown",
      "source": "Now, we can align the LFP to these presentation times using some xarray magic:",
      "metadata": {},
      "id": "b2405bc5"
    },
    {
      "cell_type": "code",
      "source": "trial_window = np.arange(-0.5, 0.5, 1/500)\ntime_selection = np.concatenate([trial_window + t for t in presentation_times])\n\ninds = pd.MultiIndex.from_product((presentation_ids, trial_window), \n                                  names=('presentation_id', 'time_from_presentation_onset'))\n\nds = lfp.sel(time = time_selection, method='nearest').to_dataset(name = 'aligned_lfp')\nds = ds.assign(time=inds).unstack('time')\n\naligned_lfp = ds['aligned_lfp']",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "50fb3213"
    },
    {
      "cell_type": "markdown",
      "source": "PLOTTING INDIVIDUAL TRIAL DATA FOR EACH COLOR OF FLASH STIMULUS",
      "metadata": {},
      "id": "85eff8f0"
    },
    {
      "cell_type": "code",
      "source": "presentation_table_flashes_minus1 = presentation_table_flashes[presentation_table_flashes.color == -1]\npresentation_table_flashes_minus1",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "62f610ba"
    },
    {
      "cell_type": "code",
      "source": "presentation_table_flashes_plus1 = presentation_table_flashes[presentation_table_flashes.color == 1]\npresentation_table_flashes_plus1",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "ff019c50"
    },
    {
      "cell_type": "code",
      "source": "flashes_presentation_table_1",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "aa80d61b"
    },
    {
      "cell_type": "code",
      "source": "# print(aligned_lfp.shape)\n# print(aligned_lfp.presentation_id)\n# print(aligned_lfp[:,0,:])\n\npresentation_times = flashes_presentation_table_1.start_time.values\npresentation_ids = flashes_presentation_table_1.index.values\npresentation_col = 1\n\n\n# presentation_times = flashes_presentation_table_minus1.start_time.values\n# presentation_ids = flashes_presentation_table_minus1.index.values\n# presentation_col = -1\n\ntrial_window = np.arange(0.0, 0.5, 1/1000)\ntime_selection = np.concatenate([trial_window + t for t in presentation_times])\n\ninds = pd.MultiIndex.from_product((presentation_ids, trial_window), \n                                  names=('presentation_id', 'time_from_presentation_onset'))\n\nds = lfp_VISp.sel(time = time_selection, method='nearest').to_dataset(name = 'aligned_lfp')\nds = ds.assign(time=inds).unstack('time')\n\naligned_lfp = ds['aligned_lfp']\n\n# print(aligned_lfp)\n\nfor trial in range(len(aligned_lfp.presentation_id)):\n    plt.figure(figsize=(8,6))\n    im = plt.imshow(aligned_lfp[:,trial,:], aspect='auto', origin='lower', vmin=-1e-4, vmax=1e-4)\n    _ = plt.colorbar(im, fraction=0.036, pad=0.04)\n    _ = plt.xlabel('Sample number')\n    _ = plt.ylabel('Channel index')\n    _ = plt.title('Aligned LFPs to trial onset for flashes, trial {}'.format(str(aligned_lfp.presentation_id[trial])))",
      "metadata": {
        "scrolled": true
      },
      "execution_count": null,
      "outputs": [],
      "id": "da52cf7f"
    },
    {
      "cell_type": "markdown",
      "source": "PLOTTING INDIVIDUAL TRIAL DATA FOR DRIFTING GRATING ORIENTATION 135 VS 315¶",
      "metadata": {},
      "id": "3a11f6af"
    },
    {
      "cell_type": "code",
      "source": "# print(aligned_lfp.shape)\n# print(aligned_lfp.presentation_id)\n# print(aligned_lfp[:,0,:])\n\n# presentation_times = presentation_table_drifting_gratings_135.start_time.values\n# presentation_ids = presentation_table_drifting_gratings_135.index.values\n# presentation_or = 135\npresentation_times = presentation_table_drifting_gratings_315.start_time.values\npresentation_ids = presentation_table_drifting_gratings_315.index.values\npresentation_or = 315\n\ntrial_window = np.arange(-0.5, 0.5, 1/500)\ntime_selection = np.concatenate([trial_window + t for t in presentation_times])\n\ninds = pd.MultiIndex.from_product((presentation_ids, trial_window), \n                                  names=('presentation_id', 'time_from_presentation_onset'))\n\nds = lfp.sel(time = time_selection, method='nearest').to_dataset(name = 'aligned_lfp')\nds = ds.assign(time=inds).unstack('time')\n\naligned_lfp = ds['aligned_lfp']\n\nfor trial in range(len(aligned_lfp.presentation_id)):\n    plt.figure(figsize=(8,6))\n    im = plt.imshow(aligned_lfp[-20:-10,trial,:], aspect='auto', origin='lower', vmin=-1e-4, vmax=1e-4)\n    _ = plt.colorbar(im, fraction=0.036, pad=0.04)\n    _ = plt.xlabel('Sample number')\n    _ = plt.ylabel('Channel index')\n    _ = plt.title('Aligned LFPs to trial onset for drifting gratings, trial {}'.format(str(aligned_lfp.presentation_id[trial])))",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "b6ea8903"
    },
    {
      "cell_type": "markdown",
      "source": "## Probe D",
      "metadata": {},
      "id": "23a868e7"
    },
    {
      "cell_type": "markdown",
      "source": "The motivation in investigating Probe D is to isolate the LGD (lateral Geniculate Nucleus, LGN) as it may reecieve the stimulation prior to V1",
      "metadata": {},
      "id": "c6e1f71e"
    },
    {
      "cell_type": "markdown",
      "source": "### NWBWIDGETS",
      "metadata": {},
      "id": "0b4dd890"
    },
    {
      "cell_type": "code",
      "source": "from pynwb import NWBHDF5IO\nimport allensdk.brain_observatory.ecephys.nwb\n\nfrom nwbwidgets import nwb2widget\nfpath = '/Users/willi/downloads/session_715093703/probe_810755803_lfp.nwb'\nnwb = NWBHDF5IO(fpath, 'r').read()\n\n#below works if you are analyzing the session file as input rather than a probe. remmeber the .nwb ext\n#from nwbwidgets.allen import AllenRasterWidget\n\n#AllenRasterWidget(nwb.units)\n",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "192b0c08"
    },
    {
      "cell_type": "code",
      "source": "nwb2widget(nwb)\n",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "0f21d7c7"
    },
    {
      "cell_type": "markdown",
      "source": "## LFP Exploration",
      "metadata": {},
      "id": "c7acb89a"
    },
    {
      "cell_type": "markdown",
      "source": "##### Below is loading in the specific probe of interest and selecting the region of interest LGd",
      "metadata": {},
      "id": "e16da15b"
    },
    {
      "cell_type": "code",
      "source": "probe_id = session.probes[session.probes.description == 'probeD'].index.values[0]\nlfp = session.get_lfp(probe_id)\nlfp_LGd = lfp.sel(channel = lfp.channel[0:21])\n",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "c482f21c"
    },
    {
      "cell_type": "code",
      "source": "session.probes\n",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "9fb7503d"
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "567ff90e"
    },
    {
      "cell_type": "code",
      "source": "lfp",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "fe7afd9b"
    },
    {
      "cell_type": "code",
      "source": "lfp_LGd",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "1d2d8ec4"
    },
    {
      "cell_type": "markdown",
      "source": "Next we desire to isolate time slices and visualize them through a plot",
      "metadata": {},
      "id": "e0634d4d"
    },
    {
      "cell_type": "code",
      "source": "lfp_slice = lfp.sel(time=slice(1800,5410))\n\nlfp_slice_LGd = lfp_slice.sel(channel=lfp_slice.channel[62:84])\n",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "5f24d750"
    },
    {
      "cell_type": "code",
      "source": "lfp_slice = lfp.sel(time=slice(1800,5410))\n\nlfp_slice_LGd = lfp_slice.sel(channel=lfp_slice.channel[-25:-10]) ##playing around with the range for the matplotlib...\n#...function further down\n",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "170d8947"
    },
    {
      "cell_type": "markdown",
      "source": "Obtaining multiple plots at once for lfp_slice_LGd with a for loop",
      "metadata": {},
      "id": "af661486"
    },
    {
      "cell_type": "code",
      "source": "for i in range(15):\n    plt.figure(figsize=(10,2))\n    _ = plt.plot(lfp_slice_LGd.time, lfp_slice_LGd.sel(channel=lfp_slice_LGd.channel[i]))\n    plt.xlabel('Time (s)')\n    plt.ylabel('LFP (V)')",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "a0498392"
    },
    {
      "cell_type": "code",
      "source": "lfp_slice_LGd",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "ba8b0129"
    },
    {
      "cell_type": "code",
      "source": "lfp.sel(channel=lfp.channel[62:84])",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "70c9e0ce"
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "fe54b712"
    },
    {
      "cell_type": "code",
      "source": "plt.figure(figsize=(10,2))\n_ = plt.plot(lfp_slice_LGd.time, lfp_slice_LGd)\nplt.xlabel('Time (s)')\nplt.ylabel('LFP (V)')",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "67f0a74e"
    },
    {
      "cell_type": "markdown",
      "source": "###### Start of LGd Analysis for Flashes -1 and +1",
      "metadata": {},
      "id": "1c49b61b"
    },
    {
      "cell_type": "markdown",
      "source": "Yes, this code generates the desired graphs, you just have to do them one at a time changing out the time and id for the 1 and -1 conditions.",
      "metadata": {},
      "id": "50327d7c"
    },
    {
      "cell_type": "code",
      "source": "LGd= lfp.sel(channel=lfp.channel[0:21])",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "6b15071b"
    },
    {
      "cell_type": "code",
      "source": "LGdFlashes=LGd.sel(time=slice(1800,3600))",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "80cf5de1"
    },
    {
      "cell_type": "code",
      "source": "plt.figure(figsize=(10,2))\n_ = plt.plot(LGdFlashes.time, LGdFlashes)\nplt.xlabel('Time (s)')\nplt.ylabel('LFP (V)')",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "c845b919"
    },
    {
      "cell_type": "code",
      "source": "session.stimulus_presentations",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "1cb3e210"
    },
    {
      "cell_type": "code",
      "source": "\nflashes_presentation_table = session.stimulus_presentations[session.stimulus_presentations.stimulus_name == 'flashes']\n",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "9f9ccb10"
    },
    {
      "cell_type": "code",
      "source": "flashes_presentation_table_plus1 = flashes_presentation_table[flashes_presentation_table.color \n                                                                      == 1.0]\nflashes_presentation_table_minus1 = flashes_presentation_table[flashes_presentation_table.color \n                                                                      == -1.0]",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "82ba2a5a"
    },
    {
      "cell_type": "code",
      "source": "flashes_presentation_table_minus1",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "e6d3abff"
    },
    {
      "cell_type": "code",
      "source": "flashes_presentation_table_plus1",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "caece2cb"
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "93455c36"
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "de833399"
    },
    {
      "cell_type": "code",
      "source": "presentation_table = session.stimulus_presentations[session.stimulus_presentations.stimulus_name == 'flashes']\n\npresentation_times = presentation_table.start_time.values\npresentation_ids = presentation_table.index.values",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "186d906d"
    },
    {
      "cell_type": "code",
      "source": "presentation_table_plus1 = presentation_table[presentation_table.color==1]\npresentation_times_plus1 = presentation_table_plus1.start_time.values\npresentation_ids_plus1 = presentation_table_plus1.index.values",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "f9770d19"
    },
    {
      "cell_type": "code",
      "source": "presentation_table_minus1 = presentation_table[presentation_table.color==-1]\npresentation_times_minus1 = presentation_table_minus1.start_time.values\npresentation_ids_minus1 = presentation_table_minus1.index.values",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "1566a7df"
    },
    {
      "cell_type": "code",
      "source": "trial_window = np.arange(-0.5, 0.5, 1/500)\ntime_selection = np.concatenate([trial_window + t for t in presentation_times_plus1])\n\ninds = pd.MultiIndex.from_product((presentation_ids_plus1, trial_window), \n                                  names=('presentation_id', 'time_from_presentation_onset'))\n\nds = lfp.sel(time = time_selection, method='nearest').to_dataset(name = 'aligned_lfp')\nds = ds.assign(time=inds).unstack('time')\n\naligned_lfp_plus1 = ds['aligned_lfp']",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "5323a4c8"
    },
    {
      "cell_type": "code",
      "source": "plt.figure(figsize=(8,6))\nim = plt.imshow(aligned_lfp_plus1.mean(dim='presentation_id'), aspect='auto', origin='lower', vmin=-1e-4, vmax=1e-4)\n_ = plt.colorbar(im, fraction=0.036, pad=0.04)\n_ = plt.xlabel('Sample number')\n_ = plt.ylabel('Channel index')",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "64d94448"
    },
    {
      "cell_type": "code",
      "source": "trial_window = np.arange(-0.5, 0.5, 1/500)\ntime_selection = np.concatenate([trial_window + t for t in presentation_times_minus1])\n\ninds = pd.MultiIndex.from_product((presentation_ids_minus1, trial_window), \n                                  names=('presentation_id', 'time_from_presentation_onset'))\n\nds = lfp.sel(time = time_selection, method='nearest').to_dataset(name = 'aligned_lfp')\nds = ds.assign(time=inds).unstack('time')\n\naligned_lfp_minus1 = ds['aligned_lfp']",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "f28c760e"
    },
    {
      "cell_type": "code",
      "source": "aligned_lfp_minus1",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "4aa4416d"
    },
    {
      "cell_type": "code",
      "source": "plt.figure(figsize=(8,6))\nim = plt.imshow(aligned_lfp_minus1.mean(dim='presentation_id'), aspect='auto', origin='lower', vmin=-1e-4, vmax=1e-4)\n_ = plt.colorbar(im, fraction=0.036, pad=0.04)\n_ = plt.xlabel('Sample number')\n_ = plt.ylabel('Channel index')",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "990d47ed"
    },
    {
      "cell_type": "code",
      "source": "# PLOTTING ABSOLUTE DIFFERENCE BETWEEN THE TWO\n\nplt.figure(figsize=(8,6))\nim = plt.imshow(aligned_lfp_plus1.mean(dim='presentation_id') - aligned_lfp_minus1.mean(dim='presentation_id'), aspect='auto', origin='lower', vmin=-1e-4, vmax=1e-4)\n_ = plt.colorbar(im, fraction=0.036, pad=0.04)\n_ = plt.xlabel('Sample number')\n_ = plt.ylabel('Channel index')\n\n",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "94304c3b"
    },
    {
      "cell_type": "code",
      "source": "difference = aligned_lfp_plus1 - aligned_lfp_minus1\ndifference\n# difference_mean = aligned_lfp_plus1.mean(dim='presentation_id') - aligned_lfp_minus1.mean(dim='presentation_id')\n# difference_mean",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "9d04ecc9"
    },
    {
      "cell_type": "markdown",
      "source": "T test for differences Null Hypothesis H0: There is no statistically significant difference between the means of the two stimulus conditions acoss time points. Alternative Hypothesis HA: There is a statistically significant difference between the means of the two stimulus conditions across time points.",
      "metadata": {},
      "id": "2e95c2b5"
    },
    {
      "cell_type": "code",
      "source": "import scipy.stats as stats\nimport math",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "5f2660f7"
    },
    {
      "cell_type": "code",
      "source": "\n\ntStat, pValue = stats.ttest_ind(a= aligned_lfp_minus1,\n               b = aligned_lfp_plus1,\n               axis = 1,\n               equal_var = False)",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "aecc56b1"
    },
    {
      "cell_type": "code",
      "source": "print(aligned_lfp_plus1.shape)",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "b908635a"
    },
    {
      "cell_type": "code",
      "source": "tstat = tTest.statistic",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "df69aa55"
    },
    {
      "cell_type": "code",
      "source": "tstat",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "fcaa4c0f"
    },
    {
      "cell_type": "code",
      "source": "print(\"P-Value:{} T-Statistic:{}\".format(pValue,tStat))",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "1f6efc6a"
    },
    {
      "cell_type": "code",
      "source": "len(pValue[0])\np_values_flat = pValue.flatten()\np_values_flat = p_values_flat.tolist()\nindices = range(len(p_values_flat))\nprint(indices)\np_index_dictionary = dict(zip(p_values_flat,indices))\nsorted_keys = sorted(p_index_dictionary)\nprint((sorted_keys[2500]))\n# print(p_index_dictionary)\n# print(len(p_values_flat))\n# print(p_index_dictionary)\n# print(sorted(p_index_dictionary))\n# print(len(p_index_dictionary.keys()))\n# print(p_index_dictionary.items())\n# print(list(p_index_dictionary.keys())[0])",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "6db0be2b"
    },
    {
      "cell_type": "code",
      "source": "# MANUAL BENJAMINI-HOCHBERG\n\ndef benjamini_hochberg(p_values, alpha):\n    indices_of_significant_values = []\n    p_values_flat = p_values.flatten()\n    dictionary = dict(zip(p_values_flat,range(len(p_values_flat))))\n    \n    sorted_keys = sorted(dictionary)\n    \n    greatest_i_so_far = 0\n\n    for i in range(len(sorted_keys)):\n        key = sorted_keys[i]\n        critical_value = i*alpha/len(dictionary)\n        if key<critical_value:\n            greatest_i_so_far = i\n    for i in range(greatest_i_so_far):\n        indices_of_significant_values.append(dictionary.get(sorted_keys[i]))\n\n    indices_of_significant_values = sorted(indices_of_significant_values)\n    print(\"number of significant p-values:\",len(indices_of_significant_values))\n    \n    return indices_of_significant_values\n\nsignificant_indices = benjamini_hochberg(p_values = pValue, alpha = .00000000000005)",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "db6a8113"
    },
    {
      "cell_type": "code",
      "source": "\nasdf = []\nfor i in range(pValue.shape[0]*pValue.shape[1]):\n    if i in significant_indices:\n        asdf.append(1)\n    else:\n        asdf.append(0)\nprint(len(asdf))\nmask = []\nfor i in range(pValue.shape[0]):\n    row = []\n    for j in range(pValue.shape[1]):\n        row.append(asdf[i*pValue.shape[1]+j])\n    mask.append(row)\n\nplt.figure(figsize=(8,6))\nim = plt.imshow(mask, aspect='auto', origin='lower')\n_ = plt.colorbar(im, fraction=0.036, pad=0.04)\n_ = plt.xlabel('Sample number')\n_ = plt.ylabel('Channel index')\n        ",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "758cff01"
    },
    {
      "cell_type": "code",
      "source": "pValue.shape[0]",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "b18c3fc4"
    },
    {
      "cell_type": "code",
      "source": "plt.figure(figsize=(8,6))\nim = plt.imshow(tStat, aspect='auto', origin='lower')\n_ = plt.colorbar(im, fraction=0.036, pad=0.04)\n_ = plt.xlabel('Sample number')\n_ = plt.ylabel('Channel index')",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "d8f0175b"
    },
    {
      "cell_type": "code",
      "source": "plt.figure(figsize=(8,6))\nim = plt.imshow(np.log(pValue), aspect='auto', origin='lower')\n_ = plt.colorbar(im, fraction=0.036, pad=0.04)\n_ = plt.xlabel('Sample number')\n_ = plt.ylabel('Channel index')",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "3be041f2"
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "2648514f"
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "3614171a"
    },
    {
      "cell_type": "code",
      "source": "ls = tStat.tolist()",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "09d31eb0"
    },
    {
      "cell_type": "code",
      "source": "tStat.shape",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "bdf48ac7"
    },
    {
      "cell_type": "code",
      "source": "import chart_studio.plotly as cs\nimport plotly.graph_objs as go\nfrom plotly.tools import FigureFactory as FF",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "2998f1cd"
    },
    {
      "cell_type": "code",
      "source": "cs.iplot(ls, filename='normal-dists-plot')",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "96351bea"
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "b57dab7b"
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "2bfd68a2"
    },
    {
      "cell_type": "code",
      "source": "plot_aligned_LFP_different_colors(lfp, presentation_table_flashes, \n                                     presentation_table_flashes.color.unique(), \n                                   'Flashes', 'probeD_all')",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "95410096"
    },
    {
      "cell_type": "code",
      "source": "plot_aligned_LFP_different_colors(lfp_LGd, presentation_table_flashes,                                         \n                                  presentation_table_flashes.color.unique(), \n                                     'Flashes', 'probeD_LGd')",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "b3d61c59"
    },
    {
      "cell_type": "code",
      "source": "plot_aligned_LFP(lfp, presentation_table_flashes, 'Flashes', \"probeD_all\")\n",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "3eebb3e5"
    },
    {
      "cell_type": "code",
      "source": "plot_aligned_LFP(lfp_LGd, presentation_table_flashes, 'Flashes', \"probeD_LGd\")",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "33afaddf"
    },
    {
      "cell_type": "code",
      "source": "# print(aligned_lfp.shape)\n# print(aligned_lfp.presentation_id)\n# print(aligned_lfp[:,0,:])\n\n# presentation_times = presentation_table_flashes_1.start_time.values\n# presentation_ids = presentation_table_flashes_1.index.values\n# presentation_col = 1\npresentation_times = presentation_table_flashes_minus1.start_time.values\npresentation_ids = presentation_table_flashes_minus1.index.values\npresentation_col = -1\n\ntrial_window = np.arange(-0.5, 0.5, 1/1000)\ntime_selection = np.concatenate([trial_window + t for t in presentation_times])\n\ninds = pd.MultiIndex.from_product((presentation_ids, trial_window), \n                                  names=('presentation_id', 'time_from_presentation_onset'))\n\nds = lfp.sel(time = time_selection, method='nearest').to_dataset(name = 'aligned_lfp')\nds = ds.assign(time=inds).unstack('time')\n\naligned_lfp = ds['aligned_lfp']\n\nfor trial in range(5):    #(len(aligned_lfp.presentation_id)):\n    plt.figure(figsize=(8,6))\n    im = plt.imshow(aligned_lfp[-25:,trial,:], aspect='auto', origin='lower', vmin=-1e-4, vmax=1e-4)\n    _ = plt.colorbar(im, fraction=0.036, pad=0.04)\n    _ = plt.xlabel('Sample number')\n    _ = plt.ylabel('Channel index')\n    _ = plt.title('Aligned LFPs to trial onset for flashes, trial {}'.format(str(aligned_lfp.presentation_id[trial])))",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "96533eb8"
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "8f88b1d7"
    },
    {
      "cell_type": "code",
      "source": "presentation_table_flashes",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "4df5253e"
    },
    {
      "cell_type": "code",
      "source": "lfp.mean()",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "d767944e"
    },
    {
      "cell_type": "code",
      "source": "lfp_LGd.mean()",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "34ea397d"
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "5a060443"
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "f97fe375"
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "8bca585c"
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "580570f1"
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "1b82cd34"
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "0ebf39cf"
    },
    {
      "cell_type": "markdown",
      "source": "###### End of LGd Analysis for Flashes -1 and +1",
      "metadata": {},
      "id": "8a8b9777"
    },
    {
      "cell_type": "code",
      "source": "plt.figure(figsize=(16,16))\nim = plt.imshow(lfp_slice_LGd.T,aspect='auto',origin='lower',vmin=-1e-3, vmax=1e-3)\n_ = plt.colorbar(im, fraction=0.036, pad=0.04)\n_ = plt.xlabel('Sample number')\n_ = plt.ylabel('Channel index')",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "82b16700"
    },
    {
      "cell_type": "markdown",
      "source": "Note that we've transposed the original array to place the time dimension along the x-axis. We've also configured the plot so that the origin of the array is in the lower-left, so that that channels closer to the probe tip are lower in the image.\n\nA few things to note about this plot:\n\nThe units of the LFP are volts, so the color scale ranges from -1 to +1 mV\n\nEven though there are 384 channels on the Neuropixels probe, there are only 95 channels in this plot. That's because only every 4th channel is included in the NWB file (resulting in 40 micron vertical spacing). In addition, the reference channels and channels far outside the brain have been removed.\n\nThe top of the plot is relatively flat. This corresponds to channels that are outside the brain. The LFP channels are originally referenced to a ground wire embedded in the ACSF/agarose mixture about cortex. Before NWB packaging, the LFP data is digitally referenced to the channels outside the brain, to remove noise that's shared across the whole probe. There's a large increase in LFP power toward the middle of the probe, which corresponds to channels in hippocampus.\n\nLet's do some additional data selection to look at just the visual recordings",
      "metadata": {},
      "id": "fde4a1da"
    },
    {
      "cell_type": "code",
      "source": "channel_ids = session.channels[(session.channels.probe_id == probe_id) & \\\n                 (session.channels.ecephys_structure_acronym.isin(['LGd']))].index.values\n\nlfp_slice2 = lfp_slice.sel(channel=slice(np.min(channel_ids), np.max(channel_ids)))\n\nplt.figure(figsize=(8,4))\nim = plt.imshow(lfp_slice2.T,aspect='auto',origin='lower',vmin=-1e-3, vmax=1e-3)\n_ = plt.colorbar(im, fraction=0.036, pad=0.04)\n_ = plt.xlabel('Sample number') ## Sample number is time: think of it like each time point is a sample\n_ = plt.ylabel('Channel index')",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "6efc5085"
    },
    {
      "cell_type": "markdown",
      "source": "What follows next is a sequence of code cells from Written by Clay, edited by myself which appear to be attempts to isolate the stimulus presentation for the probe. The code is fairly straightforward and will be used for work on Probe D Analysis",
      "metadata": {},
      "id": "33f92117"
    },
    {
      "cell_type": "code",
      "source": "\nflahses_presentation_table = session.stimulus_presentations[session.stimulus_presentations.stimulus_name == 'flashes']\n\nflahses_presentation_times = flahses_presentation_table.start_time.values\nflahses_presentation_ids = flahses_presentation_table.index.values\n",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "7a384456"
    },
    {
      "cell_type": "code",
      "source": "flahses_presentation_table\n",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "e931cc09"
    },
    {
      "cell_type": "code",
      "source": "presentation_table_drifting_gratings = session.stimulus_presentations[session.stimulus_presentations.stimulus_name == 'drifting_gratings] ']",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "096063f6"
    },
    {
      "cell_type": "code",
      "source": "presentation_table_drifting_gratings",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "e958ec13"
    },
    {
      "cell_type": "code",
      "source": "drifting_gratings_orientations = presentation_table_drifting_gratings.orientation.unique()\n#for orientation in drifting_gratings_orientations:",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "ee048982"
    },
    {
      "cell_type": "code",
      "source": "flahses_presentation_table\n\nflahses_presentation_table_1 = flahses_presentation_table[flahses_presentation_table.color \n                                                                      == 1.0]\nflahses_presentation_table_minus1 = flahses_presentation_table[flahses_presentation_table.color \n                                                                      == -1.0]",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "9b31e7df"
    },
    {
      "cell_type": "code",
      "source": "flahses_presentation_table_1",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "6296d4c7"
    },
    {
      "cell_type": "code",
      "source": "flahses_presentation_table_minus1",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "8a9f5970"
    },
    {
      "cell_type": "code",
      "source": "print(session.stimulus_presentations.stimulus_name.unique())",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "9d933298"
    },
    {
      "cell_type": "code",
      "source": "#CONSOLIDATION OF ALLEN CODE FOR PLOTTING LFP DATA ALIGNED TO START OF STIMULUS\ndef plot_aligned_LFP(lfp_data, presentation_table_master, stimulus_str, name_str):\n    \n    #get data and plot\n    presentation_times = presentation_table_master.start_time.values\n    presentation_ids = presentation_table_master.index.values\n\n    trial_window = np.arange(-0.5, 0.5, 1/1000)\n    time_selection = np.concatenate([trial_window + t for t in presentation_times])\n\n    inds = pd.MultiIndex.from_product((presentation_ids, trial_window), \n                                      names=('presentation_id', 'time_from_presentation_onset'))\n\n    ds = lfp_data.sel(time = time_selection, method='nearest').to_dataset(name = 'aligned_lfp')\n    ds = ds.assign(time=inds).unstack('time')\n\n    aligned_lfp = ds['aligned_lfp']\n\n    plt.figure(figsize=(8,6))\n    plt.vlines(x = 500, ymin = 0, ymax = len(lfp_data.channel)-1, \n       colors = 'white', \n       label = 'vline_multiple - full height') \n    im = plt.imshow(aligned_lfp.mean(dim='presentation_id'), aspect='auto', origin='lower', vmin=-1e-4, vmax=1e-4)\n    _ = plt.colorbar(im, fraction=0.036, pad=0.04)\n    _ = plt.xlabel('Sample number')\n    _ = plt.ylabel('Channel index')\n    _ = plt.title('Aligned LFP for stimulus {}'.format(stimulus_str))\n#     filename = '{}___stimulus___{}.png'.format(name_str,stimulus_str)\n#     plt.imsave(os.path.join(out_directory, filename), im)",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "c055cc92"
    },
    {
      "cell_type": "code",
      "source": "#CUSTOM ATTEMPT TO PLOT ALIGNED LFPs UNDER DIFFERENT CONDITIONS\ndef plot_aligned_LFP_different_orientations(lfp_data, presentation_table_master, orientations, stimulus_str, name_str):\n    for orientation in orientations:\n        #make new DataArray slice\n        presentation_table = presentation_table_master[presentation_table_master.orientation == orientation]\n        \n        #get data and plot\n        presentation_times = presentation_table.start_time.values\n        presentation_ids = presentation_table.index.values\n\n        trial_window = np.arange(-0.5, 0.5, 1/1000)\n        time_selection = np.concatenate([trial_window + t for t in presentation_times])\n\n        inds = pd.MultiIndex.from_product((presentation_ids, trial_window), \n                                          names=('presentation_id', 'time_from_presentation_onset'))\n\n        ds = lfp_data.sel(time = time_selection, method='nearest').to_dataset(name = 'aligned_lfp')\n        ds = ds.assign(time=inds).unstack('time')\n\n        aligned_lfp = ds['aligned_lfp']\n\n        plt.figure(figsize=(8,6))\n        plt.vlines(x = 500, ymin = 0, ymax = len(lfp_data.channel)-1, \n           colors = 'white', \n           label = 'vline_multiple - full height') \n        im = plt.imshow(aligned_lfp.mean(dim='presentation_id'), aspect='auto', origin='lower', vmin=-1e-4, vmax=1e-4)\n        _ = plt.colorbar(im, fraction=0.036, pad=0.04)\n        _ = plt.xlabel('Sample number')\n        _ = plt.ylabel('Channel index')\n        _ = plt.title('Aligned LFP for orientation {} for stimulus {}'.format(str(orientation), stimulus_str))\n#         filename = '{}___orientation_{}___stimulus___{}.png'.format(name_str,str(orientation),stimulus_str)\n#         plt.imsave(os.path.join(out_directory, filename), im)\n\ndef plot_aligned_LFP_different_colors(lfp_data, presentation_table_master, colors, stimulus_str, name_str):\n    for color in colors:\n        #make new DataArray slice\n        presentation_table = presentation_table_master[presentation_table_master.color == color]\n        \n        #get data and plot\n        presentation_times = presentation_table.start_time.values\n        presentation_ids = presentation_table.index.values\n\n        trial_window = np.arange(-0.5, 0.5, 1/1000)\n        time_selection = np.concatenate([trial_window + t for t in presentation_times])\n\n        inds = pd.MultiIndex.from_product((presentation_ids, trial_window), \n                                          names=('presentation_id', 'time_from_presentation_onset'))\n\n        ds = lfp_data.sel(time = time_selection, method='nearest').to_dataset(name = 'aligned_lfp')\n        ds = ds.assign(time=inds).unstack('time')\n\n        aligned_lfp = ds['aligned_lfp']\n\n        plt.figure(figsize=(8,6))\n        plt.vlines(x = 500, ymin = 0, ymax = len(lfp_data.channel)-1, \n           colors = 'white', \n           label = 'vline_multiple - full height')\n        im = plt.imshow(aligned_lfp.mean(dim='presentation_id'), aspect='auto', origin='lower', vmin=-1e-4, vmax=1e-4)\n        _ = plt.colorbar(im, fraction=0.036, pad=0.04)\n        _ = plt.xlabel('Sample number')\n        _ = plt.ylabel('Channel index')\n        _ = plt.title('Aligned LFP for color {} for stimulus {}'.format(str(color), stimulus_str))\n#         filename = '{}___color_{}___stimulus___{}.png'.format(name_str,str(color),stimulus_str)\n#         plt.imsave(os.path.join(out_directory, filename), im)\n        \n        \n",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "c7baee78"
    },
    {
      "cell_type": "code",
      "source": "print(len(lfp_LGd.channel))\nprint(presentation_table_drifting_gratings.orientation.unique())\n",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "0f1cd023"
    },
    {
      "cell_type": "markdown",
      "source": "CREATE PLOTS OF LFP DATA AVERAGED ACROSS TRIALS FOR DRIFTING GRATINGS, STATIC GRATINGS, AND FLASHES FOR DIFFERENT ORIENTATION/COLOR CONDITIONS WHERE RELEVANT AS WELL AS ACROSS ALL CONDITIONS\n\nINDIVIDUAL CHANNELS DISPLAYED",
      "metadata": {},
      "id": "e3397c6a"
    },
    {
      "cell_type": "code",
      "source": "presentation_table_drifting_gratings = session.stimulus_presentations[session.stimulus_presentations.stimulus_name \n                                                                       == 'drifting_gratings']\nplot_aligned_LFP_different_orientations(lfp, presentation_table_drifting_gratings, \n                                         presentation_table_drifting_gratings.orientation.unique(), \n                                         'Drifting gratings', 'probeD_all')\n\n\npresentation_table_static_gratings = session.stimulus_presentations[session.stimulus_presentations.stimulus_name \n                                                                     == 'static_gratings']\nplot_aligned_LFP_different_orientations(lfp, presentation_table_static_gratings, \n                                         presentation_table_static_gratings.orientation.unique(), \n                                         'Static gratings', 'probeD_all')\n\n\nplot_aligned_LFP_different_orientations(lfp_LGd, presentation_table_drifting_gratings, \n                                         presentation_table_drifting_gratings.orientation.unique(), \n                                         'Drifting gratings', 'probeD_LGd')\n\nplot_aligned_LFP_different_orientations(lfp_LGd, presentation_table_static_gratings, \n                                         presentation_table_static_gratings.orientation.unique(), \n                                         'Static gratings', 'probeD_LGd')\n\n\npresentation_table_flashes = session.stimulus_presentations[session.stimulus_presentations.stimulus_name \n                                                                    == 'flashes']\nplot_aligned_LFP_different_colors(lfp, presentation_table_flashes, \n                                     presentation_table_flashes.color.unique(), \n                                   'Flashes', 'probeD_all')\n\nplot_aligned_LFP_different_colors(lfp_LGd, presentation_table_flashes,                                         \n                                  presentation_table_flashes.color.unique(), \n                                     'Flashes', 'probeD_LGd')\n\nplot_aligned_LFP(lfp, presentation_table_drifting_gratings, 'Drifting gratings', \"probeD_all\")\n\nplot_aligned_LFP(lfp, presentation_table_flashes, 'Flashes', \"probeD_all\")\n\nplot_aligned_LFP(lfp_LGd, presentation_table_drifting_gratings, 'Drifting gratings', \"probeD_LGd\")\n\nplot_aligned_LFP(lfp_LGd, presentation_table_flashes, 'Flashes', \"probeD_LGd\")\n\n\n",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "9a9ffa78"
    },
    {
      "cell_type": "code",
      "source": "#plot_aligned_LFP_different_colors(lfp_LGd, presentation_table_flashes,                                         \n                                  presentation_table_flashes.color.unique(), \n                                     'Flashes', 'probeD_LGd')",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "d506a34f-bbed-42d6-ad98-8955c3100f4e"
    },
    {
      "cell_type": "code",
      "source": "plot_aligned_LFP_different_colors(lfp, presentation_table_flashes, \n                                     presentation_table_flashes.color.unique(), \n                                   'Flashes', 'probeD_all')\n",
      "metadata": {
        "scrolled": true
      },
      "execution_count": null,
      "outputs": [],
      "id": "27fcdde8"
    },
    {
      "cell_type": "code",
      "source": "plot_aligned_LFP(lfp, presentation_table_flashes, 'Flashes', \"probeD_all\")",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "aee670a5"
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "c65e2b11"
    },
    {
      "cell_type": "code",
      "source": "plot_aligned_LFP(lfp_LGd, presentation_table_flashes, 'Flashes', \"probeD_LGd\")\n",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "f1c00d5b"
    },
    {
      "cell_type": "code",
      "source": "presentation_table_flashes_minus1 = presentation_table_flashes[presentation_table_flashes.color == -1]\npresentation_table_flashes_minus1",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "6a7ce130"
    },
    {
      "cell_type": "code",
      "source": "presentation_table_flashes_plus1 = presentation_table_flashes[presentation_table_flashes.color == 1]\npresentation_table_flashes_plus1",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "df554fa5"
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "f7dbe519"
    },
    {
      "cell_type": "code",
      "source": "lfp\n",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "5b702903"
    },
    {
      "cell_type": "code",
      "source": "import cv2\n \n# read image as grey scale\nProbeD_drifting_LGd = cv2.imread('/User/Willi/Downloads', cv2.ProbeDDriftingGratingsLGD)\n \n# save image\nstatus = cv2.imwrite('/User/Willi/Downloads', cv2.ProbeDDriftingGratingsLGD)\n \nprint(\"Image written to file-system : \",status)",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "fd850d0a"
    },
    {
      "cell_type": "markdown",
      "source": "​CREATE PLOTS OF LFP DATA AVERAGED ACROSS TRIALS FOR DRIFTING GRATINGS, STATIC GRATINGS, AND FLASHES FOR DIFFERENT ORIENTATION/COLOR CONDITIONS WHERE RELEVANT AS WELL AS ACROSS ALL CONDITIONS\n\nCHANNELS ALSO AVERAGED",
      "metadata": {},
      "id": "55162594"
    },
    {
      "cell_type": "code",
      "source": "presentation_table_drifting_gratings",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "d7138393"
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "f961cb8a"
    },
    {
      "cell_type": "code",
      "source": "trial_window = np.arange(-0.5, 0.5, 1/500)\ntime_selection = np.concatenate([trial_window + t for t in presentation_times])\n\ninds = pd.MultiIndex.from_product((presentation_ids, trial_window), \n                                  names=('presentation_id', 'time_from_presentation_onset'))\n\nds = lfp.sel(time = time_selection, method='nearest').to_dataset(name = 'aligned_lfp')\nds = ds.assign(time=inds).unstack('time')\n\naligned_lfp = ds['aligned_lfp']",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "da3a3e62"
    },
    {
      "cell_type": "markdown",
      "source": "PLOTTING INDIVIDUAL TRIAL DATA FOR EACH COLOR OF FLASH STIMULUS",
      "metadata": {},
      "id": "914216a4"
    },
    {
      "cell_type": "code",
      "source": "# print(aligned_lfp.shape)\n# print(aligned_lfp.presentation_id)\n# print(aligned_lfp[:,0,:])\n\n# presentation_times = presentation_table_flashes_1.start_time.values\n# presentation_ids = presentation_table_flashes_1.index.values\n# presentation_col = 1\npresentation_times = presentation_table_flashes_minus1.start_time.values\npresentation_ids = presentation_table_flashes_minus1.index.values\npresentation_col = -1\n\ntrial_window = np.arange(-0.5, 0.5, 1/1000)\ntime_selection = np.concatenate([trial_window + t for t in presentation_times])\n\ninds = pd.MultiIndex.from_product((presentation_ids, trial_window), \n                                  names=('presentation_id', 'time_from_presentation_onset'))\n\nds = lfp.sel(time = time_selection, method='nearest').to_dataset(name = 'aligned_lfp')\nds = ds.assign(time=inds).unstack('time')\n\naligned_lfp = ds['aligned_lfp']\n\nfor trial in range(5):    #(len(aligned_lfp.presentation_id)):\n    plt.figure(figsize=(8,6))\n    im = plt.imshow(aligned_lfp[-25:,trial,:], aspect='auto', origin='lower', vmin=-1e-4, vmax=1e-4)\n    _ = plt.colorbar(im, fraction=0.036, pad=0.04)\n    _ = plt.xlabel('Sample number')\n    _ = plt.ylabel('Channel index')\n    _ = plt.title('Aligned LFPs to trial onset for flashes, trial {}'.format(str(aligned_lfp.presentation_id[trial])))",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "7acd58e1"
    },
    {
      "cell_type": "code",
      "source": "ds",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "2406f248"
    },
    {
      "cell_type": "markdown",
      "source": "PLOTTING INDIVIDUAL TRIAL DATA FOR DRIFTING GRATING ORIENTATION 135 VS 315¶",
      "metadata": {},
      "id": "3732e1fe"
    },
    {
      "cell_type": "code",
      "source": "# print(aligned_lfp.shape)\n# print(aligned_lfp.presentation_id)\n# print(aligned_lfp[:,0,:])\n\n# presentation_times = presentation_table_drifting_gratings_135.start_time.values\n# presentation_ids = presentation_table_drifting_gratings_135.index.values\n presentation_or = 135\npresentation_times = presentation_table_drifting_gratings_315.start_time.values\npresentation_ids = presentation_table_drifting_gratings_315.index.values\npresentation_or = 315\n\ntrial_window = np.arange(-0.5, 0.5, 1/500)\ntime_selection = np.concatenate([trial_window + t for t in presentation_times])\n\ninds = pd.MultiIndex.from_product((presentation_ids, trial_window), \n                                  names=('presentation_id', 'time_from_presentation_onset'))\n\nds = lfp.sel(time = time_selection, method='nearest').to_dataset(name = 'aligned_lfp')\nds = ds.assign(time=inds).unstack('time')\n\naligned_lfp = ds['aligned_lfp']\n\nfor trial in range(len(aligned_lfp.presentation_id)):\n    plt.figure(figsize=(8,6))\n    im = plt.imshow(aligned_lfp[-20:-10,trial,:], aspect='auto', origin='lower', vmin=-1e-4, vmax=1e-4)\n    _ = plt.colorbar(im, fraction=0.036, pad=0.04)\n    _ = plt.xlabel('Sample number')\n    _ = plt.ylabel('Channel index')\n    _ = plt.title('Aligned LFPs to trial onset for drifting gratings, trial {}'.format(str(aligned_lfp.presentation_id[trial])))",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "94532058"
    }
  ]
}